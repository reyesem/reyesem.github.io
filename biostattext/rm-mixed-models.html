<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>13 Mixed Effects Models | Statistical Modeling for the Biological Sciences</title>
  <meta name="description" content="Course notes for MA482/BE482 (Biostatistics) at Rose-Hulman Institute of Technology." />
  <meta name="generator" content="bookdown 0.20 and GitBook 2.6.7" />

  <meta property="og:title" content="13 Mixed Effects Models | Statistical Modeling for the Biological Sciences" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="Course notes for MA482/BE482 (Biostatistics) at Rose-Hulman Institute of Technology." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="13 Mixed Effects Models | Statistical Modeling for the Biological Sciences" />
  
  <meta name="twitter:description" content="Course notes for MA482/BE482 (Biostatistics) at Rose-Hulman Institute of Technology." />
  

<meta name="author" content="Eric M Reyes" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="rm-terminology.html"/>
<link rel="next" href="rm-gee.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<script src="libs/accessible-code-block-0.0.1/empty-anchor.js"></script>
<script src="libs/kePrint-0.0.1/kePrint.js"></script>
<link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet" />



<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Statistical Modeling</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a></li>
<li class="part"><span><b>I Review of the Inferential Process</b></span></li>
<li class="chapter" data-level="1" data-path="statistical-process.html"><a href="statistical-process.html"><i class="fa fa-check"></i><b>1</b> The Statistical Process</a><ul>
<li class="chapter" data-level="1.1" data-path="statistical-process.html"><a href="statistical-process.html#overview-of-drawing-inference"><i class="fa fa-check"></i><b>1.1</b> Overview of Drawing Inference</a></li>
<li class="chapter" data-level="1.2" data-path="statistical-process.html"><a href="statistical-process.html#data-storage"><i class="fa fa-check"></i><b>1.2</b> Data Storage</a></li>
<li class="chapter" data-level="1.3" data-path="statistical-process.html"><a href="statistical-process.html#tabular-data-presentation"><i class="fa fa-check"></i><b>1.3</b> Tabular Data Presentation</a></li>
<li class="chapter" data-level="1.4" data-path="statistical-process.html"><a href="statistical-process.html#graphical-data-presentation"><i class="fa fa-check"></i><b>1.4</b> Graphical Data Presentation</a></li>
<li class="chapter" data-level="1.5" data-path="statistical-process.html"><a href="statistical-process.html#basic-terminology-for-statistical-tests"><i class="fa fa-check"></i><b>1.5</b> Basic Terminology for Statistical Tests</a></li>
<li class="chapter" data-level="1.6" data-path="statistical-process.html"><a href="statistical-process.html#a-note-on-codebooks"><i class="fa fa-check"></i><b>1.6</b> A Note on Codebooks</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="distributional-quartet.html"><a href="distributional-quartet.html"><i class="fa fa-check"></i><b>2</b> Distributional Quartet</a></li>
<li class="chapter" data-level="3" data-path="essential-probability.html"><a href="essential-probability.html"><i class="fa fa-check"></i><b>3</b> Essential Probability</a><ul>
<li class="chapter" data-level="3.1" data-path="essential-probability.html"><a href="essential-probability.html#density-functions-as-models"><i class="fa fa-check"></i><b>3.1</b> Density Functions as Models</a></li>
<li class="chapter" data-level="3.2" data-path="essential-probability.html"><a href="essential-probability.html#summarizing-distributions-parameters"><i class="fa fa-check"></i><b>3.2</b> Summarizing Distributions (Parameters)</a></li>
<li class="chapter" data-level="3.3" data-path="essential-probability.html"><a href="essential-probability.html#specific-models-for-populations"><i class="fa fa-check"></i><b>3.3</b> Specific Models for Populations</a></li>
<li class="chapter" data-level="3.4" data-path="essential-probability.html"><a href="essential-probability.html#models-for-sampling-distributions-and-null-distributions"><i class="fa fa-check"></i><b>3.4</b> Models for Sampling Distributions and Null Distributions</a></li>
</ul></li>
<li class="part"><span><b>II General Linear Model and Modeling Strategies</b></span></li>
<li class="chapter" data-level="4" data-path="glm-framework.html"><a href="glm-framework.html"><i class="fa fa-check"></i><b>4</b> General Linear Model Framework</a><ul>
<li class="chapter" data-level="4.1" data-path="glm-framework.html"><a href="glm-framework.html#parameter-estimation"><i class="fa fa-check"></i><b>4.1</b> Parameter Estimation</a></li>
<li class="chapter" data-level="4.2" data-path="glm-framework.html"><a href="glm-framework.html#conditions-on-the-model"><i class="fa fa-check"></i><b>4.2</b> Conditions on the Model</a></li>
<li class="chapter" data-level="4.3" data-path="glm-framework.html"><a href="glm-framework.html#alternate-characterization-of-the-model"><i class="fa fa-check"></i><b>4.3</b> Alternate Characterization of the Model</a></li>
<li class="chapter" data-level="4.4" data-path="glm-framework.html"><a href="glm-framework.html#interpretations-of-parameters"><i class="fa fa-check"></i><b>4.4</b> Interpretations of Parameters</a></li>
<li class="chapter" data-level="4.5" data-path="glm-framework.html"><a href="glm-framework.html#inference-about-the-mean-parameters"><i class="fa fa-check"></i><b>4.5</b> Inference About the Mean Parameters</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="glm-assessing-conditions.html"><a href="glm-assessing-conditions.html"><i class="fa fa-check"></i><b>5</b> Assessing Conditions</a></li>
<li class="part"><span><b>III General Modeling Techniques</b></span></li>
<li class="chapter" data-level="6" data-path="glm-related-predictors.html"><a href="glm-related-predictors.html"><i class="fa fa-check"></i><b>6</b> Side Effects of Isolating Effects</a><ul>
<li class="chapter" data-level="6.1" data-path="glm-related-predictors.html"><a href="glm-related-predictors.html#toward-causal-inference"><i class="fa fa-check"></i><b>6.1</b> Toward Causal Inference</a></li>
<li class="chapter" data-level="6.2" data-path="glm-related-predictors.html"><a href="glm-related-predictors.html#multicollinearity"><i class="fa fa-check"></i><b>6.2</b> Multicollinearity</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="glm-categorical-predictors.html"><a href="glm-categorical-predictors.html"><i class="fa fa-check"></i><b>7</b> Incorporating Categorical Predictors</a></li>
<li class="chapter" data-level="8" data-path="glm-interactions.html"><a href="glm-interactions.html"><i class="fa fa-check"></i><b>8</b> Interaction Terms (Effect Modification)</a></li>
<li class="chapter" data-level="9" data-path="glm-linear-hypotheses.html"><a href="glm-linear-hypotheses.html"><i class="fa fa-check"></i><b>9</b> General Linear Hypothesis Test</a></li>
<li class="chapter" data-level="10" data-path="glm-large-sample-theory.html"><a href="glm-large-sample-theory.html"><i class="fa fa-check"></i><b>10</b> Large Sample Theory</a><ul>
<li class="chapter" data-level="10.1" data-path="glm-large-sample-theory.html"><a href="glm-large-sample-theory.html#two-types-of-models"><i class="fa fa-check"></i><b>10.1</b> Two Types of Models</a></li>
<li class="chapter" data-level="10.2" data-path="glm-large-sample-theory.html"><a href="glm-large-sample-theory.html#large-sample-results"><i class="fa fa-check"></i><b>10.2</b> Large Sample Results</a></li>
<li class="chapter" data-level="10.3" data-path="glm-large-sample-theory.html"><a href="glm-large-sample-theory.html#residual-bootstrap"><i class="fa fa-check"></i><b>10.3</b> Residual Bootstrap</a></li>
<li class="chapter" data-level="10.4" data-path="glm-large-sample-theory.html"><a href="glm-large-sample-theory.html#big-picture"><i class="fa fa-check"></i><b>10.4</b> Big Picture</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="glm-splines.html"><a href="glm-splines.html"><i class="fa fa-check"></i><b>11</b> Modeling Curvature</a></li>
<li class="part"><span><b>IV Models for Repeated Measures</b></span></li>
<li class="chapter" data-level="12" data-path="rm-terminology.html"><a href="rm-terminology.html"><i class="fa fa-check"></i><b>12</b> Terminology</a><ul>
<li class="chapter" data-level="12.1" data-path="rm-terminology.html"><a href="rm-terminology.html#importance-of-study-design"><i class="fa fa-check"></i><b>12.1</b> Importance of Study Design</a></li>
<li class="chapter" data-level="12.2" data-path="rm-terminology.html"><a href="rm-terminology.html#studies-with-repeated-measures"><i class="fa fa-check"></i><b>12.2</b> Studies with Repeated Measures</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="rm-mixed-models.html"><a href="rm-mixed-models.html"><i class="fa fa-check"></i><b>13</b> Mixed Effects Models</a><ul>
<li class="chapter" data-level="13.1" data-path="rm-mixed-models.html"><a href="rm-mixed-models.html#partitioning-variability"><i class="fa fa-check"></i><b>13.1</b> Partitioning Variability</a></li>
<li class="chapter" data-level="13.2" data-path="rm-mixed-models.html"><a href="rm-mixed-models.html#model-formulation"><i class="fa fa-check"></i><b>13.2</b> Model Formulation</a></li>
<li class="chapter" data-level="13.3" data-path="rm-mixed-models.html"><a href="rm-mixed-models.html#considerations-when-building-a-mixed-effects-model"><i class="fa fa-check"></i><b>13.3</b> Considerations when Building a Mixed-Effects Model</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="rm-gee.html"><a href="rm-gee.html"><i class="fa fa-check"></i><b>14</b> Generalized Estimating Equations</a><ul>
<li class="chapter" data-level="14.1" data-path="rm-gee.html"><a href="rm-gee.html#correlation-structrues"><i class="fa fa-check"></i><b>14.1</b> Correlation Structrues</a></li>
<li class="chapter" data-level="14.2" data-path="rm-gee.html"><a href="rm-gee.html#the-key-to-success-of-generalized-estimating-equations"><i class="fa fa-check"></i><b>14.2</b> The Key to Success of Generalized Estimating Equations</a></li>
<li class="chapter" data-level="14.3" data-path="rm-gee.html"><a href="rm-gee.html#comparison-of-gee-and-mixed-effects-approaches"><i class="fa fa-check"></i><b>14.3</b> Comparison of GEE and Mixed Effects Approaches</a></li>
</ul></li>
<li class="part"><span><b>V Nonlinear Models</b></span></li>
<li class="chapter" data-level="15" data-path="nlm-framework.html"><a href="nlm-framework.html"><i class="fa fa-check"></i><b>15</b> Nonlinear Model Framework</a><ul>
<li class="chapter" data-level="15.1" data-path="nlm-framework.html"><a href="nlm-framework.html#scientific-model-for-theophylline"><i class="fa fa-check"></i><b>15.1</b> Scientific Model for Theophylline</a></li>
<li class="chapter" data-level="15.2" data-path="nlm-framework.html"><a href="nlm-framework.html#nonlinear-regression-model"><i class="fa fa-check"></i><b>15.2</b> Nonlinear Regression Model</a></li>
<li class="chapter" data-level="15.3" data-path="nlm-framework.html"><a href="nlm-framework.html#estimation"><i class="fa fa-check"></i><b>15.3</b> Estimation</a></li>
<li class="chapter" data-level="15.4" data-path="nlm-framework.html"><a href="nlm-framework.html#inference-on-the-parameters"><i class="fa fa-check"></i><b>15.4</b> Inference on the Parameters</a></li>
<li class="chapter" data-level="15.5" data-path="nlm-framework.html"><a href="nlm-framework.html#allowing-relationships-to-vary-across-groups"><i class="fa fa-check"></i><b>15.5</b> Allowing Relationships to Vary Across Groups</a></li>
</ul></li>
<li class="chapter" data-level="16" data-path="nlm-heteroskedasticity.html"><a href="nlm-heteroskedasticity.html"><i class="fa fa-check"></i><b>16</b> Relaxing the Constant Variance Condition</a><ul>
<li class="chapter" data-level="16.1" data-path="nlm-heteroskedasticity.html"><a href="nlm-heteroskedasticity.html#modeling-assumptions"><i class="fa fa-check"></i><b>16.1</b> Modeling Assumptions</a></li>
<li class="chapter" data-level="16.2" data-path="nlm-heteroskedasticity.html"><a href="nlm-heteroskedasticity.html#modeling-the-variance"><i class="fa fa-check"></i><b>16.2</b> Modeling the Variance</a></li>
<li class="chapter" data-level="16.3" data-path="nlm-heteroskedasticity.html"><a href="nlm-heteroskedasticity.html#wild-bootstrap"><i class="fa fa-check"></i><b>16.3</b> Wild Bootstrap</a></li>
</ul></li>
<li class="chapter" data-level="17" data-path="nlm-logistic.html"><a href="nlm-logistic.html"><i class="fa fa-check"></i><b>17</b> Logistic Regression</a><ul>
<li class="chapter" data-level="17.1" data-path="nlm-logistic.html"><a href="nlm-logistic.html#considerations-for-a-binary-response"><i class="fa fa-check"></i><b>17.1</b> Considerations for a Binary Response</a></li>
<li class="chapter" data-level="17.2" data-path="nlm-logistic.html"><a href="nlm-logistic.html#the-logistic-regression-model"><i class="fa fa-check"></i><b>17.2</b> The Logistic Regression Model</a></li>
<li class="chapter" data-level="17.3" data-path="nlm-logistic.html"><a href="nlm-logistic.html#estimation-of-the-parameters"><i class="fa fa-check"></i><b>17.3</b> Estimation of the Parameters</a></li>
<li class="chapter" data-level="17.4" data-path="nlm-framework.html"><a href="nlm-framework.html#inference-on-the-parameters"><i class="fa fa-check"></i><b>17.4</b> Inference on the Parameters</a></li>
<li class="chapter" data-level="17.5" data-path="nlm-logistic.html"><a href="nlm-logistic.html#interpretation-of-parameters"><i class="fa fa-check"></i><b>17.5</b> Interpretation of Parameters</a></li>
</ul></li>
<li class="chapter" data-level="18" data-path="nlm-selection.html"><a href="nlm-selection.html"><i class="fa fa-check"></i><b>18</b> Model Selection</a></li>
<li class="chapter" data-level="19" data-path="nlm-estimation.html"><a href="nlm-estimation.html"><i class="fa fa-check"></i><b>19</b> Estimation Details</a></li>
<li class="chapter" data-level="20" data-path="nlm-rm.html"><a href="nlm-rm.html"><i class="fa fa-check"></i><b>20</b> Nonlinear Models with Repeated Measures</a></li>
<li class="part"><span><b>VI Survival Analysis</b></span></li>
<li class="chapter" data-level="21" data-path="surv-terminology.html"><a href="surv-terminology.html"><i class="fa fa-check"></i><b>21</b> Key Terminolgy</a></li>
<li class="chapter" data-level="22" data-path="surv-censoring.html"><a href="surv-censoring.html"><i class="fa fa-check"></i><b>22</b> Censoring</a></li>
<li class="chapter" data-level="23" data-path="surv-basic.html"><a href="surv-basic.html"><i class="fa fa-check"></i><b>23</b> Basic Estimation and Inference</a><ul>
<li class="chapter" data-level="23.1" data-path="surv-basic.html"><a href="surv-basic.html#life-table-methods"><i class="fa fa-check"></i><b>23.1</b> Life-Table Methods</a></li>
<li class="chapter" data-level="23.2" data-path="surv-basic.html"><a href="surv-basic.html#kaplan-meier-estimation"><i class="fa fa-check"></i><b>23.2</b> Kaplan-Meier Estimation</a></li>
<li class="chapter" data-level="23.3" data-path="surv-basic.html"><a href="surv-basic.html#log-rank-test"><i class="fa fa-check"></i><b>23.3</b> Log-Rank Test</a></li>
</ul></li>
<li class="chapter" data-level="24" data-path="surv-cph.html"><a href="surv-cph.html"><i class="fa fa-check"></i><b>24</b> Cox Proportional Hazards Model</a></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Statistical Modeling for the Biological Sciences</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="rm-mixed-models" class="section level1">
<h1><span class="header-section-number">13</span> Mixed Effects Models</h1>
<p>As we stated in the previous chapter, repeated measures induces a correlation structure on the observed data. Many scientific questions could be answered by modeling the <em>average</em> response while accounting for the correlation structure when making inference. However, other questions may seek to characterize how the parameters vary across subjects in the population. In either case, considering a flexible modeling framework that builds up the data generating in stages can be helpful.</p>
<div id="partitioning-variability" class="section level2">
<h2><span class="header-section-number">13.1</span> Partitioning Variability</h2>
<p>In order to motivate the modeling approach developed in this chapter, we first discuss the various reasons the value of the response is not the same for all observations. By constructing this conceptual framework, we see the various sources of variability and the various ways in which the repeated observations are related with one another. This then allows us to construct a model in stages.</p>

<div class="rmdkeyidea">
Statistical models partition variability in the response.
</div>

<p>We can view regression models as trying to explain why the response values differ across observations. The more reasons we can put in place, the more variability we are able to explain. This allows us to better characterize the differences we observe and more accurately make predictions. There are several sources of variability.</p>
<p>While these ideas generalize to many types of studies, it helps to imagine measuring the response of interest at several points across time for each subject. The observed responses may be expected to differ across time; they may also be expected to differ if they were exposed to different treatment groups or the subjects have different values of a key covariate. For example, the weight of children is expected to change as they age; further, the weight of a child may be expected to differ depending on their height. This is the overall trajectory in the population is typically what we are interested in parameterizing and making inference upon.</p>
<p>Of course, the trajectory of any particular subject (across their repeated observations) will differ from the overall trajectory. At any point in time, a subject may have a trajectory that is above average; others will have a trajectory that is below average. This vertical shift or “bump” in the position of the trajectory captures the biological variation between subjects. Of course, we could constrain whether this shift is allowed to change over time or not. All observations measured on the same subject will share a similar “bump,” creating a relationship between observations.</p>
<p>For any subject, the actual response is likely to not lie directly on their individual trajectory. For example, a child’s growth may not follow a smooth growth-curve even if we model it in that way. This is the result of natural biological fluctuations from the trajectory. A child’s weight on any one day bounces around their trajectory depending on their recent food intake and activity level. As such, observations measured close together in time can tend to be more alike than those measured further apart in time. As an example, if a child’s weight is slightly above their individual trajectory at this moment, it is likely to be above their trajectory an hour from now. However, if a child’s weight is slightly above their individual trajectory at this moment, it does not really tell us anything about whether their weight will be slightly above or below their individual trajectory a year from now. Therefore, magnitudes of this source of variability are thought to be related when close in time and independent otherwise.</p>
<p>Finally, it is unlikely that the observed response is equal to the <em>actual</em> response as a result of measurement error. The weight of a child will be subject to the accuracy and precision of the scale, whether the subject was measured with or without clothing and shoes, etc. The magnitude of such errors are thought to be independent of one another.</p>
<p>This discussion highlights that the “error” we typically consider in a linear model is actually the result of several sources of variability. The above discussion highlights some common beliefs.</p>

<div class="rmdkeyidea">
<p>Observations from the same block (could be subject or other inherent grouping) tend to be high or low (relative to the average) together, incuding a “between-subject” correlation. It is common to think that observations from different blocks are independent.</p>
Observations from within a block recorded close together in time are likely to be related, inducing a “within-subject” correlation. It is common to think that observations far apart in time are independent.
</div>

<p>Taking into account all sources of variability can result in a very complex model (and this continues to be an area of active research). In practice, we can make simplifying assumptions about the data generating process that allows us to rely on a simpler construct. For example, we may assume the data are collected far enough apart in time so that the within-subject correlation is negligible.</p>
</div>
<div id="model-formulation" class="section level2">
<h2><span class="header-section-number">13.2</span> Model Formulation</h2>
<p>Our discussion above illustrates how the various sources of error/variability build on one another to create the observed data. We worked backward; we started with the overall trend and decomposed it to arrive at the data observed. When we model, we work the other direction, building the model in stages. This is known as a hierarchical model.</p>

<div class="definition">
<span id="def:defn-hierarchical-model" class="definition"><strong>Definition 13.1  (Hierarchcial Model)  </strong></span>A model in which is broken into stages defining a hierarchy of units capturing the sources of variability.
</div>

<p>For our purposes, we can consider a hierarchical model that is composed of two stages: the individual and the population. In particular, we first model the trajectory within the individual (the observations within a block); then, we describe how that trajectory changes across individuals in the population (between observations in different blocks).</p>

<div class="definition">
<span id="def:defn-individual-model" class="definition"><strong>Definition 13.2  (Individual-Level Model)  </strong></span>Characterizes the responses for the <span class="math inline">\(i\)</span>-th subject (or block) only.
</div>

<p>We can often think of the individual-level model as the one we would construct if we only had data for a single subject/block. Therefore, this model can only make use of within-individual predictors — those which vary within a subject/block. In biological settings, this is most common when measurements are taken across time; for example, following a child over several years, the height of the child will change. However, it is unlikely that the highest level of education achieved by the child’s parents is likely to change. In that case, the height and time itself would be within-individual predictors, but the education level of the parents would not be.</p>
<p>Consider the <em>Digestive Enzyme</em> Example (<a href="rm-terminology.html#exm:rm-enzyme-expanded">12.2</a>) of the previous chapter. The individual-level model would model the fecal fat observed within a subject; we would expect the responses to differ in part because of the form of the supplement as well as measurement error. This leads to a model of the form</p>
<p><span class="math display">\[(\text{Fecal Fat})_i = \alpha_{0,i} + \alpha_{1,i} (\text{Tablet})_{i,j} + \alpha_{2,i} (\text{Coated})_{i,j} + \alpha_{3,i} (\text{Uncoated})_{i,j} + \varepsilon_{i,j}\]</span></p>
<p>where here <span class="math inline">\(i\)</span> is indexing the subject and <span class="math inline">\(j\)</span> the observation within each subject. It is common to take</p>
<p><span class="math display">\[\varepsilon_{i,j} \iid N\left(0, \sigma^2\right).\]</span></p>
<p>This model makes use of the supplement form because it changes across the observations within a subject; it is an individual-level predictor. What is unique about this model formulation is at this point, the <em>parameters</em> themselves are allowed to vary across subjects. How those vary is determined by the population-level model.</p>

<div class="definition">
<span id="def:defn-population-model" class="definition"><strong>Definition 13.3  (Population-Level Model)  </strong></span>Characterizes how the <em>parameters</em> of the individual-level model vary across subjects/blocks in the population.
</div>

<p>While we do not actually proceed in this way, we can conceptualize this as the model we construct using the estimates from the <span class="math inline">\(i\)</span> individual-level models as responses in a new model. That is, we imagine using the data from each of the <span class="math inline">\(i\)</span> individuals to estimate the individual-level parameters; we will have <span class="math inline">\(i\)</span> different estimates. We then feed these into a model as responses and use the characteristics of the groups to explain why these vary. This second-stage model makes use of among-individual predictors — those which vary across subjects/blocks but are constant for all observations on the same subject/block. Often, these are the treatment groups of interest, with the exception of block designs.</p>
<p>For the <em>Digestive Enzyme</em> example, we want to explain how (if at all) the parameters from the individual-level model vary across the subjects. There is not a single answer, but instead, the model constructed should communicate our beliefs about the data-generating process. Suppose we are willing to believe the following:</p>
<ul>
<li>The delivery of the medication affects each subject in a similar way. That is, if the tablet is best for one subject, we believe it is best for all subjects. And, the only reason it may not appear this way in the observed data is due to random noise (which we captured by <span class="math inline">\(\varepsilon_{i,j}\)</span> in the individual-level model).</li>
<li>The baseline level of fat in each person is fundamentally different. That is, due to diet and genetics etc., each person has a unique level of fat. Some people have more than others, and that varies randomly in the population, but it is centered on some value.</li>
</ul>
<p>Again, we might disagree on whether these two assumptions are appropriate, but once we agree on a set of reasonable assumptions, it guides the model. The first assumption above says that the treatment effects in the individual-level model <span class="math inline">\(\left(\alpha_{1,i}, \alpha_{2,i}, \alpha_{3,i}\right)\)</span> are the same for every individual. The second assumption says that the intercept, the baseline level of fat under the placebo arm, differs across subjects randomly. Putting these together, the population-level model takes the form</p>
<p><span class="math display">\[
\begin{aligned}
  \alpha_{1,i} &amp;= \beta_1 \\
  \alpha_{2,i} &amp;= \beta_2 \\
  \alpha_{3,i} &amp;= \beta_3 \\
  \alpha_{0,i} &amp;= \beta_0 + b_{0, i} \\
  b_{0,i} &amp;\sim N\left(0, \sigma^2_0\right)
\end{aligned}
\]</span></p>
<p>for some unknown <span class="math inline">\(\sigma^2 &gt; 0\)</span>. We are modeling the intercept in the individual-level model as a random component as a result of the subjects; hence the name “random effect.”</p>
<p>While we have describe the individual-level and population-level models, the combination of these is needed to fully explain the data. The idea that some of our effects (coefficients) in a model are fixed (not allowed to vary across individuals) and some are random (allowed to vary across individuals) leads to our description of this model as a mixed-effects model.</p>

<div class="definition">
<span id="def:defn-mixed-effects-model" class="definition"><strong>Definition 13.4  (Mixed Effects Model)  </strong></span>A model which contains both fixed and random effects. Useful for modeling repeated measures from a hierarchical perspective.
</div>

<p>It can be useful to represent the mixed-effects model in a combined model instead of its individual components. For the <em>Digestive Enzyme</em> example, we simply substitute the population-level model into the individual-level model. This results in</p>
<p><span class="math display">\[
\begin{aligned}
  (\text{Fecal Fat})_{i,j} 
    &amp;= \left(\beta_0 + b_{0,i}\right) + \beta_1 (\text{Tablet})_{i,j} + \beta_2 (\text{Coated})_{i,j} + \beta_3 (\text{Uncoated})_{i,j} + \varepsilon_{i,j} \\
  \varepsilon_{i,j} &amp;\iid N\left(0, \sigma^2\right) \\
  b_{0,i} &amp;\iid N\left(0, \sigma^2_0\right).
\end{aligned}
\]</span></p>

<div class="rmdtip">
Specifying the mixed-effects model as a single model can help with specifying the model in statistical software.
</div>


<div class="rmdwarning">
Proper inference in mixed-effects models is debated among statisticians. The two leading statistical software packages (SAS and R) disagree in implementation. SAS provides default p-values for each fixed-effect parameter; R does not.
</div>

<p>Despite the fully parametric nature of a mixed-effect model, inference on the fixed effects is generally carried out using large-sample theory. Generally, we do not test the random effects. Instead, we leave them in the model to capture the correlation we believe is present in the data. As a way of illustrating that incorporating the correlation structure can impact the results, the p-value for comparing the supplement forms went from 0.1682 when we did not account for the correlation to 310^{-4} when we fit the mixed-effects model.</p>
</div>
<div id="considerations-when-building-a-mixed-effects-model" class="section level2">
<h2><span class="header-section-number">13.3</span> Considerations when Building a Mixed-Effects Model</h2>
<p>Constructing a mixed-effects model can feel overwhelming at times. We urge you to keep the following ideas in mind:</p>
<ul>
<li>Construct a model that preserves the behavior at the individual-level. This is generally the stage in which we have more scientific intuition.</li>
<li>All the behavior to vary across subjects, which corresponds to allowing the parameters to vary. Choose which parameters to vary based on discipline expertise.</li>
<li>The variation in the parameters naturally induces a correlation structure in the data.</li>
</ul>
<p>In the above discussion, we considered the error term at the individual-level model to be independent and identically distributed. In theory, we could allow a correlation to exist here as well; for example, we may want observations closer together in time to be correlated. This can dramatically increase the complexity of the model fit and often requires custom software.</p>
<p>When representing data from a repeated-measures study, it is useful to convey the correlation structure in the graphic. This is not always straight-forward. When the number of subjects in the study is not overwhelming, a spaghetti plot can be useful. While we made use of such a plot in the <em>Digestive Enzyme</em> example in the previous chapter, these are particularly useful for studies which follow subjects over time and illustrate the trend.</p>

<div class="definition">
<span id="def:defn-spaghetti-plot" class="definition"><strong>Definition 13.5  (Spaghetti Plot)  </strong></span>A scatterplot that displays the trends within a subject, highlighting the correlation structure by connecting points from the same subject.
</div>

<p>Before closing this chapter, we address the conditions of a mixed-effects model. We have the same conditions on the individual-level model as we do in classical regression models. Further, they can be assessed and relaxed in the same way. However, the conditions on the random effects are not easily assessed. In particular, the distributional assumption of Normality for the random effects is rarely questioned. Bootstrap algorithms for such processes need to be custom-written to take advantage of the hierarchy, and there is ongoing research on the efficacy of this approach.</p>
<p>In this text, our emphasis is on understanding and interpreting such models. Other texts consider the theoretical underpinnings of such model in more detail.</p>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="rm-terminology.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="rm-gee.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": false,
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": null,
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["MA482CourseNotes.pdf"],
"toc": {
"collapse": "section"
},
"toolbar": {
"position": "fixed"
},
"search": true
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
