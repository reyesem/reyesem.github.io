<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>9 General Linear Hypothesis Test | Statistical Modeling for the Biological Sciences</title>
  <meta name="description" content="Course notes for MA482/BE482 (Biostatistics) at Rose-Hulman Institute of Technology." />
  <meta name="generator" content="bookdown 0.20 and GitBook 2.6.7" />

  <meta property="og:title" content="9 General Linear Hypothesis Test | Statistical Modeling for the Biological Sciences" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="Course notes for MA482/BE482 (Biostatistics) at Rose-Hulman Institute of Technology." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="9 General Linear Hypothesis Test | Statistical Modeling for the Biological Sciences" />
  
  <meta name="twitter:description" content="Course notes for MA482/BE482 (Biostatistics) at Rose-Hulman Institute of Technology." />
  

<meta name="author" content="Eric M Reyes" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="glm-interactions.html"/>
<link rel="next" href="glm-large-sample-theory.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<script src="libs/accessible-code-block-0.0.1/empty-anchor.js"></script>
<script src="libs/kePrint-0.0.1/kePrint.js"></script>
<link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet" />



<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Statistical Modeling</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a></li>
<li class="part"><span><b>I Review of the Inferential Process</b></span></li>
<li class="chapter" data-level="1" data-path="statistical-process.html"><a href="statistical-process.html"><i class="fa fa-check"></i><b>1</b> The Statistical Process</a><ul>
<li class="chapter" data-level="1.1" data-path="statistical-process.html"><a href="statistical-process.html#overview-of-drawing-inference"><i class="fa fa-check"></i><b>1.1</b> Overview of Drawing Inference</a></li>
<li class="chapter" data-level="1.2" data-path="statistical-process.html"><a href="statistical-process.html#data-storage"><i class="fa fa-check"></i><b>1.2</b> Data Storage</a></li>
<li class="chapter" data-level="1.3" data-path="statistical-process.html"><a href="statistical-process.html#tabular-data-presentation"><i class="fa fa-check"></i><b>1.3</b> Tabular Data Presentation</a></li>
<li class="chapter" data-level="1.4" data-path="statistical-process.html"><a href="statistical-process.html#graphical-data-presentation"><i class="fa fa-check"></i><b>1.4</b> Graphical Data Presentation</a></li>
<li class="chapter" data-level="1.5" data-path="statistical-process.html"><a href="statistical-process.html#basic-terminology-for-statistical-tests"><i class="fa fa-check"></i><b>1.5</b> Basic Terminology for Statistical Tests</a></li>
<li class="chapter" data-level="1.6" data-path="statistical-process.html"><a href="statistical-process.html#a-note-on-codebooks"><i class="fa fa-check"></i><b>1.6</b> A Note on Codebooks</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="distributional-quartet.html"><a href="distributional-quartet.html"><i class="fa fa-check"></i><b>2</b> Distributional Quartet</a></li>
<li class="chapter" data-level="3" data-path="essential-probability.html"><a href="essential-probability.html"><i class="fa fa-check"></i><b>3</b> Essential Probability</a><ul>
<li class="chapter" data-level="3.1" data-path="essential-probability.html"><a href="essential-probability.html#density-functions-as-models"><i class="fa fa-check"></i><b>3.1</b> Density Functions as Models</a></li>
<li class="chapter" data-level="3.2" data-path="essential-probability.html"><a href="essential-probability.html#summarizing-distributions-parameters"><i class="fa fa-check"></i><b>3.2</b> Summarizing Distributions (Parameters)</a></li>
<li class="chapter" data-level="3.3" data-path="essential-probability.html"><a href="essential-probability.html#specific-models-for-populations"><i class="fa fa-check"></i><b>3.3</b> Specific Models for Populations</a></li>
<li class="chapter" data-level="3.4" data-path="essential-probability.html"><a href="essential-probability.html#models-for-sampling-distributions-and-null-distributions"><i class="fa fa-check"></i><b>3.4</b> Models for Sampling Distributions and Null Distributions</a></li>
</ul></li>
<li class="part"><span><b>II General Linear Model and Modeling Strategies</b></span></li>
<li class="chapter" data-level="4" data-path="glm-framework.html"><a href="glm-framework.html"><i class="fa fa-check"></i><b>4</b> General Linear Model Framework</a><ul>
<li class="chapter" data-level="4.1" data-path="glm-framework.html"><a href="glm-framework.html#parameter-estimation"><i class="fa fa-check"></i><b>4.1</b> Parameter Estimation</a></li>
<li class="chapter" data-level="4.2" data-path="glm-framework.html"><a href="glm-framework.html#conditions-on-the-model"><i class="fa fa-check"></i><b>4.2</b> Conditions on the Model</a></li>
<li class="chapter" data-level="4.3" data-path="glm-framework.html"><a href="glm-framework.html#alternate-characterization-of-the-model"><i class="fa fa-check"></i><b>4.3</b> Alternate Characterization of the Model</a></li>
<li class="chapter" data-level="4.4" data-path="glm-framework.html"><a href="glm-framework.html#interpretations-of-parameters"><i class="fa fa-check"></i><b>4.4</b> Interpretations of Parameters</a></li>
<li class="chapter" data-level="4.5" data-path="glm-framework.html"><a href="glm-framework.html#inference-about-the-mean-parameters"><i class="fa fa-check"></i><b>4.5</b> Inference About the Mean Parameters</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="glm-assessing-conditions.html"><a href="glm-assessing-conditions.html"><i class="fa fa-check"></i><b>5</b> Assessing Conditions</a></li>
<li class="part"><span><b>III General Modeling Techniques</b></span></li>
<li class="chapter" data-level="6" data-path="glm-related-predictors.html"><a href="glm-related-predictors.html"><i class="fa fa-check"></i><b>6</b> Side Effects of Isolating Effects</a><ul>
<li class="chapter" data-level="6.1" data-path="glm-related-predictors.html"><a href="glm-related-predictors.html#toward-causal-inference"><i class="fa fa-check"></i><b>6.1</b> Toward Causal Inference</a></li>
<li class="chapter" data-level="6.2" data-path="glm-related-predictors.html"><a href="glm-related-predictors.html#multicollinearity"><i class="fa fa-check"></i><b>6.2</b> Multicollinearity</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="glm-categorical-predictors.html"><a href="glm-categorical-predictors.html"><i class="fa fa-check"></i><b>7</b> Incorporating Categorical Predictors</a></li>
<li class="chapter" data-level="8" data-path="glm-interactions.html"><a href="glm-interactions.html"><i class="fa fa-check"></i><b>8</b> Interaction Terms (Effect Modification)</a></li>
<li class="chapter" data-level="9" data-path="glm-linear-hypotheses.html"><a href="glm-linear-hypotheses.html"><i class="fa fa-check"></i><b>9</b> General Linear Hypothesis Test</a></li>
<li class="chapter" data-level="10" data-path="glm-large-sample-theory.html"><a href="glm-large-sample-theory.html"><i class="fa fa-check"></i><b>10</b> Large Sample Theory</a><ul>
<li class="chapter" data-level="10.1" data-path="glm-large-sample-theory.html"><a href="glm-large-sample-theory.html#two-types-of-models"><i class="fa fa-check"></i><b>10.1</b> Two Types of Models</a></li>
<li class="chapter" data-level="10.2" data-path="glm-large-sample-theory.html"><a href="glm-large-sample-theory.html#large-sample-results"><i class="fa fa-check"></i><b>10.2</b> Large Sample Results</a></li>
<li class="chapter" data-level="10.3" data-path="glm-large-sample-theory.html"><a href="glm-large-sample-theory.html#residual-bootstrap"><i class="fa fa-check"></i><b>10.3</b> Residual Bootstrap</a></li>
<li class="chapter" data-level="10.4" data-path="glm-large-sample-theory.html"><a href="glm-large-sample-theory.html#big-picture"><i class="fa fa-check"></i><b>10.4</b> Big Picture</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="glm-splines.html"><a href="glm-splines.html"><i class="fa fa-check"></i><b>11</b> Modeling Curvature</a></li>
<li class="part"><span><b>IV Models for Repeated Measures</b></span></li>
<li class="chapter" data-level="12" data-path="rm-terminology.html"><a href="rm-terminology.html"><i class="fa fa-check"></i><b>12</b> Terminology</a><ul>
<li class="chapter" data-level="12.1" data-path="rm-terminology.html"><a href="rm-terminology.html#importance-of-study-design"><i class="fa fa-check"></i><b>12.1</b> Importance of Study Design</a></li>
<li class="chapter" data-level="12.2" data-path="rm-terminology.html"><a href="rm-terminology.html#studies-with-repeated-measures"><i class="fa fa-check"></i><b>12.2</b> Studies with Repeated Measures</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="rm-mixed-models.html"><a href="rm-mixed-models.html"><i class="fa fa-check"></i><b>13</b> Mixed Effects Models</a><ul>
<li class="chapter" data-level="13.1" data-path="rm-mixed-models.html"><a href="rm-mixed-models.html#partitioning-variability"><i class="fa fa-check"></i><b>13.1</b> Partitioning Variability</a></li>
<li class="chapter" data-level="13.2" data-path="rm-mixed-models.html"><a href="rm-mixed-models.html#model-formulation"><i class="fa fa-check"></i><b>13.2</b> Model Formulation</a></li>
<li class="chapter" data-level="13.3" data-path="rm-mixed-models.html"><a href="rm-mixed-models.html#considerations-when-building-a-mixed-effects-model"><i class="fa fa-check"></i><b>13.3</b> Considerations when Building a Mixed-Effects Model</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="rm-gee.html"><a href="rm-gee.html"><i class="fa fa-check"></i><b>14</b> Generalized Estimating Equations</a><ul>
<li class="chapter" data-level="14.1" data-path="rm-gee.html"><a href="rm-gee.html#correlation-structrues"><i class="fa fa-check"></i><b>14.1</b> Correlation Structrues</a></li>
<li class="chapter" data-level="14.2" data-path="rm-gee.html"><a href="rm-gee.html#the-key-to-success-of-generalized-estimating-equations"><i class="fa fa-check"></i><b>14.2</b> The Key to Success of Generalized Estimating Equations</a></li>
<li class="chapter" data-level="14.3" data-path="rm-gee.html"><a href="rm-gee.html#comparison-of-gee-and-mixed-effects-approaches"><i class="fa fa-check"></i><b>14.3</b> Comparison of GEE and Mixed Effects Approaches</a></li>
</ul></li>
<li class="part"><span><b>V Nonlinear Models</b></span></li>
<li class="chapter" data-level="15" data-path="nlm-framework.html"><a href="nlm-framework.html"><i class="fa fa-check"></i><b>15</b> Nonlinear Model Framework</a><ul>
<li class="chapter" data-level="15.1" data-path="nlm-framework.html"><a href="nlm-framework.html#scientific-model-for-theophylline"><i class="fa fa-check"></i><b>15.1</b> Scientific Model for Theophylline</a></li>
<li class="chapter" data-level="15.2" data-path="nlm-framework.html"><a href="nlm-framework.html#nonlinear-regression-model"><i class="fa fa-check"></i><b>15.2</b> Nonlinear Regression Model</a></li>
<li class="chapter" data-level="15.3" data-path="nlm-framework.html"><a href="nlm-framework.html#estimation"><i class="fa fa-check"></i><b>15.3</b> Estimation</a></li>
<li class="chapter" data-level="15.4" data-path="nlm-framework.html"><a href="nlm-framework.html#inference-on-the-parameters"><i class="fa fa-check"></i><b>15.4</b> Inference on the Parameters</a></li>
<li class="chapter" data-level="15.5" data-path="nlm-framework.html"><a href="nlm-framework.html#allowing-relationships-to-vary-across-groups"><i class="fa fa-check"></i><b>15.5</b> Allowing Relationships to Vary Across Groups</a></li>
</ul></li>
<li class="chapter" data-level="16" data-path="nlm-heteroskedasticity.html"><a href="nlm-heteroskedasticity.html"><i class="fa fa-check"></i><b>16</b> Relaxing the Constant Variance Condition</a><ul>
<li class="chapter" data-level="16.1" data-path="nlm-heteroskedasticity.html"><a href="nlm-heteroskedasticity.html#modeling-assumptions"><i class="fa fa-check"></i><b>16.1</b> Modeling Assumptions</a></li>
<li class="chapter" data-level="16.2" data-path="nlm-heteroskedasticity.html"><a href="nlm-heteroskedasticity.html#modeling-the-variance"><i class="fa fa-check"></i><b>16.2</b> Modeling the Variance</a></li>
<li class="chapter" data-level="16.3" data-path="nlm-heteroskedasticity.html"><a href="nlm-heteroskedasticity.html#wild-bootstrap"><i class="fa fa-check"></i><b>16.3</b> Wild Bootstrap</a></li>
</ul></li>
<li class="chapter" data-level="17" data-path="nlm-logistic.html"><a href="nlm-logistic.html"><i class="fa fa-check"></i><b>17</b> Logistic Regression</a><ul>
<li class="chapter" data-level="17.1" data-path="nlm-logistic.html"><a href="nlm-logistic.html#considerations-for-a-binary-response"><i class="fa fa-check"></i><b>17.1</b> Considerations for a Binary Response</a></li>
<li class="chapter" data-level="17.2" data-path="nlm-logistic.html"><a href="nlm-logistic.html#the-logistic-regression-model"><i class="fa fa-check"></i><b>17.2</b> The Logistic Regression Model</a></li>
<li class="chapter" data-level="17.3" data-path="nlm-logistic.html"><a href="nlm-logistic.html#estimation-of-the-parameters"><i class="fa fa-check"></i><b>17.3</b> Estimation of the Parameters</a></li>
<li class="chapter" data-level="17.4" data-path="nlm-framework.html"><a href="nlm-framework.html#inference-on-the-parameters"><i class="fa fa-check"></i><b>17.4</b> Inference on the Parameters</a></li>
<li class="chapter" data-level="17.5" data-path="nlm-logistic.html"><a href="nlm-logistic.html#interpretation-of-parameters"><i class="fa fa-check"></i><b>17.5</b> Interpretation of Parameters</a></li>
</ul></li>
<li class="chapter" data-level="18" data-path="nlm-selection.html"><a href="nlm-selection.html"><i class="fa fa-check"></i><b>18</b> Model Selection</a></li>
<li class="chapter" data-level="19" data-path="nlm-estimation.html"><a href="nlm-estimation.html"><i class="fa fa-check"></i><b>19</b> Estimation Details</a></li>
<li class="chapter" data-level="20" data-path="nlm-rm.html"><a href="nlm-rm.html"><i class="fa fa-check"></i><b>20</b> Nonlinear Models with Repeated Measures</a></li>
<li class="part"><span><b>VI Survival Analysis</b></span></li>
<li class="chapter" data-level="21" data-path="surv-terminology.html"><a href="surv-terminology.html"><i class="fa fa-check"></i><b>21</b> Key Terminolgy</a></li>
<li class="chapter" data-level="22" data-path="surv-censoring.html"><a href="surv-censoring.html"><i class="fa fa-check"></i><b>22</b> Censoring</a></li>
<li class="chapter" data-level="23" data-path="surv-basic.html"><a href="surv-basic.html"><i class="fa fa-check"></i><b>23</b> Basic Estimation and Inference</a><ul>
<li class="chapter" data-level="23.1" data-path="surv-basic.html"><a href="surv-basic.html#life-table-methods"><i class="fa fa-check"></i><b>23.1</b> Life-Table Methods</a></li>
<li class="chapter" data-level="23.2" data-path="surv-basic.html"><a href="surv-basic.html#kaplan-meier-estimation"><i class="fa fa-check"></i><b>23.2</b> Kaplan-Meier Estimation</a></li>
<li class="chapter" data-level="23.3" data-path="surv-basic.html"><a href="surv-basic.html#log-rank-test"><i class="fa fa-check"></i><b>23.3</b> Log-Rank Test</a></li>
</ul></li>
<li class="chapter" data-level="24" data-path="surv-cph.html"><a href="surv-cph.html"><i class="fa fa-check"></i><b>24</b> Cox Proportional Hazards Model</a></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Statistical Modeling for the Biological Sciences</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="glm-linear-hypotheses" class="section level1">
<h1><span class="header-section-number">9</span> General Linear Hypothesis Test</h1>
<p>We previously discussed a model for the sampling distribution of the parameter estimates that allows for making inference on individual parameters; however, we do not yet have a way of testing more complex hypotheses. For example, testing whether the response is associated a categorical predictor involves determining if there is evidence that any of the coefficients associated with the indicator variables differs from zero. Such simultaneous tests fall under the General Linear Hypothesis framework.</p>
<p>While we write hypotheses as statements about parameters, we could also view them as comparisons of alternative models for the response.</p>

<div class="rmdkeyidea">
Hypothesis testing is a way of determining if a simpler model (null hypothesis) is sufficient for explaining the variability in the response or if a more complex model (alternative hypothesis) is necessary. The simpler model is the result of placing <em>constraints</em> on the complex model. Statistical significance is evidence that a more complex model is needed to capture the observed variability.
</div>

<p>The vast majority of scientific questions can be framed as a hypothesis which places a constraint on a more complex model for the data generating process. These constraints can in turn often be written as a linear combination of the parameters.</p>

<div class="rmdtip">
<p>For those less familiar with matrix algebra, a linear combination is simply the product of two vectors, and a series of linear combinations is the product of a matrix and a vector. Let <span class="math inline">\(\bm{K}\)</span> be a 2-by-3 matrix defined as</p>
<p><span class="math display">\[\bm{K} = \begin{pmatrix} 
   K_{1,1} &amp; K_{1,2} &amp; K_{1,3} \\
   K_{2,1} &amp; K_{2,2} &amp; K_{2,3} \end{pmatrix}.\]</span></p>
<p>Let <span class="math inline">\(\bs{\beta}\)</span> be a column vector of length 3 defined as</p>
<p><span class="math display">\[\bs{\beta} = \begin{pmatrix}
   \beta_1 \\
   \beta_2 \\
   \beta_3 \end{pmatrix}.\]</span></p>
<p>The product <span class="math inline">\(\bm{K} \bs{\beta}\)</span> is defined as</p>
<p><span class="math display">\[\bm{K}\bs{\beta} = \begin{pmatrix}
   K_{1,1} \beta_1 + K_{1,2} \beta_2 + K_{1,3} \beta_3 \\
   K_{2,1} \beta_1 + K_{2,2} \beta_2 + K_{2,3} \beta_3 \end{pmatrix}\]</span></p>
which is a vector of length 2. Each element in <span class="math inline">\(\bm{K}\bs{\beta}\)</span> is a linear combination of the elements of <span class="math inline">\(\bs{\beta}\)</span>.
</div>


<div class="definition">
<p><span id="def:defn-general-linear-hypothesis" class="definition"><strong>Definition 9.1  (General Linear Hypothesis)  </strong></span>The general linear hypothesis refers to testing</p>
<p><span class="math display">\[H_0: \bm{K}\bs{\beta} = \bm{m} \qquad \text{vs.} \qquad H_1: \bm{K}\bs{\beta} \neq \bm{m}\]</span></p>
<p>where</p>
<ul>
<li><span class="math inline">\(\bs{\beta}\)</span> is the <span class="math inline">\((p+1)\)</span>-length vector of the parameters (includes the intercept),</li>
<li><span class="math inline">\(\bm{K}\)</span> is an <span class="math inline">\(r\)</span>-by-<span class="math inline">\((p+1)\)</span> matrix that specifies the linear combinations defining the hypothesis of interest, and</li>
<li><span class="math inline">\(\bm{m}\)</span> is a vector of length <span class="math inline">\(r\)</span> specifying the null values, the value of each linear combination under the null hypothesis (often a vector of 0’s).</li>
</ul>
</div>

<p>Before discussing inference for this hypothesis, we discuss the most common use of this framework. Consider the following linear model:</p>
<p><span class="math display">\[(\text{Response})_i = \beta_0 + \beta_1 (\text{Predictor 1})_i + \beta_2 (\text{Predictor 2})_i + \varepsilon_i.\]</span></p>
<p>Suppose we are interested in testing the following hypotheses:</p>
<p><span class="math display">\[H_0: \beta_1 = \beta_2 = 0 \qquad \text{vs.} \qquad H_1: \text{At least one } \beta_j \text{ not equal to 0}.\]</span></p>
<p>To express this in the general linear hypothesis framework, we must identify the matrix <span class="math inline">\(\bm{K}\)</span> and the vector <span class="math inline">\(\bm{m}\)</span>. Note that for this example</p>
<p><span class="math display">\[\bs{\beta} = \begin{pmatrix} 
\beta_0 \\
\beta_1 \\
\beta_2 \end{pmatrix}.\]</span></p>
<p>There are actually several choices for <span class="math inline">\(\bm{K}\)</span>, but we select the most straight-forward:</p>
<p><span class="math display">\[\bm{K} = \begin{pmatrix}
0 &amp; 1 &amp; 0 \\
0 &amp; 0 &amp; 1 \end{pmatrix} \qquad \text{with} \qquad \bm{m} = \begin{pmatrix}
0 \\ 0 \end{pmatrix}.\]</span></p>
<p>That is, the null hypothesis above can be stated as</p>
<p><span class="math display">\[\begin{pmatrix} 0 &amp; 1 &amp; 0 \\ 0 &amp; 0 &amp; 1 \end{pmatrix} \bs{\beta} = \begin{pmatrix} 0 \\ 0 \end{pmatrix}.\]</span></p>

<div class="rmdtip">
When developing the matrix <span class="math inline">\(\bm{K}\)</span>, the number of rows corresponds to the number of equal signs in the null hypothesis.
</div>

<p>The general linear hypothesis allows us to say something about multiple parameters (or combinations of parameters) <em>simultaneously</em>. Each linear combination is not a separate hypothesis; together, they form a “joint” hypothesis. That is, we should think of each linear combination defined by the rows of <span class="math inline">\(\bm{K}\)</span> as “and” statements; we want every statement to be true at the same time. The framework is extremely flexible and can be used across several types of statistical models. It allows us to write the hypotheses compactly, mostly for communicating them to a computer. However, the framework alone does not produce p-values for such tests. In order to obtain a p-value, we need a model for the null distribution. As the hypothesis involve many parameters, we cannot (and should not) test each statement separately.</p>
<p>To fully understand the previous statement requires a background in statistical theory. We hand-wave this by saying that our parameter estimates are related. This is somewhat intuitive. Imagine trying to develop a line that runs through a cloud of points (see Figure <a href="glm-linear-hypotheses.html#fig:glm-linear-hypotheses-line">9.1</a>); if we constrain the line to go through the “middle” of the data (the point represented by the average of the predictor and the average of the response), then changing the slope of the line will necessarily change the intercept of the line. We extend this intuition by claiming that the estimate of one coefficient is related to the estimate of the parameters in a model.</p>
<div class="figure" style="text-align: center"><span id="fig:glm-linear-hypotheses-line"></span>
<img src="images/glm-linear-hypotheses-line-1.png" alt="Illustration of the relationship between parameter estimates." width="80%" />
<p class="caption">
Figure 9.1: Illustration of the relationship between parameter estimates.
</p>
</div>
<p>We know that the standard error is a measure of the variability in an estimate; we could just as easily use their variance (the square of the standard error). A convenient measure of the relationship between the estimates is known as their covariance. We store this information in the variance-covariance matrix.</p>

<div class="definition">
<p><span id="def:defn-variance-covariance-matrix" class="definition"><strong>Definition 9.2  (Variance-Covariance Matrix)  </strong></span>Let <span class="math inline">\(\bs{\beta}\)</span> represent the <span class="math inline">\((p+1)\)</span>-length vector of the parameters and <span class="math inline">\(\widehat{\bs{\beta}}\)</span> represent the <span class="math inline">\((p+1)\)</span> vector of the parameter <em>estimates</em>. The variance-covariance matrix of the parameter estimates is the <span class="math inline">\((p+1)\)</span>-by-<span class="math inline">\((p+1)\)</span> matrix <span class="math inline">\(\bs{\Sigma}\)</span> where</p>
<ul>
<li>the <span class="math inline">\(j\)</span>-th diagonal element contains <span class="math inline">\(Var\left(\widehat{\beta}_j\right)\)</span>, and</li>
<li>the <span class="math inline">\((i,j)\)</span>-th element contains the covariance between <span class="math inline">\(\widehat{\beta}_i\)</span> and <span class="math inline">\(\widehat{\beta}_j\)</span>.</li>
</ul>
</div>

<p>The variance-covariance matrix is an extremely important concept in statistical theory; here, we simply note that it is contains information on the structure of how the estimates are related to one another. We further note that this is computed automatically in most software. We are now in a place to discuss inference for the general linear hypothesis.</p>

<div class="definition">
<p><span id="def:defn-general-linear-hypothesis-null" class="definition"><strong>Definition 9.3  (Model for the Null Distribution with the General Linear Hypothesis)  </strong></span>Let <span class="math inline">\(\widehat{\bs{\beta}}\)</span> be the <span class="math inline">\((p+1)\)</span> vector of estimates for the parameter vector <span class="math inline">\(\bs{\beta}\)</span>, and let the estimates have variance-covariance matrix <span class="math inline">\(\bs{\Sigma}\)</span>. Assuming the null hypothesis</p>
<p><span class="math display">\[H_0: \bm{K} \bs{\beta} = \bm{m}\]</span></p>
<p>is true, under the conditions of the classical regression model</p>
<span class="math display">\[(1/r) \left(\bm{K}\widehat{\bbeta} - \bm{m}\right)^\top \left(\bm{K}\widehat{\bs{\Sigma}}\bm{K}^\top\right)^{-1} \left(\bm{K}\widehat{\bbeta} - \bm{m}\right) \sim F_{r, n-p-1}\]</span>
</div>

<p>Again, the specifics of the above result are not as important as understanding there exists a standardized statistic for which the null distribution can be modeled explicitly, as an F-distribution with <span class="math inline">\(r\)</span> numerator degrees of freedom and <span class="math inline">\(n-p-1\)</span> denominator degrees of freedom. While the denominator degrees of freedom are associated with the scaling term for the residual variance estimate, the numerator degrees of freedom are associated with the complexity of the hypothesis (the number of rows of <span class="math inline">\(\bm{K}\)</span>).</p>
<p>While the theory that provides the above results holds only for the linear model under the classical regression model, the approach we have outlined here will allow us to provide general results which are applicable under many types of regression models.</p>

</div>
            </section>

          </div>
        </div>
      </div>
<a href="glm-interactions.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="glm-large-sample-theory.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": false,
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": null,
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["MA482CourseNotes.pdf"],
"toc": {
"collapse": "section"
},
"toolbar": {
"position": "fixed"
},
"search": true
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
