<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>27 Regression Models for Discrete Responses | Course Notes for Bayesian Data Analysis</title>
  <meta name="description" content="Course notes for MA483 (Bayesian Data Analysis) at Rose-Hulman Institute of Technology." />
  <meta name="generator" content="bookdown 0.24 and GitBook 2.6.7" />

  <meta property="og:title" content="27 Regression Models for Discrete Responses | Course Notes for Bayesian Data Analysis" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="Course notes for MA483 (Bayesian Data Analysis) at Rose-Hulman Institute of Technology." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="27 Regression Models for Discrete Responses | Course Notes for Bayesian Data Analysis" />
  
  <meta name="twitter:description" content="Course notes for MA483 (Bayesian Data Analysis) at Rose-Hulman Institute of Technology." />
  

<meta name="author" content="Eric M Reyes" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="reg-conditions.html"/>
<link rel="next" href="references.html"/>
<script src="libs/header-attrs-2.11/header-attrs.js"></script>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.0.1/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0.1/anchor-sections.js"></script>
<script src="libs/kePrint-0.0.1/kePrint.js"></script>
<link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet" />



<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Bayesian Data Analysis</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a></li>
<li class="chapter" data-level="1" data-path="essential-probability.html"><a href="essential-probability.html"><i class="fa fa-check"></i><b>1</b> Essential Probability</a>
<ul>
<li class="chapter" data-level="1.1" data-path="essential-probability.html"><a href="essential-probability.html#density-functions-as-models"><i class="fa fa-check"></i><b>1.1</b> Density Functions as Models</a></li>
<li class="chapter" data-level="1.2" data-path="essential-probability.html"><a href="essential-probability.html#summarizing-distributions-parameters"><i class="fa fa-check"></i><b>1.2</b> Summarizing Distributions (Parameters)</a>
<ul>
<li class="chapter" data-level="1.2.1" data-path="essential-probability.html"><a href="essential-probability.html#kernels"><i class="fa fa-check"></i><b>1.2.1</b> Kernels</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="essential-probability.html"><a href="essential-probability.html#transformations-of-random-variables"><i class="fa fa-check"></i><b>1.3</b> Transformations of Random Variables</a>
<ul>
<li class="chapter" data-level="1.3.1" data-path="essential-probability.html"><a href="essential-probability.html#expectations-of-functions"><i class="fa fa-check"></i><b>1.3.1</b> Expectations of Functions</a></li>
<li class="chapter" data-level="1.3.2" data-path="essential-probability.html"><a href="essential-probability.html#moment-generating-functions"><i class="fa fa-check"></i><b>1.3.2</b> Moment Generating Functions</a></li>
</ul></li>
<li class="chapter" data-level="1.4" data-path="essential-probability.html"><a href="essential-probability.html#independent-random-variables"><i class="fa fa-check"></i><b>1.4</b> Independent Random Variables</a></li>
</ul></li>
<li class="part"><span><b>I Language and Logic of Inference</b></span></li>
<li class="chapter" data-level="2" data-path="CaseDeepwater.html"><a href="CaseDeepwater.html"><i class="fa fa-check"></i><b>2</b> Case Study: Health Effects of the Deepwater Horizon Oil Spill</a></li>
<li class="chapter" data-level="3" data-path="Basics.html"><a href="Basics.html"><i class="fa fa-check"></i><b>3</b> The Statistical Process</a>
<ul>
<li class="chapter" data-level="3.1" data-path="Basics.html"><a href="Basics.html#overview-of-drawing-inference"><i class="fa fa-check"></i><b>3.1</b> Overview of Drawing Inference</a></li>
<li class="chapter" data-level="3.2" data-path="Basics.html"><a href="Basics.html#anatomy-of-a-dataset"><i class="fa fa-check"></i><b>3.2</b> Anatomy of a Dataset</a></li>
<li class="chapter" data-level="3.3" data-path="Basics.html"><a href="Basics.html#a-note-on-codebooks"><i class="fa fa-check"></i><b>3.3</b> A Note on Codebooks</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="Questions.html"><a href="Questions.html"><i class="fa fa-check"></i><b>4</b> Asking the Right Questions</a>
<ul>
<li class="chapter" data-level="4.1" data-path="Questions.html"><a href="Questions.html#characterizing-a-variable"><i class="fa fa-check"></i><b>4.1</b> Characterizing a Variable</a></li>
<li class="chapter" data-level="4.2" data-path="Questions.html"><a href="Questions.html#framing-the-question"><i class="fa fa-check"></i><b>4.2</b> Framing the Question</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="Data.html"><a href="Data.html"><i class="fa fa-check"></i><b>5</b> Gathering the Evidence (Data Collection)</a>
<ul>
<li class="chapter" data-level="5.1" data-path="Data.html"><a href="Data.html#what-makes-a-sample-reliable"><i class="fa fa-check"></i><b>5.1</b> What Makes a Sample Reliable</a></li>
<li class="chapter" data-level="5.2" data-path="Data.html"><a href="Data.html#poor-methods-of-data-collection"><i class="fa fa-check"></i><b>5.2</b> Poor Methods of Data Collection</a></li>
<li class="chapter" data-level="5.3" data-path="Data.html"><a href="Data.html#preferred-methods-of-sampling"><i class="fa fa-check"></i><b>5.3</b> Preferred Methods of Sampling</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="Summaries.html"><a href="Summaries.html"><i class="fa fa-check"></i><b>6</b> Presenting the Evidence (Summarizing Data)</a>
<ul>
<li class="chapter" data-level="6.1" data-path="Summaries.html"><a href="Summaries.html#characteristics-of-a-distribution-summarizing-a-single-variable"><i class="fa fa-check"></i><b>6.1</b> Characteristics of a Distribution (Summarizing a Single Variable)</a></li>
<li class="chapter" data-level="6.2" data-path="Summaries.html"><a href="Summaries.html#summarizing-relationships"><i class="fa fa-check"></i><b>6.2</b> Summarizing Relationships</a></li>
</ul></li>
<li class="part"><span><b>II Fundamentals of Bayesian Inference</b></span></li>
<li class="chapter" data-level="7" data-path="bayes-rule.html"><a href="bayes-rule.html"><i class="fa fa-check"></i><b>7</b> Bayes Rule</a>
<ul>
<li class="chapter" data-level="7.1" data-path="bayes-rule.html"><a href="bayes-rule.html#tenants-of-the-bayesian-approach-to-inference"><i class="fa fa-check"></i><b>7.1</b> Tenants of the Bayesian Approach to Inference</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="modeling-samples.html"><a href="modeling-samples.html"><i class="fa fa-check"></i><b>8</b> Modeling Samples</a>
<ul>
<li class="chapter" data-level="8.1" data-path="modeling-samples.html"><a href="modeling-samples.html#independence"><i class="fa fa-check"></i><b>8.1</b> Independence</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="quantifying-prior-information.html"><a href="quantifying-prior-information.html"><i class="fa fa-check"></i><b>9</b> Quantifying Prior Information</a></li>
<li class="chapter" data-level="10" data-path="posterior-distributions.html"><a href="posterior-distributions.html"><i class="fa fa-check"></i><b>10</b> Updating Prior Beliefs (Posterior Distributions)</a></li>
<li class="chapter" data-level="11" data-path="point-estimation.html"><a href="point-estimation.html"><i class="fa fa-check"></i><b>11</b> Point Estimation</a></li>
<li class="chapter" data-level="12" data-path="interval-estimation.html"><a href="interval-estimation.html"><i class="fa fa-check"></i><b>12</b> Interval Estimation</a></li>
<li class="chapter" data-level="13" data-path="prediction.html"><a href="prediction.html"><i class="fa fa-check"></i><b>13</b> Prediction</a>
<ul>
<li class="chapter" data-level="13.1" data-path="prediction.html"><a href="prediction.html#derivation-of-the-posterior-predictive"><i class="fa fa-check"></i><b>13.1</b> Derivation of the Posterior Predictive</a></li>
<li class="chapter" data-level="13.2" data-path="prediction.html"><a href="prediction.html#summary"><i class="fa fa-check"></i><b>13.2</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html"><i class="fa fa-check"></i><b>14</b> Hypothesis Testing</a>
<ul>
<li class="chapter" data-level="14.1" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#point-null-hypotheses"><i class="fa fa-check"></i><b>14.1</b> Point-Null Hypotheses</a></li>
<li class="chapter" data-level="14.2" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#model-comparison"><i class="fa fa-check"></i><b>14.2</b> Model Comparison</a></li>
</ul></li>
<li class="chapter" data-level="15" data-path="constructing-priors.html"><a href="constructing-priors.html"><i class="fa fa-check"></i><b>15</b> Constructing Prior Distributions</a>
<ul>
<li class="chapter" data-level="15.1" data-path="constructing-priors.html"><a href="constructing-priors.html#elicitation-from-experts"><i class="fa fa-check"></i><b>15.1</b> Elicitation from Experts</a></li>
<li class="chapter" data-level="15.2" data-path="constructing-priors.html"><a href="constructing-priors.html#mixtures"><i class="fa fa-check"></i><b>15.2</b> Mixtures</a></li>
<li class="chapter" data-level="15.3" data-path="constructing-priors.html"><a href="constructing-priors.html#chains"><i class="fa fa-check"></i><b>15.3</b> Chains</a></li>
<li class="chapter" data-level="15.4" data-path="constructing-priors.html"><a href="constructing-priors.html#non-informative-priors"><i class="fa fa-check"></i><b>15.4</b> Non-Informative Priors</a></li>
</ul></li>
<li class="part"><span><b>III Numerical Approaches to Bayesian Computations</b></span></li>
<li class="chapter" data-level="16" data-path="mc-integration.html"><a href="mc-integration.html"><i class="fa fa-check"></i><b>16</b> Monte Carlo Integration</a></li>
<li class="chapter" data-level="17" data-path="mcmc.html"><a href="mcmc.html"><i class="fa fa-check"></i><b>17</b> Markov Chain Monte Carlo</a>
<ul>
<li class="chapter" data-level="17.1" data-path="mcmc.html"><a href="mcmc.html#hamiltonian-monte-carlo"><i class="fa fa-check"></i><b>17.1</b> Hamiltonian Monte Carlo</a></li>
</ul></li>
<li class="chapter" data-level="18" data-path="mcmc-assessment.html"><a href="mcmc-assessment.html"><i class="fa fa-check"></i><b>18</b> Assessing MCMC Samples</a></li>
<li class="part"><span><b>IV Hierarchical Models Comparing Groups</b></span></li>
<li class="chapter" data-level="19" data-path="study-design.html"><a href="study-design.html"><i class="fa fa-check"></i><b>19</b> Elements of Good Study Design</a></li>
<li class="chapter" data-level="20" data-path="independent-groups.html"><a href="independent-groups.html"><i class="fa fa-check"></i><b>20</b> Models for Comparing Independent Groups</a>
<ul>
<li class="chapter" data-level="20.1" data-path="independent-groups.html"><a href="independent-groups.html#bridge-sampling"><i class="fa fa-check"></i><b>20.1</b> Bridge Sampling</a></li>
</ul></li>
<li class="chapter" data-level="21" data-path="dependent-groups.html"><a href="dependent-groups.html"><i class="fa fa-check"></i><b>21</b> Comparing Related Groups</a></li>
<li class="part"><span><b>V Overview of Regression Modeling</b></span></li>
<li class="chapter" data-level="22" data-path="linear-regression.html"><a href="linear-regression.html"><i class="fa fa-check"></i><b>22</b> Regression Models for a Quantitative Response</a>
<ul>
<li class="chapter" data-level="22.1" data-path="linear-regression.html"><a href="linear-regression.html#developing-a-model"><i class="fa fa-check"></i><b>22.1</b> Developing a Model</a></li>
<li class="chapter" data-level="22.2" data-path="linear-regression.html"><a href="linear-regression.html#note-on-predictors"><i class="fa fa-check"></i><b>22.2</b> Note on Predictors</a></li>
<li class="chapter" data-level="22.3" data-path="linear-regression.html"><a href="linear-regression.html#interpreting-the-predictors"><i class="fa fa-check"></i><b>22.3</b> Interpreting the Predictors</a></li>
</ul></li>
<li class="chapter" data-level="23" data-path="reg-extensions.html"><a href="reg-extensions.html"><i class="fa fa-check"></i><b>23</b> Extensions to the Linear Model</a>
<ul>
<li class="chapter" data-level="23.1" data-path="reg-extensions.html"><a href="reg-extensions.html#including-categorical-predictors"><i class="fa fa-check"></i><b>23.1</b> Including Categorical Predictors</a></li>
<li class="chapter" data-level="23.2" data-path="reg-extensions.html"><a href="reg-extensions.html#curvature"><i class="fa fa-check"></i><b>23.2</b> Curvature</a></li>
</ul></li>
<li class="chapter" data-level="24" data-path="reg-priors.html"><a href="reg-priors.html"><i class="fa fa-check"></i><b>24</b> Default Priors</a></li>
<li class="chapter" data-level="25" data-path="qr-factorization.html"><a href="qr-factorization.html"><i class="fa fa-check"></i><b>25</b> QR Factorization</a></li>
<li class="chapter" data-level="26" data-path="reg-conditions.html"><a href="reg-conditions.html"><i class="fa fa-check"></i><b>26</b> Assessing a Mean Model</a></li>
<li class="chapter" data-level="27" data-path="discrete-response.html"><a href="discrete-response.html"><i class="fa fa-check"></i><b>27</b> Regression Models for Discrete Responses</a>
<ul>
<li class="chapter" data-level="27.1" data-path="discrete-response.html"><a href="discrete-response.html#considerations-for-a-binary-response"><i class="fa fa-check"></i><b>27.1</b> Considerations for a Binary Response</a></li>
<li class="chapter" data-level="27.2" data-path="discrete-response.html"><a href="discrete-response.html#considerations-for-count-data"><i class="fa fa-check"></i><b>27.2</b> Considerations for Count Data</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Course Notes for Bayesian Data Analysis</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="discrete-response" class="section level1" number="27">
<h1><span class="header-section-number">27</span> Regression Models for Discrete Responses</h1>
<p>On the one hand, modeling a categorical response (discrete distribution) is no different than modeling a quantitative response (continuous distribution). In both cases, we specify a distribution, and we allow one or more parameters to vary across individuals based on their predictors through some pre-specified function. On the other hand, the modeling is quite different as there are often more pitfalls to be aware of. In particular, we are no longer in a position to think of the model as</p>
<p><span class="math display">\[(\text{Response})_i = (\text{Signal})_i + (\text{Noise})_i.\]</span></p>
<p>As an example, if the response is binary, what type of noise could be added to “jitter” the response? The response must always be a 0 or 1 in that case, meaning thinking of it as a “jittered” signal seems somehow inauthentic. The key to extending the regression model to categorical response variables is to view regression as an extension as a more complex specification of the conditional response.</p>
<div id="considerations-for-a-binary-response" class="section level2" number="27.1">
<h2><span class="header-section-number">27.1</span> Considerations for a Binary Response</h2>
<p>Suppose our response is binary, taking the value 1 when an event of interest occurs (a “success”) and taking the value 0 when the event does not occur (a “failure”). A starting point for this model is</p>
<p><span class="math display">\[(\text{Response})_i \stackrel{\text{Ind}}{\sim}Ber\left(\theta_i\right)\]</span></p>
<p>where we are allowing the probability of success <span class="math inline">\(\theta_i\)</span> to potentially vary from one observation to the next. This model continues to assume the response from one individual is independent of the response from any other individual. Our initial attempt at generalizing to a regression setting may be to borrow the linear model structure of previous sections and consider</p>
<p><span class="math display">\[\theta_i = \beta_0 + \sum_{j=1}^{p} \beta_j (\text{Predictor } j)_i.\]</span></p>
<p>Unfortunately, this can be a poor strategy. Notice that there is nothing ensuring that this linear function produces values of <span class="math inline">\(\theta_i\)</span> which are consistent with its support. That is, we know that since <span class="math inline">\(\theta_i\)</span> is a probability, its support is the interval <span class="math inline">\((0, 1)\)</span>. The linear function, however, could quite easily produce values which are negative or exceed 1; instead, we desire a function that is always bounded between 0 and 1 (see Figure <a href="discrete-response.html#fig:logistic-regression">27.1</a>).</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:logistic-regression"></span>
<img src="images/logistic-regression-1.png" alt="Comparison of two functional forms of a single predictor for the success probability in a regression for a binary response." width="672" />
<p class="caption">
Figure 27.1: Comparison of two functional forms of a single predictor for the success probability in a regression for a binary response.
</p>
</div>
<p>One of the most common choices for the functional form is the <em>logistic function</em>.</p>
<div class="definition">
<p><span id="def:defn-logistic-regression" class="definition"><strong>Definition 27.1  (Logistic Regression) </strong></span>Given a binary response; logistic regression assumes that</p>
<p><span class="math display">\[\begin{aligned}
  (\text{Response})_i \mid (\text{Predictors})_i, \boldsymbol{\beta} &amp;\stackrel{\text{Ind}}{\sim}Ber\left(\theta_i\right) \\
  \theta_i = \frac{e^{\beta_0 + \sum_{j=1}^{p} \beta_j (\text{Predictor } j)_i}}{1 + e^{\beta_0 + \sum_{j=1}^{p} \beta_j (\text{Predictor } j)_i}}
\end{aligned}\]</span></p>
</div>
<p>This is known as logistic regression because the functional form of the probability matches that of the CDF of the Standard Logistic Distribution:</p>
<p><span class="math display">\[\frac{e^x}{1+e^{x}}.\]</span></p>
<div class="rmdtip">
<p>When performing a regression with a binary response, any CDF could be used for the functional form; the Standard Logistic (“logistic regression”) and Standard Normal (“probit regression”) distributions are most common.</p>
</div>
<p>Using a CDF for the functional form ensures that for any choice of <span class="math inline">\(\boldsymbol{\beta}\)</span>, the function will always take a value between 0 and 1. Notice that our choice of <span class="math inline">\(\theta_i\)</span> is <em>nonlinear</em> in the parameters <span class="math inline">\(\boldsymbol{\beta}\)</span>; however, it still has that feel of a linear model because of the <em>linear predictor</em></p>
<p><span class="math display">\[\beta_0 + \sum_{j=1}^{p} \beta_j (\text{Predictor } j)_i.\]</span></p>
<p>Nothing prohibits us from considering a nonlinear function instead of the linear predictor; it is just common practice to use the linear predictor, as we have already seen it is flexible enough to accommodate categorical predictors and curvature.</p>
<p>For a logistic regression, the <span class="math inline">\(j\)</span>-th coefficient <span class="math inline">\(\beta_j\)</span> is the log odds ratio of the response occurring when the <span class="math inline">\(j\)</span>-th predictor is increased by one unit compared to its current value, holding all other predictors fixed. For probit regression, the <span class="math inline">\(j\)</span>-th coefficient <span class="math inline">\(\beta_j\)</span> has no intuitive interpretation (hence the popularity of logistic regression).</p>
</div>
<div id="considerations-for-count-data" class="section level2" number="27.2">
<h2><span class="header-section-number">27.2</span> Considerations for Count Data</h2>
<p>As in the binary response setting, we take care to ensure that the functional form relating the predictors to key parameters in the conditional distribution of the response enforces constraints on the support.</p>
<p>Consider a response which counts the number of successes out of a fixed number of trials. We might consider a model of the form</p>
<p><span class="math display">\[\begin{aligned}
(\text{Response})_i \mid (\text{Predictors})_i, \boldsymbol{\beta} &amp;\stackrel{\text{Ind}}{\sim}Bin\left(m_i, \theta_i\right) \\
\log\left(\frac{\theta_i}{1-\theta_i}\right) &amp;= \beta_0 + \sum_{j=1}^{p} \beta_j (\text{Predictor } j)_i.
\end{aligned}\]</span></p>
<p>While we have written this in a slightly different form, we are using the same functional form for linking the response probability to the predictors; here, we have written it in terms of the <em>link function</em>.</p>
<div class="definition">
<p><span id="def:defn-link-function" class="definition"><strong>Definition 27.2  (Link Function) </strong></span>The functional form “linking” the linear predictor</p>
<p><span class="math display">\[\beta_0 + \sum_{j=1}^{p} \beta_j (\text{Predictor } j)_i\]</span></p>
<p>to the mean response of the model in a regression model. In particular, it is the function <span class="math inline">\(g\)</span> such that</p>
<p><span class="math display">\[g\left(\theta_i\right) = \beta_0 + \sum_{j=1}^{p} \beta_j (\text{Predictor } j)_i.\]</span></p>
</div>
<p>The logistic distribution function is chosen since <span class="math inline">\(\theta_i\)</span> should be constrained to the interval <span class="math inline">\((0, 1)\)</span>. Notice that the logit link (inverse of the logistic CDF function) does not specify the mean response directly; instead, it is simply used to link the predictors to the mean response such that</p>
<p><span class="math display">\[E\left[(\text{Response}) \mid (\text{Predictors}), \boldsymbol{\beta}\right] = m  \frac{e^{\beta_0 + \sum_{j=1}^{p} \beta_j (\text{Predictor } j)}}{1 + e^{\beta_0 + \sum_{j=1}^{p} \beta_j (\text{Predictor } j)}}\]</span></p>
<p>where <span class="math inline">\(m\)</span> is the number of trials.</p>
<div class="rmdtip">
<p>Any distribution for which the mean response is defined through the “success” probability could potentially make use of the logit link: Bernoulli, Binomial, Geometric.</p>
</div>
<p>The Poisson distribution is common for modeling the number of rare events in a large population, or for arbitrary counts that have no upper bound. Extending this into a regression model generally takes the form</p>
<p><span class="math display">\[\begin{aligned}
(\text{Response})_i \mid (\text{Predictors})_i, \boldsymbol{\beta} &amp;\stackrel{\text{Ind}}{\sim}Poisson\left(\lambda_i\right) \\
\log\left(\lambda_i\right) &amp;= \beta_0 + \sum_{j=1}^{p} \beta_j (\text{Predictor } j)_i.
\end{aligned}\]</span></p>
<p>The log link function is chosen to ensure that <span class="math inline">\(\lambda &gt; 0\)</span> for all possible choice of the parameter vector <span class="math inline">\(\boldsymbol{\beta}\)</span>.</p>
<p>In all of the cases considered in this chapter, the model specifies the mean response; however, it also specifies the variability in the response. These distributional models are unique in that knowing the mean response uniquely determines the variability in the response. Occasionally, we come across data for which the response behaves <em>nearly</em> like one of these distributions; however, additional variability is present. There are ways of generalizing these models to account for this additional dispersion.</p>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="reg-conditions.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="references.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": false,
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": null,
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "section"
},
"toolbar": {
"position": "fixed"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
