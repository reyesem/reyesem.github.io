<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>9 Quantifying Prior Information | Course Notes for Bayesian Data Analysis</title>
  <meta name="description" content="Course notes for MA483 (Bayesian Data Analysis) at Rose-Hulman Institute of Technology." />
  <meta name="generator" content="bookdown 0.24 and GitBook 2.6.7" />

  <meta property="og:title" content="9 Quantifying Prior Information | Course Notes for Bayesian Data Analysis" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="Course notes for MA483 (Bayesian Data Analysis) at Rose-Hulman Institute of Technology." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="9 Quantifying Prior Information | Course Notes for Bayesian Data Analysis" />
  
  <meta name="twitter:description" content="Course notes for MA483 (Bayesian Data Analysis) at Rose-Hulman Institute of Technology." />
  

<meta name="author" content="Eric M Reyes" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="modeling-samples.html"/>
<link rel="next" href="posterior-distributions.html"/>
<script src="libs/header-attrs-2.11/header-attrs.js"></script>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.0.1/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0.1/anchor-sections.js"></script>
<script src="libs/kePrint-0.0.1/kePrint.js"></script>
<link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet" />



<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Bayesian Data Analysis</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a></li>
<li class="chapter" data-level="1" data-path="essential-probability.html"><a href="essential-probability.html"><i class="fa fa-check"></i><b>1</b> Essential Probability</a>
<ul>
<li class="chapter" data-level="1.1" data-path="essential-probability.html"><a href="essential-probability.html#density-functions-as-models"><i class="fa fa-check"></i><b>1.1</b> Density Functions as Models</a></li>
<li class="chapter" data-level="1.2" data-path="essential-probability.html"><a href="essential-probability.html#summarizing-distributions-parameters"><i class="fa fa-check"></i><b>1.2</b> Summarizing Distributions (Parameters)</a>
<ul>
<li class="chapter" data-level="1.2.1" data-path="essential-probability.html"><a href="essential-probability.html#kernels"><i class="fa fa-check"></i><b>1.2.1</b> Kernels</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="essential-probability.html"><a href="essential-probability.html#transformations-of-random-variables"><i class="fa fa-check"></i><b>1.3</b> Transformations of Random Variables</a>
<ul>
<li class="chapter" data-level="1.3.1" data-path="essential-probability.html"><a href="essential-probability.html#expectations-of-functions"><i class="fa fa-check"></i><b>1.3.1</b> Expectations of Functions</a></li>
<li class="chapter" data-level="1.3.2" data-path="essential-probability.html"><a href="essential-probability.html#moment-generating-functions"><i class="fa fa-check"></i><b>1.3.2</b> Moment Generating Functions</a></li>
</ul></li>
<li class="chapter" data-level="1.4" data-path="essential-probability.html"><a href="essential-probability.html#independent-random-variables"><i class="fa fa-check"></i><b>1.4</b> Independent Random Variables</a></li>
</ul></li>
<li class="part"><span><b>I Language and Logic of Inference</b></span></li>
<li class="chapter" data-level="2" data-path="CaseDeepwater.html"><a href="CaseDeepwater.html"><i class="fa fa-check"></i><b>2</b> Case Study: Health Effects of the Deepwater Horizon Oil Spill</a></li>
<li class="chapter" data-level="3" data-path="Basics.html"><a href="Basics.html"><i class="fa fa-check"></i><b>3</b> The Statistical Process</a>
<ul>
<li class="chapter" data-level="3.1" data-path="Basics.html"><a href="Basics.html#overview-of-drawing-inference"><i class="fa fa-check"></i><b>3.1</b> Overview of Drawing Inference</a></li>
<li class="chapter" data-level="3.2" data-path="Basics.html"><a href="Basics.html#anatomy-of-a-dataset"><i class="fa fa-check"></i><b>3.2</b> Anatomy of a Dataset</a></li>
<li class="chapter" data-level="3.3" data-path="Basics.html"><a href="Basics.html#a-note-on-codebooks"><i class="fa fa-check"></i><b>3.3</b> A Note on Codebooks</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="Questions.html"><a href="Questions.html"><i class="fa fa-check"></i><b>4</b> Asking the Right Questions</a>
<ul>
<li class="chapter" data-level="4.1" data-path="Questions.html"><a href="Questions.html#characterizing-a-variable"><i class="fa fa-check"></i><b>4.1</b> Characterizing a Variable</a></li>
<li class="chapter" data-level="4.2" data-path="Questions.html"><a href="Questions.html#framing-the-question"><i class="fa fa-check"></i><b>4.2</b> Framing the Question</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="Data.html"><a href="Data.html"><i class="fa fa-check"></i><b>5</b> Gathering the Evidence (Data Collection)</a>
<ul>
<li class="chapter" data-level="5.1" data-path="Data.html"><a href="Data.html#what-makes-a-sample-reliable"><i class="fa fa-check"></i><b>5.1</b> What Makes a Sample Reliable</a></li>
<li class="chapter" data-level="5.2" data-path="Data.html"><a href="Data.html#poor-methods-of-data-collection"><i class="fa fa-check"></i><b>5.2</b> Poor Methods of Data Collection</a></li>
<li class="chapter" data-level="5.3" data-path="Data.html"><a href="Data.html#preferred-methods-of-sampling"><i class="fa fa-check"></i><b>5.3</b> Preferred Methods of Sampling</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="Summaries.html"><a href="Summaries.html"><i class="fa fa-check"></i><b>6</b> Presenting the Evidence (Summarizing Data)</a>
<ul>
<li class="chapter" data-level="6.1" data-path="Summaries.html"><a href="Summaries.html#characteristics-of-a-distribution-summarizing-a-single-variable"><i class="fa fa-check"></i><b>6.1</b> Characteristics of a Distribution (Summarizing a Single Variable)</a></li>
<li class="chapter" data-level="6.2" data-path="Summaries.html"><a href="Summaries.html#summarizing-relationships"><i class="fa fa-check"></i><b>6.2</b> Summarizing Relationships</a></li>
</ul></li>
<li class="part"><span><b>II Fundamentals of Bayesian Inference</b></span></li>
<li class="chapter" data-level="7" data-path="bayes-rule.html"><a href="bayes-rule.html"><i class="fa fa-check"></i><b>7</b> Bayes Rule</a>
<ul>
<li class="chapter" data-level="7.1" data-path="bayes-rule.html"><a href="bayes-rule.html#tenants-of-the-bayesian-approach-to-inference"><i class="fa fa-check"></i><b>7.1</b> Tenants of the Bayesian Approach to Inference</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="modeling-samples.html"><a href="modeling-samples.html"><i class="fa fa-check"></i><b>8</b> Modeling Samples</a>
<ul>
<li class="chapter" data-level="8.1" data-path="modeling-samples.html"><a href="modeling-samples.html#independence"><i class="fa fa-check"></i><b>8.1</b> Independence</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="quantifying-prior-information.html"><a href="quantifying-prior-information.html"><i class="fa fa-check"></i><b>9</b> Quantifying Prior Information</a></li>
<li class="chapter" data-level="10" data-path="posterior-distributions.html"><a href="posterior-distributions.html"><i class="fa fa-check"></i><b>10</b> Updating Prior Beliefs (Posterior Distributions)</a></li>
<li class="chapter" data-level="11" data-path="point-estimation.html"><a href="point-estimation.html"><i class="fa fa-check"></i><b>11</b> Point Estimation</a></li>
<li class="chapter" data-level="12" data-path="interval-estimation.html"><a href="interval-estimation.html"><i class="fa fa-check"></i><b>12</b> Interval Estimation</a></li>
<li class="chapter" data-level="13" data-path="prediction.html"><a href="prediction.html"><i class="fa fa-check"></i><b>13</b> Prediction</a>
<ul>
<li class="chapter" data-level="13.1" data-path="prediction.html"><a href="prediction.html#derivation-of-the-posterior-predictive"><i class="fa fa-check"></i><b>13.1</b> Derivation of the Posterior Predictive</a></li>
<li class="chapter" data-level="13.2" data-path="prediction.html"><a href="prediction.html#summary"><i class="fa fa-check"></i><b>13.2</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html"><i class="fa fa-check"></i><b>14</b> Hypothesis Testing</a>
<ul>
<li class="chapter" data-level="14.1" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#point-null-hypotheses"><i class="fa fa-check"></i><b>14.1</b> Point-Null Hypotheses</a></li>
<li class="chapter" data-level="14.2" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#model-comparison"><i class="fa fa-check"></i><b>14.2</b> Model Comparison</a></li>
</ul></li>
<li class="chapter" data-level="15" data-path="constructing-priors.html"><a href="constructing-priors.html"><i class="fa fa-check"></i><b>15</b> Constructing Prior Distributions</a>
<ul>
<li class="chapter" data-level="15.1" data-path="constructing-priors.html"><a href="constructing-priors.html#elicitation-from-experts"><i class="fa fa-check"></i><b>15.1</b> Elicitation from Experts</a></li>
<li class="chapter" data-level="15.2" data-path="constructing-priors.html"><a href="constructing-priors.html#mixtures"><i class="fa fa-check"></i><b>15.2</b> Mixtures</a></li>
<li class="chapter" data-level="15.3" data-path="constructing-priors.html"><a href="constructing-priors.html#chains"><i class="fa fa-check"></i><b>15.3</b> Chains</a></li>
<li class="chapter" data-level="15.4" data-path="constructing-priors.html"><a href="constructing-priors.html#non-informative-priors"><i class="fa fa-check"></i><b>15.4</b> Non-Informative Priors</a></li>
</ul></li>
<li class="part"><span><b>III Numerical Approaches to Bayesian Computations</b></span></li>
<li class="chapter" data-level="16" data-path="mc-integration.html"><a href="mc-integration.html"><i class="fa fa-check"></i><b>16</b> Monte Carlo Integration</a></li>
<li class="chapter" data-level="17" data-path="mcmc.html"><a href="mcmc.html"><i class="fa fa-check"></i><b>17</b> Markov Chain Monte Carlo</a>
<ul>
<li class="chapter" data-level="17.1" data-path="mcmc.html"><a href="mcmc.html#hamiltonian-monte-carlo"><i class="fa fa-check"></i><b>17.1</b> Hamiltonian Monte Carlo</a></li>
</ul></li>
<li class="chapter" data-level="18" data-path="mcmc-assessment.html"><a href="mcmc-assessment.html"><i class="fa fa-check"></i><b>18</b> Assessing MCMC Samples</a></li>
<li class="part"><span><b>IV Hierarchical Models Comparing Groups</b></span></li>
<li class="chapter" data-level="19" data-path="study-design.html"><a href="study-design.html"><i class="fa fa-check"></i><b>19</b> Elements of Good Study Design</a></li>
<li class="chapter" data-level="20" data-path="independent-groups.html"><a href="independent-groups.html"><i class="fa fa-check"></i><b>20</b> Models for Comparing Independent Groups</a>
<ul>
<li class="chapter" data-level="20.1" data-path="independent-groups.html"><a href="independent-groups.html#bridge-sampling"><i class="fa fa-check"></i><b>20.1</b> Bridge Sampling</a></li>
</ul></li>
<li class="chapter" data-level="21" data-path="dependent-groups.html"><a href="dependent-groups.html"><i class="fa fa-check"></i><b>21</b> Comparing Related Groups</a></li>
<li class="part"><span><b>V Overview of Regression Modeling</b></span></li>
<li class="chapter" data-level="22" data-path="linear-regression.html"><a href="linear-regression.html"><i class="fa fa-check"></i><b>22</b> Regression Models for a Quantitative Response</a>
<ul>
<li class="chapter" data-level="22.1" data-path="linear-regression.html"><a href="linear-regression.html#developing-a-model"><i class="fa fa-check"></i><b>22.1</b> Developing a Model</a></li>
<li class="chapter" data-level="22.2" data-path="linear-regression.html"><a href="linear-regression.html#note-on-predictors"><i class="fa fa-check"></i><b>22.2</b> Note on Predictors</a></li>
<li class="chapter" data-level="22.3" data-path="linear-regression.html"><a href="linear-regression.html#interpreting-the-predictors"><i class="fa fa-check"></i><b>22.3</b> Interpreting the Predictors</a></li>
</ul></li>
<li class="chapter" data-level="23" data-path="reg-extensions.html"><a href="reg-extensions.html"><i class="fa fa-check"></i><b>23</b> Extensions to the Linear Model</a>
<ul>
<li class="chapter" data-level="23.1" data-path="reg-extensions.html"><a href="reg-extensions.html#including-categorical-predictors"><i class="fa fa-check"></i><b>23.1</b> Including Categorical Predictors</a></li>
<li class="chapter" data-level="23.2" data-path="reg-extensions.html"><a href="reg-extensions.html#curvature"><i class="fa fa-check"></i><b>23.2</b> Curvature</a></li>
</ul></li>
<li class="chapter" data-level="24" data-path="reg-priors.html"><a href="reg-priors.html"><i class="fa fa-check"></i><b>24</b> Default Priors</a></li>
<li class="chapter" data-level="25" data-path="qr-factorization.html"><a href="qr-factorization.html"><i class="fa fa-check"></i><b>25</b> QR Factorization</a></li>
<li class="chapter" data-level="26" data-path="reg-conditions.html"><a href="reg-conditions.html"><i class="fa fa-check"></i><b>26</b> Assessing a Mean Model</a></li>
<li class="chapter" data-level="27" data-path="discrete-response.html"><a href="discrete-response.html"><i class="fa fa-check"></i><b>27</b> Regression Models for Discrete Responses</a>
<ul>
<li class="chapter" data-level="27.1" data-path="discrete-response.html"><a href="discrete-response.html#considerations-for-a-binary-response"><i class="fa fa-check"></i><b>27.1</b> Considerations for a Binary Response</a></li>
<li class="chapter" data-level="27.2" data-path="discrete-response.html"><a href="discrete-response.html#considerations-for-count-data"><i class="fa fa-check"></i><b>27.2</b> Considerations for Count Data</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Course Notes for Bayesian Data Analysis</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="quantifying-prior-information" class="section level1" number="9">
<h1><span class="header-section-number">9</span> Quantifying Prior Information</h1>
<p>Data contributes information to our beliefs. But, prior to beginning a study, we generally have some established beliefs. Those beliefs may be based on previous studies, expert opinions, personal experience, etc. The Bayesian framework explicitly incorporates these beliefs in the analysis. It is the job of the analyst to quantify these beliefs.</p>
<div class="rmdkeyidea">
<p>The Bayesian framework encodes any uncertainty through a probability distribution.</p>
</div>
<p>Recall that our primary aim is to make some statement about the population using a corresponding sample. These statements involve unknown parameters. Thus, we want to make a statement about a parameter using the sample. The data we observe will inform us about the values of these parameters. Prior to beginning the study, however, we generally have some notion about these parameters. What is a typical GPA for a Rose-Hulman student? How much does a member of the mathematics faculty earn each year, on average? Statisticians collect data to inform these beliefs (topic of the next section). But, even without data available, we have some idea of where we think the answer lies. Bayesians encode these beliefs into probability distributions. The beliefs we have prior to seeing the data are described by the prior distribution (since the beliefs were those we had <em>a priori</em>).</p>
<div class="definition">
<p><span id="def:defn-prior-distribution" class="definition"><strong>Definition 9.1  (Prior Distribution) </strong></span>A distribution quantifying our beliefs about uncertainty in the <em>parameter(s)</em> of the underlying sampling distribution <em>prior to</em> observing any data. This is often denoted by <span class="math inline">\(\pi(\boldsymbol{\theta})\)</span> where <span class="math inline">\(\boldsymbol{\theta}\)</span> is the parameter vector.</p>
<ul>
<li>This relies on a <em>subjective</em> view of probability.</li>
<li>As prior beliefs are subjective, there is no “one” prior, but each individual may have a unique prior.</li>
</ul>
</div>
<p>Constructing a prior distribution is not all that different from constructing the likelihood. There are several aspects involved, but it is all about understanding the structure of the beliefs.</p>
<div class="rmdtip">
<p><strong>Tips for Constructing a Prior:</strong><br />
The following considerations should be kept in mind when constructing the prior distribution.</p>
<ul>
<li>Identify the unknown parameter(s). That is, on what unknown value(s) does the <em>likelihood</em> depend?</li>
<li>Describe the support for the parameter(s).</li>
<li>Use clear statements about our beliefs of the parameters to determine the <strong>hyperparameters</strong>.</li>
</ul>
</div>
<div class="definition">
<p><span id="def:defn-hyperparameter" class="definition"><strong>Definition 9.2  (Hyperparameter) </strong></span>A constant term of a prior distribution which characterizes the family we are considering. While “parameters” (constant terms which characterize the likelihood) are unknown, hyperparameters are chosen such that the prior distribution reflects our prior beliefs.</p>
</div>
<div class="example">
<p><span id="exm:ex-mms" class="example"><strong>Example 9.1  (The Green Ones) </strong></span>Despite logically knowing that each tastes the same, Jamie prefers the green M&amp;M candies. Jamie’s husband has sent a small bag (of 30 candies) of M&amp;M’s with her for work. If they are a typical pack, she expects 1/6 of the candies to be green; however, if the pack is a holiday pack, she expects 1/2 of the candies to be green. Since it is close to Christmas, Jamie is 60% sure that she got a holiday pack.</p>
</div>
<p>Notice that in this example, no data has been collected — the pack has not been open. The beliefs stated here are <em>prior</em> to seeing any data, and they can therefore be used to form a prior distribution. Again, notice the use of “a” when describing the prior instead of “the.” While this prior will reflect Jamie’s beliefs; if someone had a different set of beliefs, we would arrive at a different prior.</p>
<p>Let <span class="math inline">\(Y\)</span> represent the number of green candies Jamie will observe when she opens the pack. Then, <span class="math inline">\(Y \sim Bin(30, \theta)\)</span>, where <span class="math inline">\(\theta\)</span> is the probability of a green candy. This is <strong>not</strong> the prior distribution but instead represents the likelihood. We see that this likelihood depends on the unknown parameter <span class="math inline">\(\theta\)</span>, which represents the liklihood of an individual candy being green. This is the first step in constructing a prior — constructing the likelihood and identifying any unknown parameters.</p>
<p>Now, we must describe the support for <span class="math inline">\(\theta\)</span>. Ordinarily, we might think that <span class="math inline">\(\theta\)</span> could be any value between 0 and 1 since it represents a probability. However, notice that the context we have here suggests there are really only two possible values: either <span class="math inline">\(\theta = 1/6\)</span> representing a typical pack, or <span class="math inline">\(\theta = 1/2\)</span> representing a holiday pack. So, the support of <span class="math inline">\(\theta\)</span> is the set <span class="math inline">\(\{1/6, 1/2\}\)</span>. Since the support is countable, we will need a discrete distribution for <span class="math inline">\(\theta\)</span>.</p>
<p>Now that we know the support of <span class="math inline">\(\theta\)</span>, we can use any remaining beliefs to create clear statements that help us define the hyperparameters and therefore create the exact form of the prior distribution. Our last piece of information is that Jamie is 60% sure she has a holiday pack. That is,</p>
<p><span class="math display">\[
Pr(\theta = u) = \begin{cases}
  0.4 &amp; u = 1/6 \\
  0.6 &amp; u = 1/2
  \end{cases}.
\]</span></p>
<p>This is a completely acceptable way of writing the prior distribution. However, as we will later see, formulas are much easier to work with instead of specific cases. As an alternative to the above, we write</p>
<p><span class="math display">\[\pi(\theta) = 0.4\delta(\theta - 1/6) + 0.6\delta(\theta - 1/2)\]</span></p>
<p>where <span class="math inline">\(\delta(x)\)</span> is the Dirac Delta function defined as</p>
<p><span class="math display">\[\int_{-\infty}^{\infty} f(x) \delta(x) dx = f(0)\]</span></p>
<p>for any function <span class="math inline">\(f\)</span>. There are other ways to represent <span class="math inline">\(\pi(\theta)\)</span>, but this makes it a continuous distribution over potential values of <span class="math inline">\(\theta\)</span>.</p>
<div class="rmdkeyidea">
<p>A prior distribution quantifies the uncertainty we have about a parameter prior to observing data.</p>
</div>
<p>The above example offers a rather simplistic view of constructing a prior. In practice, nearly every problem will involve some numerical computation at some point. Rarely, perhaps never, are we simply provided with a complete prior distribution and asked to perform an analysis. Generally, we must convert statements from researchers into some type of distribution.</p>

</div>
            </section>

          </div>
        </div>
      </div>
<a href="modeling-samples.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="posterior-distributions.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": false,
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": null,
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "section"
},
"toolbar": {
"position": "fixed"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
