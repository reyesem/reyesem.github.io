[["index.html", "Course Notes for Bayesian Data Analysis Preface", " Course Notes for Bayesian Data Analysis Eric M Reyes Last Updated: 2021-11-25 Preface Statistical analyses are used to make statements about a population using only a sample from the population, a process known as statistical inference. This resource introduces the Bayesian framework for statistical inference. Building from Bayes Rule for probability computations, we develop a framework of estimation and hypothesis testing. We will examine inference in several scenarios, including regression analysis. We discuss the construction of prior distributions given prior information about a parameter and give an introduction to computational tools for Bayesian inference, including Markov Chain Monte Carlo (MCMC) methods. While we do work through derivations when introducing the fundamental elements of Bayesian inference, we quickly move to computational approaches and emphasize application. Knowing the approach to modeling in the Bayesian framework and how to interpret the results is of primary importance. As with any text in statistics, we seek to develop your statistical literacy and statistical reasoning. "],["essential-probability.html", "1 Essential Probability 1.1 Density Functions as Models 1.2 Summarizing Distributions (Parameters) 1.3 Transformations of Random Variables 1.4 Independent Random Variables", " 1 Essential Probability Statistics uses data to make inference on a population. In turn, statistical theory is built on probability  the discipline of mathematics which studies and models random processes. This is particularly true within the Bayesian paradigm. An introductory course in probability provides a foundation in model random processes. Throughout the text, we will extend these ideas to modeling the process which generates observed data and the uncertainty in parameters that govern these processes. This chapter, however, provides a brief review of the most relevant aspects of probability theory necessary which permeate the remainder of the text. 1.1 Density Functions as Models Any process for which the outcome cannot be predicted with certainty is a random process. Typically, probability is taught from a mathematical perspective, with a goal of constructing a coherent and complete framework for characterizing such processes. Here, our goal is to introduce key probability concepts by relating them to their data-centric analogues. That is, we want to think of probability in light of how we will use it in statistical analysis. Each time we collect data, we can think of each observation as the result of a random process. These observations are recorded as variables in our dataset. Technically, a random variable is a function which maps outcomes from a random process to the real line; however, it suffices to think of a random variable as representing a measurement that results from a random process. Just as we have both quantitative and qualitative variables, there are continuous and discrete random variables. Definition 1.1 (Random Variable) Represents a measurement that will be collected and for which the value cannot be predicted with certainty. Generally represented with a capital letter. Continuous random variables represent quantitative measurements while discrete random variables represent qualitative measurements. While the exact value the random variable will take is unknown (because it results from a random process), we often know the range of the random variable  the possible values it can assume. In statistics, we refer to this as the support of the random variable. Definition 1.2 (Support) The set of all possible values a random variable can assume. We typically denote the support of the random variable \\(X\\) by \\(\\mathcal{S}_X\\). As a random variable is the result of a random process, each time we observe the process, the value of the random variable is subject to change. Further, it is often the case that not all values in the support are equally likely. A distribution is the way in which a random variable moves across its support. Probability is really about modeling and characterizing distributions. The most common way to represent a probability model is through its density function. Definition 1.3 (Density Function) A density function \\(f\\) relates the potential values of a random variable \\(X\\) with the probability those values occur. For a continuous random variable, the probability the random variable \\(X\\) falls within an interval \\((a, b)\\) is given by \\[Pr(a \\leq X \\leq b) = \\int_{a}^{b} f(x) dx.\\] For a discrete random variable, the probability the random variable \\(X\\) is equal to the value \\(u\\) is given by \\[Pr(X = u) = f(u).\\] In a probability course, there is often a distinction made between probability density functions (continuous random variables) and probability mass functions (discrete random variables). We do not make this distinction and instead rely on the context to determine whether we are dealing with a continuous or discrete random variable. From the definition, it is clear that the density function for a discrete random variable provides a very nice interpretation  it is a probability. However, for a continuous random variable, the density function is a smooth function over some region, and the actual value of the function is not interpretable; instead, we get at a probability by considering the area under the curve. Especially for visualization, the density function is the most common way of characterizing a probability model. However, computing the probability using the density is problematic due to the integration required. Many software programs address this by working with the cumulative distribution function (CDF). Definition 1.4 (Cumulative Distribution Function (CDF)) Let \\(X\\) be a random variable; the cumulative distribution function (CDF) is defined as \\[F(u) = Pr(X \\leq u).\\] For a continuous random variable, we have that \\[F(u) = \\int_{-\\infty}^{u} f(x) dx\\] implying that the density function is the derivative of the CDF. For a discrete random variable \\[F(u) = \\sum_{x \\leq u} f(x).\\] Working with the CDF improves computation because it avoids the need to integrate each time; instead, the integral is computed once (and stored internally in the computer), and we use the result to compute probabilities directly. Density functions are the mathematical models for distributions; they link values of the variable with the likelihood of occurence. However, for computational reasons, we often work with the cumulative distribution function which provides the probability of being less than or equal to a value. 1.2 Summarizing Distributions (Parameters) Most scientific questions are focused on the location or spread of a distribution. For example, we are interested in estimating the average yield of a crop, or the variance in the amount of sleep among college students. In probability, these are typically viewed simply as summaries of the entire distribution. In particular, the mean of a random variable (denoted by \\(E(X)\\)) and the variance of a random variable (denoted by \\(Var(X)\\)) are measures of the location and spread, respectively, of the distribution represented by its corresponding density function. When the density function is a model for the population, these represent the parameters of the population  the same parameters we will later estimate and make inference on using data analysis. Definition 1.5 (Mean and Variance of a Random Variable) Suppose \\(X\\) is a random variable with density function \\(f\\). If \\(X\\) is a continuous random variable, then the mean and variance are given by \\[ \\begin{aligned} E(X) &amp;= \\int x f(x) dx \\\\ Var(X) &amp;= \\int \\left(x - E(X)\\right)^2 f(x) dx \\end{aligned} \\] where the integral is taken over the support of \\(X\\). If \\(X\\) is a discrete random variable, then the mean and variance are given by \\[ \\begin{aligned} E(X) &amp;= \\sum x f(x) \\\\ Var(X) &amp;= \\sum \\left(x - E(X)\\right)^2 f(x) \\end{aligned} \\] where the sum is taken over the support of \\(X\\). In probability, often the distribution we are working with is completely determined. In reality, however, only the functional form of the distribution may be known, and therefore the distribution is known only up to some defining parameters that govern the shape. For example, a researcher might posit that within the population, the time until a medical device fails could be modeled using the density \\[f(x) = \\frac{1}{\\mu} e^{-\\frac{x}{\\mu}} \\qquad x &gt; 0.\\] Here, the researcher has really posited a form of the model, but not the exact model. The value \\(\\mu\\) is the average (which could be confirmed using the formulas in the above definition). In such cases, making inference on the parameters allows us to really characterize the entire distribution of the population. When a probability model is specified for a population, it is generally specified up to some unknown parameter(s). Making inference on the unknown parameter(s) therefore characterizes the entire distribution. 1.2.1 Kernels All density functions share some common properties. For example, a density function must be non-negative everywhere. We also know that if evaluated across the entire support, the density should sum to 1. That is, if \\(X\\) is a discrete random variable, then \\[\\sum_{\\mathcal{S}_X} f(x) = 1;\\] and, if \\(X\\) is a continuous random variable, then \\[\\int_{\\mathcal{S}_X} f(x) dx = 1.\\] Any density function \\(f(x)\\) can be rewritten as \\(f(x) = K h(x)\\) where \\(K &gt; 0\\) is a constant. We call \\(h\\) the kernel of the density function. Definition 1.6 (Kernel) A valid density function can be obtained by scaling the kernel such that integrating (or summing) over the support results in the value 1. Often, the kernel is useful for identifying the distributional family to which a random variable belongs. 1.3 Transformations of Random Variables Occasionally, we have some intuition about how to model the distribution of a random variable \\(X\\), but we are actually interested in the distribution of some function \\(g(X)\\) of that random variable. This is known as a variable transformation. For example, we may posit that the grade on an exam (when represented as a fraction) follow a Beta distribution; however, we are interested in characterizing the grade when it has been rescaled on the interval from 0 to 100. The derivation of the density function for the transformed random variable, when \\(X\\) is continuous, is often useful. While there are some well-known formulas for obtaining this density function, we prefer the following procedure: Define \\(Y = g(X)\\). Recognize that \\(F_Y(y) = Pr(Y \\leq y) = Pr(g(X) \\leq y)\\). Rewrite the above probability statement in terms of \\(X\\) and therefore the CDF \\(F_X\\) of \\(X\\). For monotone functions, this is simple by applying the inverse function \\(g^{-1}(y)\\) to both sides of the inequality within the probability statement; but, it may be more cumbersome in general. Compute the derivative of the result, with respect to \\(y\\) to obtain the density. Once you have the density function for \\(Y\\), which is a characterization of its distribution, you are able to summarize all aspects of its distribution as we would with any other random variable. 1.3.1 Expectations of Functions If all we are interested in is some summary of \\(Y = g(X)\\), determining the entire distribution is overkill. For example, suppose we are interested in \\(E(Y) = E\\left[g(X)\\right]\\); we could determine this by first performing the variable transformation to obtain the density of \\(Y\\) and then taking the expectation as defined in the previous section. However, there is a nice result that allows us to skip the intermediate step (it unfortunately is sometimes referred to as the Law of the Unconscious Statistician, which we of course object to). Definition 1.7 (Expectation of a Function of a Random Variable) Suppose \\(X\\) is a random variable with density function \\(f\\), and let \\(Y = g(X)\\). If \\(X\\) is a continuous random variable, then we have that \\[E(Y) = E\\left[g(X)\\right] = \\int g(x) f(x) dx\\] where the integral is taken over the support of \\(X\\). If \\(X\\) is a discrete random variable, then \\[E(Y) = E\\left[g(X)\\right] = \\sum g(x) f(x)\\] where the sum is taken over the support of \\(X\\). 1.3.2 Moment Generating Functions The mean and variance are known as the first two central moments of a distribution. For well-behaved distributions, any moment of a distribution can be computed from its moment generating function. Definition 1.8 (Moment Generating Function) Suppose \\(X\\) is a random variable with density function \\(f\\). The moment generating function (MGF) of \\(X\\), evaluated at \\(t\\), is given by \\[M_X(t) = E\\left[e^{tX}\\]] The \\(k\\)-th moment of \\(X\\) is then given by evaluating \\(M^{(k)}_X(t)\\), the \\(k\\)-th derivative of the MGF, at \\(t = 0\\). 1.4 Independent Random Variables As we will see as we progress, assuming random variables are independent greatly simplifies a model for the data generating process. In particular, when two random variables are independent, probability statements become easier to evaluate because and statements reduce to multiplication. Lemma 1.1 (Independence) If \\(X\\) and \\(Y\\) are independent random variables, then \\[Pr(a \\leq X \\leq b, c \\leq Y \\leq d) = Pr(a \\leq X \\leq b) Pr(c \\leq Y \\leq d).\\] Note: stating \\(Pr(A, B)\\) is equivalent to \\(Pr(A \\cap B)\\). "],["CaseDeepwater.html", "2 Case Study: Health Effects of the Deepwater Horizon Oil Spill", " 2 Case Study: Health Effects of the Deepwater Horizon Oil Spill On the evening of April 20, 2010, the Deepwater Horizon, an oil drilling platform positioned off the coast of Louisiana, was engulfed in flames as the result of an explosion. The drilling rig, leased and operated by BP, had been tasked with drilling an oil well in water nearly 5000 feet deep. Eleven personnel were killed in the explosion. The following screenshot is from the initial coverage by the New York Times1: Figure 2.1: New York Times coverage of the Deepwater Horizon oil spill. The incident is considered the worst oil spill in US history, creating an environmental disaster along the Gulf Coast. In addition to studying the effects on the local environment, researchers have undertaken studies to examine the short and long-term health effects caused by the incident. As an example, it is reasonable to ask whether volunteers who were directly exposed to oil, such as when cleaning wildlife, are at higher risk of respiratory irritation compared to those volunteers who were helping with administrative tasks and therefore were not directly exposed to the oil. An article appearing in The New England Journal of Medicine (Goldstein, Osofsky, and Lichtveld 2011) reported the results from a health symptom survey performed in the Spring and Summer of 2010 by the National Institute for Occupational Safety and Health. Of 54 volunteers assigned to wildlife cleaning and rehabilitation, 15 reported experiencing nose irritation, sinus problems, or sore throat. Of 103 volunteers who had no exposure to oil, dispersants, cleaners, or other chemicals, 16 reported experiencing nose irritation, sinus problems, or sore throat. While a larger fraction of volunteers cleaning wildlife in the study reported respiratory symptoms compared to those who were not directly exposed to irritants, would we expect similar results if we were able to interview all volunteers? What about during a future oil spill? Is there evidence that more than 1 in 5 volunteers who clean wildlife will develop respiratory symptoms? What is a reasonable value for the increased risk of respiratory symptoms for those volunteers with direct exposure compared to those without? In the first part of this text, we use this motivating example as the context for discussing how research questions should be framed, methods for data collection, and summarizing and presenting data clearly. References "],["Basics.html", "3 The Statistical Process 3.1 Overview of Drawing Inference 3.2 Anatomy of a Dataset 3.3 A Note on Codebooks", " 3 The Statistical Process Is driving while texting as dangerous as driving while intoxicated? Is there evidence that my measurement device is calibrated inappropriately? How much force, on average, can our concrete blocks withstand before failing? Regardless of your future career path, you will eventually need to answer a question. The discipline of statistics is about using data to address questions by converting that data into valuable information. Statistics is the discipline of converting data into information. It might be natural at this point to ask do I really need an entire class about answering questions with data? Isnt this simple? Sometimes, it is simple; other times, it can be far from it. Lets illustrate with the following example from Tintle et al. (2015). Example 3.1 (Organ Donation) Even though organ donations save lives, recruiting organ donors is difficult. Interestingly, surveys show that about 85% of Americans approve of organ donation in principle and many states offer a simple organ donor registration process when people apply for a drivers license. However, only about 38% of licensed drivers in the United States are registered to be organ donors. Some people prefer not to make an active decision about organ donation because the topic can be unpleasant to think about. But perhaps phrasing the question differently could affect a persons willingness to become a donor. Johnson and Goldstein (2003) recruited 161 participants for a study, published in the journal Science, to address the question of organ donor recruitment. The participants were asked to imagine they had moved to a new state and were applying for a drivers license. As part of this application, the participants were to decide whether or not to become an organ donor. Participants were presented with one of three different default choices: Some of the participants were forced to make a choice of becoming a donor or not, without being given a default option (the neutral group). Other participants were told that the default option was not to be a donor but that they could choose to become a donor if they wished (the opt-in group). The remaining participants were told that the default option was to be a donor but that they could choose not to become a donor if they wished (the opt-out group). The study found that 79% of those in the neutral group, 42% of those in the opt-in group, and 82.0% of those in the opt-out group agreed to become donors. The results of the study are presented in Figure 3.1. It seems obvious that using the opt-in strategy results in fewer people agreeing to organ donation. However, does the opt-out strategy, in which people are by default declared organ donors, result in more people agreeing to organ donation compared to the neutral strategy? On the one hand, a higher percentage did agree to organ donation under the opt-out (82% compared to 79%). However, since this study involved only a subset of Americans, is this enough evidence to claim the opt-out strategy is really superior compared to the neutral strategy in the broader population? The discipline of statistics provides a framework for addressing such ambiguity. Figure 3.1: Summary of the responses for the Organ Donation Study described in Example 3.1. 3.1 Overview of Drawing Inference Lets begin by taking a step back and considering the big picture of how data is turned into information. Every research question we pose, at its heart, is trying to characterize a population, the group of subjects of ultimate interest. Definition 3.1 (Population) The collection of subjects we would like to say something about. In the Organ Donation study, the researchers would like to say something about Americans who are of the age to consent to organ donation; in particular, they would like to quantify how likely it is that someone from this group agrees to organ donation. Therefore, the population is all Americans who are of the age to consent to organ donation. In general, the subjects in a population need not be people; in some studies, the population could be a collection of screws, cell phones, sheet metalwhatever characterizes the objects from which we would like to obtain measurements. We use the phrase like to because in reality it is often impossible (or impractical) to observe the entire population. Instead, we make observations on a subset of the population; this smaller group is known as the sample. Definition 3.2 (Sample) The collection of subjects for which we actually obtain measurements (data). For each subject within the sample, we obtain a collection of measurements forming our set of data. The goal of statistical modeling is to use the sample (the group we actually observe) to say something about the population of interest (the group we wish we had observed); this process is known as statistical inference. This process is illustrated in Figure 3.2. Definition 3.3 (Statistical Inference) The process of using a sample to characterize some aspect of the underlying population. Figure 3.2: Illustration of the statistical process. 3.2 Anatomy of a Dataset Once we have our sample, we take measurements on each of the subjects within this sample. These measurements form the data. When we hear the word data, most of us envision a large spreadsheet. In reality, data can take on many forms  spreadsheets, images, text files, unstructured text from a social media feed, etc. Regardless of the form, all datasets contain information for each subject in the sample; this information, the various measurements, are called variables. Definition 3.4 (Variable) A measurement, or category, describing some aspect of the subject. Variables come in one of two flavors. Categorical variables are those which denote a grouping to which the subject belongs. Examples include marital status, brand, and experimental treatment group. Numeric variables are those which take on values for which ordinary arithmetic (e.g., addition and multiplication) makes sense. Examples include height, age of a product, and diameter. Note that sometimes numeric values are used to represent the levels of a categorical variable in a dataset; for example, 0 may indicate No and 1 may indicate Yes for a variable capturing whether a person is a registered organ donor. Therefore, just because a variable has a numeric value does not make it a numeric variable; the key here is that numeric variables are those for which arithmetic makes sense. Definition 3.5 (Categorical Variable) Also called a qualitative variable, a measurement on a subject which denotes a grouping or categorization. Definition 3.6 (Numeric Variable) Also called a quantitative variable, a measurement on a subject which takes on a numeric value and for which ordinary arithmetic makes sense. While it may be natural to think of a dataset as a spreadsheet, not all spreadsheets are created equal. Here, we consider datasets which have the following characteristics: Each column contains a unique variable. Each record (row in the dataset) corresponds to a different observation of the variables. If you have multiple datasets, they should include a column in the table that allows them to be linked (subject identifier). These are characteristics of tidy data. Even unstructured data such as images or text files must be processed, often converted to tidy data, prior to performing a statistical analysis. The above description eliminates a common method of storing data in engineering and scientific disciplines  storing each sample in a different column. To illustrate, suppose we conduct a study comparing the lifetime (in hours) of two brands of batteries. We measure the lifetime of five batteries of Brand A and six of Brand B. It is common to see a dataset like that in Table 3.1; the problem here is that the first record of the dataset contains information on two different observations. We have the lifetime from a battery of Brand A in the same row as the lifetime from a battery of Brand B. This violates the second condition of tidy data described above. Table 3.1: Example of a common data structure which does not represent tidy data. Data is from a hypothetical study comparing battery lifetimes (hours). Brand A Brand B 8.3 8.4 5.1 8.6 3.3 3.8 5.3 4.1 5.7 4.5 4.0 In order to adhere to the tidy structure, we can reformat this dataset as illustrated in Table 3.2. Here, each record represents a unique observation and each column is a different variable. We have also added a unique identifier. Table 3.2: Example of a tidy dataset, a good way of storing data. Data is from a hypothetical study comparing battery lifetimes (hours). Battery Brand Lifetime 1 A 8.3 2 A 5.1 3 A 3.3 4 A 5.3 5 A 5.7 6 B 8.4 7 B 8.6 8 B 3.8 9 B 4.1 10 B 4.5 11 B 4.0 It may take some time to get used to storing data in this format, but it makes analysis easier and avoids time spent managing the data later. 3.3 A Note on Codebooks A dataset on its own is meaningless if you cannot understand what the values represent. Before you access a dataset, you should always review any available codebooks. Definition 3.7 (Codebook) Also called a data dictionary, these provide complete information regarding the variables contained within a dataset. Some codebooks are excellent, with detailed descriptions of how the variables were collected and appropriate units. Other codebooks give only an indication of what each variable represents. Whenever you are working with previously collected data, reviewing a codebook is the first step; and, you should be prepared to revisit the codebook often throughout an analysis. When you are collecting your own dataset, constructing a codebook is essential for others to make use of your data. References "],["Questions.html", "4 Asking the Right Questions 4.1 Characterizing a Variable 4.2 Framing the Question", " 4 Asking the Right Questions The discipline of statistics is about turning data into information in order to address some question. While there may be no such thing as a stupid question, there are ill-posed questions  those which cannot be answered as stated. Consider the Deepwater Horizon Case Study. It might seem natural to ask if a volunteer cleans wildlife, will she develop adverse respiratory symptoms? Lets consider the data. Of the 54 volunteers assigned to wildlife cleaning and rehabilitation, 15 reported experiencing adverse respiratory symptoms (nose irritation, sinus problems, or sore throat); while some volunteers developed symptoms, others did not. It seems the answer to our question is then it depends or maybe. This is an example of an ill-posed question. Such questions exist because of variability, the fact that every subject in the population does not behave in exactly the same way. In our example not every volunteer had the same reaction when directly exposed to oil. It is variability that creates a need for statistics; in fact, you could think of statistics as the study and characterization of variability. We must therefore learn to ask the right questions  those which can be answered in the presence of variability. Definition 4.1 (Variability) The notion that measurements differ from one observation to another. The presence of variability makes some questions ill-posed; statistics concerns itself with how to address questions in the presence of variability. 4.1 Characterizing a Variable Recall that the goal of statistical inference is to say something about the population; as a result, any question we ask should then be centered on this larger group. The first step to constructing a well-posed question is then to identify the population of interest for the study. For the Deepwater Horizon Case Study, it is unlikely that we are only interested in these 54 observed volunteers assigned to wildlife cleaning. In reality, we probably want to say something about volunteers for any oil spill. The 54 volunteers in our dataset form the sample, a subset from all volunteers who clean wildlife following an oil spill. Our population of interest is comprised of all volunteers who clean wildlife following an oil spill. When identifying the population of interest, be specific! Suppose you are trying to estimate the average height of trees. Are you really interested in all trees? Or, are you interested in Maple trees within the city limits of Terre Haute, Indiana? Since we expect that the reaction to oil exposure  the primary variable of interest for this study, sometimes called the response  to vary from one individual to another, we cannot ask a question about the value of the reaction (whether they experienced symptoms or not). Instead, we want to characterize the distribution of the response. Definition 4.2 (Response) The primary variable of interest within a study. This is the variable you would either like to explain or estimate. We will use random variables to represent the observations we will observe when we collect data; for example, \\(X_3\\) would refer to the value we expect to see for the third observation in our sample. Definition 4.3 (Distribution) The pattern of variability corresponding to a set of values. We will use probability theory to model the distribution of a response across the population. Notice that in this case, the response is a categorical variable; describing the distribution of such a variable is equivalent to describing how individuals are divided among the possible groups. With a finite number of observations, we could present the number of observations (frequeny) within each group. For example, of the 54 volunteers, 15 experienced adverse symptoms and 39 did not. This works well within the sample; however, as our population is infinitely large (all volunteers cleaning wildlife following an oil spill), reporting the frequencies is not appropriate. In this case, we report the fraction of observations (relative frequency) falling within each group; this helps convey information about the distribution of this variable. Definition 4.4 (Frequency) The number of observations falling into a particular level of a categorical variable. Definition 4.5 (Relative Frequency) Also called the proportion, the fraction of observations falling into a particular level of a categorical variable. Numeric quantities, like the proportion, which summarize the distribution of a variable within the population are known as parameters. Definition 4.6 (Parameter) Numeric quantity which summarizes the distribution of a variable within the population of interest. Generally denoted by Greek letters in statistical formulas. While the value of a variable may vary across the population, the parameter is a single fixed constant which summarizes the variable for that population. For example, the grade received on an exam varies from one student to another in a class; but, the average exam grade is a fixed number which summarizes the class as a whole. Well-posed questions can be constructed if we limit ourselves to questions about the parameter. The second step in constructing well-posed questions is then to identify the parameter of interest. The questions we ask generally fall into one of three categories: Estimation: what proportion of volunteers who clean wildlife following an oil spill will experience adverse respiratory symptoms? Hypothesis Testing: is it reasonable to expect that no more than 1 in 5 volunteers who clean wildlife following an oil spill will experience adverse respiratory symptoms? Prediction: how likely is a volunteer who cleans wildlife following an oil spill to experience adverse respiratory symptoms? Definition 4.7 (Estimation) Using the sample to approximate the value of a parameter from the underlying population. Definition 4.8 (Hypothesis Testing) Using a sample to determine if the data is consistent with a working theory or if there is evidence to suggest the data is not consistent with the theory. Definition 4.9 (Prediction) Using a sample to predict the value for an individual future observation. Since we do not get to observe the population (we only see the sample), we cannot observe the value of the parameter. That is, we will never know the true proportion of volunteers who experience symptoms. However, we can determine what the data suggests about the population (that is what inference is all about). Parameters are unknown values and can, in general, never be known. Parameters within the population correspond to the unknown parameters which define the mathematical probability model which describes the distribution of the response. It turns out, the vast majority of research questions can be framed in terms of a parameter. This is a fundamental ideas of inference. A research question can often be framed in terms of a parameter which characterizes the population. Framing the question should then guide our analysis. We now have a way of describing a well-posed question, a question which can be addressed using data. Well posed questions are about the population and can be framed in terms of a parameter which summarizes that population. We now describe how these questions are typically framed. 4.2 Framing the Question In engineering and scientific applications, many questions fall under the second category of model consistency. Examining such questions is known as hypothesis testing, which is a form of model comparison in which data is collected to help the researcher choose between two competing theories for the parameter of interest. In this section, we consider the terminology surrounding specifying such questions. For the Deepwater Horizon Case Study suppose we are interested in addressing the following question: Is there evidence that more than 1 in 5 volunteers who clean wildlife following an oil spill will develop adverse respiratory symptoms? The question itself is about the population (all volunteers assigned to clean wildlife following an oil spill) and is centered on a parameter (the proportion who develop adverse respiratory symptoms). That is, this is a well-posed question that can be answered with appropriate data. The overall process for addressing these types of questions is to form opposing statements defining reality, and then quantifying how likely each of those statements are based on the data we have observed. Consider the above question for the Deepwater Horizon Case Study. We are interested in finding evidence that the proportion experiencing adverse symptoms exceeds 0.20 (1 in 5). Therefore, we are interested in determining how likely this is to be true given the data we have observed. More, we might want to compare it against the likelihood that the proportion experiencing adverse symptoms does not exceed 0.20 (the opposite statement) given the data we have observed. There are therefore two opposing statements which could each define reality: the proportion experiencing adverse symptoms exceeds 0.20, or the proportion experiencing adverse symptoms does not exceed 0.20. Notice that both statements cannot be simultaneously true; each is a different statement about the parameter. We call these hypotheses. Definition 4.10 (Hypothesis) A statement (or theory) regarding a region for the parameter(s) of interest. Hypotheses are generally mutually exclusive. If there are only two competing hypotheses, the one we are more interested in establishing is typically called the alternative hypothesis (written \\(H_1\\) and read H-one), and its opposite is known as the null hypothesis (written \\(H_0\\) and read H-naught). For the Deepwater Horizon Case Study, we write: \\(H_0:\\) The proportion of volunteers assigned to clean wildlife following an oil spill who experience adverse respiratory symptoms is no more than 0.20. \\(H_1:\\) The proportion of volunteers assigned to clean wildlife following an oil spill who experience adverse respiratory symptoms exceeds 0.20. Each hypothesis is a well-posed statement (about a parameter characterizing the entire population), and the two statements are exactly opposite of one another meaning only one can be a true statement. For those who have prior exposure to statistical inference, notice that this framework vastly differs from the classical frequentist perspective. We are actually interested in the probability the hypothesis is true given the data observed! After writing down our hypotheses, we can collect data to determine which hypothesis is more likely given what we observe. Often these statements are written in a bit more of a mathematical structure in which a Greek letter is used to represent the parameter of interest. For example, we might write Let \\(\\theta\\) be the proportion of volunteers (assigned to clean wildlife following an oil spill) who experience adverse respiratory symptoms. \\(H_0: \\theta \\leq 0.20\\) \\(H_1: \\theta &gt; 0.20\\) In the above statements, \\(\\theta\\) represents the parameter of interest; the value 0.20 is known as the null value. Writing the hypotheses in this way connects them to probabilistic models underlying the distribution. Definition 4.11 (Null Value) The value associated with the equality component of the null hypothesis; it forms the threshold or boundary between the two hypothesis. Note: not all questions of interest require a null value be specified. This section has focused on developing the null and alternative hypothesis when our question of interest is best characterized as one of comparing models or evaluating a particular statement. If our goal is estimation, a null and alternative hypothesis are not applicable. For example, we might have the following goal: Estimate the proportion of volunteers (assigned to clean wildlife following an oil spill) who experience adverse respiratory symptoms. In this version of our research question there is no statement which needs to be evaluated. We are interested in estimation, not hypothesis testing and thus there is no corresponding null and alternative hypothesis. Process for Framing a Question In order to frame a research question, consider the following steps: Identify the population of interest. Identify the parameter(s) of interest. Determine if you are interested in estimating the parameter(s) or quantifying the evidence against some working theory. If you are interested in testing a working theory, make the null hypothesis the working theory and the alternative the exact opposite statement (what you want to provide evidence for). "],["Data.html", "5 Gathering the Evidence (Data Collection) 5.1 What Makes a Sample Reliable 5.2 Poor Methods of Data Collection 5.3 Preferred Methods of Sampling", " 5 Gathering the Evidence (Data Collection) Consider again the goal of statistical inference  to use a sample as a snapshot to say something about the underlying population (Figure 5.1). This generally provokes unease in people, leading to a distrust of statistical results. In this section we attack that distrust head on. Figure 5.1: Illustration of the statistical process (reprinted from Chapter 1). 5.1 What Makes a Sample Reliable If we are going to have some amount of faith in the statistical results we produce, we must have data in which we can place our trust. The Treachery of Images (Figure 5.2) is a canvas painting depicting a pipe, below which the artist wrote the French phrase This is not a pipe. Regarding the painting, the artist said The famous pipe. How people reproached me for it! And yet, could you stuff my pipe? No, its just a representation, is it not? So if I had written on my picture This is a pipe, Id have been lying! Figure 5.2: The Treachery of Images by René Magritte. Just as a painting is a representation of the object it depicts, so a sample should be a representation of the population under study. This is the primary requirement if we are to rely on the resulting data. In order for a statistical analysis to be reliable, the sample must be representative of the population under study. We need to be careful to not get carried away in our expectations. What constitutes representative really depends on the question, just as an artist chooses his depiction based on how he wants to represent the object. Lets consider the following example. Example 5.1 (School Debt) In addition to a degree, college graduates also tend to leave with a large amount of debt due to college loans. In 2012, a graduate with a student loan had an average debt of $29,400; for graduates from private non-profit institutions, the average debt was $32,3002. Suppose we are interested in determining the average amount of debt in student loans carried by a graduating senior from Rose-Hulman Institute of Technology, a small private non-profit engineering school. There are many faculty at Rose-Hulman who choose to send their children to the institute. Since I am also on the faculty, I know many of these individuals. Suppose I were to ask each to report the amount of student loans their children carried upon graduation from Rose-Hulman. I compile the 25 responses and compute the average amount of debt. Further, I report that based on this study, there is significant evidence that the average debt carried by a graduate of Rose-Hulman is far below the $32,300 reported above (great news for this years graduating class)! Why might we be hesitant to trust these results? Many objections to statistical results stem from a distrust of whether the data (the sample) is really representative of the population of interest. Rose-Hulman, like many other universities, has a policy that the children of faculty may attend their university (assuming admittance) tuition-free. We would therefore expect their children to carry much less debt than the typical graduating senior. There is a mismatch between the group we would like to study and the data we have collected. This example provides a nice backdrop for discussing what it means to be representative. First, lets define our population; in this case, we are interested in graduating seniors from Rose-Hulman. The variable of interest is the amount of debt carried in student loans; the parameter of interest is then the average amount of debt in student loans carried by graduating seniors of Rose-Hulman. However, the sample consists of only graduating seniors of Rose-Hulman who have a parent employeed by the university. With regard to the grade point average of the students in our sample, it is probably similar to all graduating seniors. The starting salary of the students in our sample is probably similar to all graduating seniors; the fraction of mechanical engineering majors versus math majors is probably similar. So, in many regards the sample is representative of the population; however, it fails to be representative with regard to the variable of interest. This is our concern. The amount of debt carried by students in our sample is not representative of that debt carried by all graduating seniors from the university. When thinking about whether a sample is representative, focus your attention to the characteristics specific to your research question. Does that mean the sample is useless? Yes and no. The sample collected cannot be used to answer our initial question of interest. No statistical method can fix bad data; statistics adheres to the garbage-in, garbage-out phenomena. If the data is bad, no analysis will undo that. However, while the sample cannot be used to answer our initial question, it could be used to address a different question: What is the average amount of debt in student loans carried by graduating seniors from Rose-Hulman whose parent is a faculty member at the university? For this revised question, the sample may indeed be representative. If we are working with previously collected data, we must consider the population to which our results will generalize. That is, for what population is the given sample representative? If we are collecting our data, we need to be sure we collect data in such a way that the data is representative of our target population. Lets first look at what not to do. 5.2 Poor Methods of Data Collection Example 5.1 is an example of a convenience sample, when the subjects in the sample are chosen simply due to ease of collection. Examples include surveying students only in your sorority when you are interested in all females who are part of a sorority on campus; taking soil samples from only your city when you are interested in the soil for the entire state; and, obtaining measurements from only one brand of phone, because it was the only one you could afford on your budget, when you are interested in studying all cell phones on the market. A convenience sample is unlikely to be representative if there is a relationship between the ease of collection and the variable under study. This was true in the School Debt example; the relationship of a student to a faculty member was directly related to the amount of debt they carried. As a result, the resulting sample was not representative of the population. When conducting a survey with human subjects, it is common to only illicit responses from volunteers. Such volunteer samples tend to draw in those with extreme opinions. Consider product ratings on Amazon. Individual ratings tend to cluster around 5s and 1s. This is because those customers who take time to submit a review (which is voluntary) tend to be those who are really thrilled with their product (and want to encourage others to purchase it) and those who are really disappointed with their purchase (and want to encourage others to avoid it). Such surveys often fail to capture those individuals in the population who have middle of the road opinions. We could not possibly name all the poor methods for collecting a sample; but, poor methods all share something in common  it is much more likely the resulting sample is not representative. Failing to be representative results in biased estimates of the parameter. Definition 5.1 (Bias) A set of measurements is said to be biased if they are consistently too high (or too low). Similarly, an estimate of a parameter is said to be biased if it is consistently too high (or too low). To illustrate the concept of bias, consider shooting at a target as in Figure 5.3. We can consider the center of our target to be the parameter we would like to estimate within the population. The values in our sample (the strikes on the target) will vary around the parameter; while we do not expect any one value to hit the target precisely, a representative sample is one in which the values tend to be clustered about the parameter (unbiased). When the sample is not representative, the values in the sample tend to cluster off the mark (biased). Notice that to be unbiased, it may be that not a single value in the sample is perfect, but aggregated together, they point in the right direction. So, bias is not about an individual measurement being an outlier, (more on those in a later chapter) but about repeatedly shooting in the wrong direction. Figure 5.3: Illustration of bias and variability. There is a difference between accuracy and precision. Generally, accuracy refers to location (and therefore bias); we say a process is accurate when it is unbiased. Precision refers to the variability. Biased results are typically due to poor sampling methods that result in a sample which is not representative of the target population. The catch (there is always a catch) is that we will never know if a sample is actually representative or not. We can, however, employ methods that help to minimize the chance that the sample is biased. 5.3 Preferred Methods of Sampling No method guarantees a perfectly representative sample; but, we can take measures to reduce or eliminate bias. A useful strategy is to employ randomization. If data is to be useful for making conclusions about the population, a process referred to as drawing inference, proper data collection is crucial. Randomization can play an important role ensuring a sample is representative and that inferential conclusions are appropriate. Consider the School Debt example again. Suppose instead of the strategy described there, we had done the following: We constructed a list of all graduating seniors from the university. We placed the name of each student on an index card; then, we thoroughly shuffled the cards and chose the top 25 cards. For these 25 individuals, we recorded the amount of debt in student loans each carried. This essentially describes using a lottery to select the sample. This popular method is known as taking a simple random sample. By conducting a lottery, we make it very unlikely that our sample consists of only students with a very small amount of student debt (as occurred when we used a convenience sample). Definition 5.2 (Simple Random Sample) Often abbreviated SRS, this is a sample of size \\(n\\) such that every collection of size \\(n\\) is equally likely to be the resulting sample. This is equivalent to a lottery. There are situations in which a simple random sample does not suffice. Again, consider our School Debt example. The Rose-Hulman student body is predominantly domestic, with only about 3% of the student body being international students. But, suppose we are interested in comparing the average debt carried between international and domestic students. It is very likely, by chance alone, that in a simple random sample of 25 students none will be international. Instead of a simple random sample, we might consider taking a sample of 13 domestic students and a sample of 12 international students; this is an example of a stratified random sample. This approach is useful when there is a natural grouping of interest within the population. Definition 5.3 (Stratified Random Sample) A sample in which the population is first divided into groups, or strata, based on a characteristic of interest; a simple random sample is then taken within each group. There are countless sampling techniques used in practice. The two described above can be very useful starting points for developing a custom method suitable for a particular application. Their benefit stems from their use of randomization. This section is entitled Preferred Methods because while these methods are ideal, they are not always practical. Consider the Deepwater Horizon Case Study; conceptually, we can take a simple random sample of the volunteers for our study. However, as with any study involving human subjects, researchers would be required to obtain consent from each subject in the study. That is, a volunteer has the right to refuse to participate in the study. Therefore, it is unlikely that a simple random sample as described above could be obtained. Again, the key is to obtain a representative sample; while random selection may be a nice tool for accomplishing this, we may need to appeal to the composition of the sample itself to justify its use. Based on the characteristics of those willing to participate in the study, do we feel the study participants form a representative group of all volunteers? That is the essential question. This is often why studies report a table summarizing subject demographics such as age, gender, etc. It is also why it is extremely important for researchers to describe how subjects were selected so that readers may make the judgement for themselves whether the sample is representative. http://ticas.org/sites/default/files/pub_files/Debt_Facts_and_Sources.pdf "],["Summaries.html", "6 Presenting the Evidence (Summarizing Data) 6.1 Characteristics of a Distribution (Summarizing a Single Variable) 6.2 Summarizing Relationships", " 6 Presenting the Evidence (Summarizing Data) If you open any search engine and look up data visualization, you will quickly be overwhelmed by a host of pages, texts, and software filled with tools for summarizing your data. Here is the bottom line: a good visualization is one that helps you answer your question of interest. It is both that simple and that complicated. The use of data for decision making requires that the data be summarized and presented in ways that address the question of interest. Whether simple or complex, all graphical and numerical summaries should help turn the data into usable information. Pretty pictures for the sake of pretty pictures are not helpful. In this section, we will consider various simple graphical and numerical summaries to help build a case for addressing the question of interest. 6.1 Characteristics of a Distribution (Summarizing a Single Variable) Remember that because of variability, the key to asking good questions is to not ask questions about individual values but to characterize the underlying distribution (see Definition 4.3). Therefore, characterizing the underlying distribution is also the key to a good visualization or numeric summary. For the Deepwater Horizon Case Study, the response (whether a volunteer experienced adverse respiratory symptoms) is categorical. As we stated previously, summarizing the distribution of a categorical variable reduces to showing how individual subjects fall into the various groups. Figure 6.1 displays a bar chart summarizing the rate of respiratory symptoms for volunteers cleaning wildlife. Figure 6.1: Frequency of adverse respiratory symptoms for volunteers cleaning wildlife following the Deepwater Horizon oil spill. In general, it does not matter whether the frequency or the relative frequencies are reported; however, if the relative frequencies are plotted, some indication of the sample size should be provided with the figure either as an annotation or within the caption. From the above graphic, we see that nearly 28% of volunteers assigned to wildlife experienced adverse respiratory symptoms; the graphic helps address our question, even if not definitively. When you are summarizing only categorical variables, a bar chart is sufficient. Statisticians tend to agree that bar charts are preferable to pie charts (see this whitepaper and this blog for further explanation). While a single type of graphic (bar charts) are helpful for looking at categorical data, summarizing the distribution of a numeric variable requires a bit more thought. Consider the following example. Example 6.1 (Paper Strength) While electronic records have become the predominant means of storing information, we do not yet live in a paperless society. Paper products are still used in a variety of applications ranging from printing reports and photography to packaging and bathroom tissue. In manufacturing paper for a particular application, the strength of the resulting paper product is a key characteristic. There are several metrics for the strength of paper. A conventional metric for assessing the inherent (not dependent upon the physical characteristics, such as the weight of the paper, which might have an effect) strength of paper is the breaking length. This is the length of a paper strip, if suspended vertically from one end, that would break under its own weight. Typically reported in kilometers, the breaking length is computed from other common measurements. For more information on paper strength measurements and standards, see the following website: http://www.paperonweb.com A study was conducted at the University of Toronto to investigate the relationship between pulp fiber properties and the resulting paper properties (Lee 1992). The breaking length was obtained for each of the 62 paper specimens, the first 5 measurements of which are shown in Table 6.1. The complete dataset is available online at the following website: https://vincentarelbundock.github.io/Rdatasets/doc/robustbase/pulpfiber.html While there are several questions one might ask with the available data, here we are primarily interested in characterizing the breaking length of these paper specimens. Table 6.1: Breaking length (km) for first 5 specimens in the Paper Strength study. Specimen Breaking Length 1 21.312 2 21.206 3 20.709 4 19.542 5 20.449 Figure 6.2 presents the breaking length for all 62 paper specimens in the sample through a dot plot in which the breaking length for each observed specimen is represented on a number line using a single dot. Figure 6.2: Breaking Length (km) for 62 paper specimens. With any graphic, we tend to be drawn to three components: where the values tend to be, how tightly the values tend to be clustered there, and the way the values tend to cluster. Notice that about half of the paper specimens in the sample had a breaking length longer than 21.26 km. Only about 25% of paper specimens had a breaking length less than 19.33 km. These are measures of location. In particular, these are known as percentiles, of which the median, first quartile and third quartile are commonly used examples. Definition 6.1 (Percentile) The \\(k\\)-th percentile is the value \\(q\\) such that \\(k\\)% of the values in the distribution are less than or equal to \\(q\\). For example, 25% of values in a distribution are less than or equal to the 25-th percentile (known as the first quartile and denoted \\(Q_1\\)). 50% of values in a distribution are less than or equal to the 50-th percentile (known as the median). 75% of values in a distribution are less than or equal to the 75-th percentile (known as the third quartile and denoted \\(Q_3\\)). The average is also a common measure of location. The breaking length of a paper specimen is 21.72 km, on average. In this case, the average breaking length and median breaking length are very close; this need not be the case. The average is not describing the center of the data in the same way as the median; they capture different properties. Definition 6.2 (Average) Also known as the mean, this measure of location represents the balance point for the distribution. It is denoted by \\(\\bar{x}\\). For a sample of size \\(n\\), it is computed by \\[\\bar{x} = \\frac{1}{n}\\sum_{i=1}^{n} x_i\\] where \\(x_i\\) rerpesents the \\(i\\)-th value in the sample. When referencing the average for a population, the mean is also called the Expected Value, and is often denoted by \\(\\mu\\). Clearly, the breaking length is not equivalent for all paper specimens; that is, there is variability in the measurements. Measures of spread quantify the variability of values within a distribution. Common examples include the standard deviation (related to variance) and interquartile range. For the Paper Strength example, the breaking length varies with a standard deviation of 2.88 km; the interquartile range for the breaking length is 5.2 km. The standard deviation is often reported more often than the variance since it is on the same scale as the original data; however, as we will see later, the variance is useful from a mathematical perspective for derivations. Neither of these values has a natural interpretation; instead, larger values of these measures simply indicate a higher degree of variability in the data. Definition 6.3 (Variance) A measure of spread, this roughly captures the average distance values in the distribution are from the mean. For a sample of size \\(n\\), it is computed by \\[s^2 = \\frac{1}{n-1}\\sum_{i=1}^{n} \\left(x_i - \\bar{x}\\right)^2\\] where \\(\\bar{x}\\) is the sample mean and \\(x_i\\) is the \\(i\\)-th value in the sample. The division by \\(n-1\\) instead of \\(n\\) reduces the bias in the statistic. The symbol \\(\\sigma^2\\) is often used to denote the variance in the population. Definition 6.4 (Standard Deviation) A measure of spread, this is the square root of the variance. Definition 6.5 (Interquartile Range) The distance between the first and third quartiles. This measure of spread indicates the range over which the middle 50% of the data is spread. The measures we have discussed so far are illustrated in Figure 6.3. While some authors suggest the summaries you choose to report depends on the shape of the distribution, we argue that it is best to report the values that align with the question of interest. It is the question that should be shaped by the beliefs about the underlying distribution. Figure 6.3: Illustration of measures of location and spread for a distribution of values. Finally, consider the shape of the distribution of breaking length we have observed. The breaking length tends to be clustered in two locations; we call this bimodal (each mode is a hump in the distribution). Other terms used to describe the shape of a distribution are symmetric and skewed. Symmetry refers to cutting a distribution in half (at the median) and the lower half being a mirror image of the upper half; skewed distributions are those which are not symmetric. Observe then that the dot plot above gives us some idea of the location, spread, and shape of the distribution, in a way that the table of values could not. This makes it a useful graphic as it is characterizing the distribution of the sample we have observed. This is one of the four components of what we call the Distributional Quartet. Definition 6.6 (Distribution of the Sample) The pattern of variability in the observed values of a variable. When the sample is not large, a dot plot is reasonable. Other common visualizations for a single variable include: jitter plot: similar to a dot plot, each value observed is represented by a dot; the dots are jittered (shifted randomly) in order to avoid overplotting when many subjects share the same value of the response. box plot: a visual depiction of five key percentiles; the plot includes the minimum, first quartile, median, third quartile, and maximum value observed. The quartiles are connected with a box, the median cuts the box into two components. histogram: can be thought of as a grouped dot plot in which subjects are binned into groups of similar values. The height of each bin represents the number of subjects falling into that bin. density plot: a smoothed histogram in which the y-axis has been standardized so that the area under the curve has value 1. The y-axis is not interpretable directly, but higher values simply mean more likely to occur. To illustrate these graphics, the breaking length for the Paper Strength example is summarized using various methods in Figure 6.4. The latter three visualizations are more helpful when the dataset is very large and plotting the raw values actually hides the distribution. There is no right or wrong graphic; it is about choosing the graphic which addresses the question and adequately portrays the distribution. Figure 6.4: Four graphical summaries of the breaking length for the Paper Strength example. The numeric summaries of a distribution are known as statistics. While parameters characterize a variable at the population level, statistics characterize a variable at the sample level. Definition 6.7 (Statistic) Numeric quantity which summarizes the distribution of a variable within a sample. Why would we compute numerical summaries in the sample if we are interested in the population? Remember the goal of this discipline is to use the sample to say something about the underlying population. As long as the sample is representative, the distribution of the sample should reflect the distribution of the population; therefore, summaries of the sample should be close to the analogous summaries of the population (statistics estimate their corresponding parameters). Now we see the real importance of having a representative sample; it allows us to say that what we observe in the sample is a good proxy for what is happening in the population. Definition 6.8 (Distribution of the Population) The pattern of variability in values of a variable at the population level. Generally, this is impossible to know, but we might model it. That is, the mean in the sample should approximate (estimate) the mean in the population; the standard deviation of the sample should estimate the standard deviation in the population; and, the shape of the sample should approximate the shape of the population, etc. The sample is acting as a representation in all possible ways of the population. A representative sample reflects the population; therefore, we can use statistics as estimates of the population parameters. We would never use \\(\\bar{x}\\) to represent a parameter like the mean of the population. The symbol \\(\\bar{x}\\) (or \\(\\bar{y}\\), etc.) represents observed values being averaged together. Since the values are observed, we must be talking about the sample, and therefore \\(\\bar{x}\\) represents a statistic. A similar statement could be made for \\(s^2\\) (sample variance) compared to \\(\\sigma^2\\) (often used to represent population variance, though it can represent other things). In reality, the symbols themselves are not important. The importance is on their representation. Statistics are observed while parameters are not. 6.2 Summarizing Relationships The summaries discussed above are nice for examining a single variable. In general, research questions of interest typically involve the relationship between two or more variables. Most graphics are two-dimensional (though 3-dimensional graphics and even virtual reality are being utilized now); therefore, summarizing a rich set of relationships may require the use of both axes as well as color, shape, size, and even multiple plots in order to tell the right story. We will explore these various features in upcoming units of the text. Here, we focus on the need to tell a story that answers the question of interest instead of getting lost in making a graphic. Consider the following question from the Deepwater Horizon Case Study: What is the increased risk of developing adverse respiratory symptoms for volunteers cleaning wildlife compared to those volunteers who do not have direct exposure to oil? Consider the graphic in Figure 6.5; this is not a useful graphic. While it compares the number of volunteers with symptoms in each group, we cannot adequately address the question because the research question involves comparing the rates for the two groups. Figure 6.5: Illustration of a poor graphic; the graphic does not give us a sense of the rate within each group in order to make a comparison. Instead, Figure 6.6 compares the rates within each group. Notice that since we are reporting relative frequencies, we also report the sample size for each group. Figure 6.6: Comparison of the rate of adverse respiratory symptoms among volunteers assigned to different tasks. From the graphic, it becomes clear that within the sample a higher fraction of volunteers cleaning wildlife experienced adverse symptoms compared with those without oil exposure. In fact, volunteers cleaning wildlife were 1.79 times more likely to experience adverse respiratory symptoms. The key to a good summary is understanding the question of interest and addressing this question through a useful characterization of the variability. References "],["bayes-rule.html", "7 Bayes Rule 7.1 Tenants of the Bayesian Approach to Inference", " 7 Bayes Rule Statistical inference is the process of using a sample to make a statement about the underlying population or data generating process. There are two large paradigms in the statistical community for defining the framework under which inference occurs. This unit introduces the fundamental components of the Bayesian paradigm. This builds on a simple result, Bayes Rule, which has much greater potential than we might see at first glance. In a probability course, Bayes Rule is often presented as a neat trick for solving a particular type of problem involving two events. While this simple class of problems understates its true potential, it does serve as a way of highlighting the key idea behind the method. Example 7.1 (Disease Testing) An enzyme-linked immunosorent assay (ELISA) test is performed to determine if the human immunodeficiency virus (HIV) is present in the blood of individuals. Suppose that the ELISA test correctly indicates HIV 99% of the time, and it correctly indicates being HIV-free in 99.5% of cases. Finally, suppose that the prevalence of HIV among blood donors is known to be 1/10000. What is the probability an individual who testes positive is actually infected with HIV? In this example, we are interested in the probability of an individual being infected with HIV given their test is positive. Recalling the definition of conditional probability, we consider \\[Pr(\\text{Infected with HIV} \\mid \\text{Tests Positive}) = \\frac{Pr(\\text{Infected with HIV} \\cap \\text{Tests Positive})}{Pr(\\text{Tests Positive})};\\] however, these probabilities are not provided in the problem. What we actually have are the probability of testing positive given the patient is infected with HIV (0.99), the probability of testing negative given the patient is not infected with HIV (0.95), and the probability of having HIV (1/10000). This is the power of Bayes Rule  it allows you to address problems by reversing the conditioning. That is, we can make a statement about the likelihood of \\(A\\) given \\(B\\) using information about the likelihood of \\(B\\) given \\(A\\)! As we state Bayes Rule, we keep in mind that it is not the rule itself which is innovative but (a) what the rule implies and (b) how we apply it to solve problems in statistical inference, that make it valuable. Theorem 7.1 (Bayes Theorem, Two Events) Given events \\(A\\) and \\(B\\) such that \\(Pr(A), Pr(B) \\neq 0\\), then we have that \\[Pr(A \\mid B) = \\frac{Pr(B \\mid A)Pr(A)}{Pr(B \\mid A)Pr(A) + Pr(B \\mid A^\\mathsf{c}) Pr(A^\\mathsf{c})}\\] Bayes Rule is actually a convenient wrapper for an application of several other basic probability results combined: The numerator is an application of the definition of conditional probability; we can always write a joint probability (and statement) as the product of a conditional probability and a marginal probability. The denominator is the result of the total probability rule; a marginal probability is computed by summing over mutually exclusive joint probabilities, which again are rewritten similarly to the numerator. Bayes Rule says that our information about \\(A\\), after observing \\(B\\), can be stated in terms of what we know about \\(B\\) after observing \\(A\\) and our belief about \\(A\\) prior to seeing \\(B\\). The above is useful when talking about two events, but the majority of applications address random variables, not specific events. That is, we are interested in characterizing entire distributions, not just probabilities for specific events. Following the same logic as above, we are able to extend (from a total probability rule and from the definition of conditional probability) the above result to two random variables. Theorem 7.2 (Bayes Theorem, Two Random Variables) Let \\(X\\) and \\(Y\\) be two random variables; then, we have that \\[f_{Y \\mid X}(y \\mid x) = \\frac{f_{X \\mid Y}(x \\mid y) f_Y(y)}{\\int_{\\mathcal{S}_Y} f_{X \\mid Y}(x \\mid y) f_Y(y) dy},\\] where the integration is replaced by summation when necessary to account for a discrete random variable. We will not distinguish between continuous and discrete random variables. For compactness, all results are presented assuming continuous random variables. When necessary, replace integration with summation (as summation is really just integration with respect to a specific measure). As stated above, this result is really the application of basic definitions covered in a probability course. But, they are worth revisiting. Definition 7.1 (Conditional Density) Let \\(X\\) and \\(Y\\) be two random variables; the conditional density of \\(X\\) given \\(Y\\) is given by \\[f_{X \\mid Y}(y \\mid x) = \\frac{f_{X, Y}(x, y)}{f_Y(y)}\\] Subscripts are to denote which random variable is being discussed; so, \\(f_X(x)\\) refers to the density function of the random variable \\(X\\) evaluated at \\(x\\). We suppress the subscripts when they are unnecessary. Rearranging the terms in Definition 7.1, we are able to see that any joint density function \\(f_{X, Y}(x, y)\\) can be written as the product of a conditional density and a marginal density. Similarly, we can write any marginal density by integrating over a joint density. Lemma 7.1 (Total Probability Rule for Random Variables) Let \\(X\\) and \\(Y\\) be two random variables with joint density \\(f_{X,Y}(x,y)\\); then, the marginal density of \\(X\\) is given by \\[f_X(x) = \\int_{\\mathcal{S}_Y} f_{X,Y}(x, y) dy,\\] where \\(\\mathcal{S}_Y\\) is the support of \\(Y\\). To add a little more intuition to this result, let \\(X\\) represent the grade in this course, and suppose we are interested in the event that \\(X\\) takes the value A. Well, this course is most certainly impacted by your other courses; so, let \\(Y\\) take the value of the grade in the hardest class remaining on your schedule. Then, there are only a certain number of options: \\(X\\) takes the value A while \\(Y\\) takes the value A (whoo hoo!); \\(X\\) takes the value A while \\(Y\\) takes the value B; \\(X\\) takes the value A while \\(Y\\) takes the value C; \\(X\\) takes the value A while \\(Y\\) takes the value D; and, \\(X\\) takes the value A while \\(Y\\) takes the value F (lets hope not). Each of these has some probability of occurring. Since this exhausts all possibilities for \\(Y\\), then we can determine the probability of \\(X\\) by adding up probability of each of these mutually exclusive events. The above lemma captures that we can do this for all values in the support of \\(X\\) simultaneously. The above definition is sufficient for several applications. However, it is worth stating the theorem from the most general of perspectives. To do so, we need to define the concept of a random vector. Definition 7.2 (Random Vector) Let \\(X_1, X_2, \\dots, X_n\\) be \\(n\\) random variables. Then, the vector \\(\\mathbf{X} = \\left(X_1, X_2, \\dots, X_n\\right)^\\top\\) is a random vector of length \\(n\\). A random vector is essentially a vector comprised of random components. This will be necessary moving forward because we typically have samples of size \\(n &gt; 1\\). Theorem 7.3 (Bayes Theorem) Let \\(\\mathbf{X}\\) and \\(\\mathbf{Y}\\) be two random vectors. Then, we have that \\[f_{\\mathbf{Y} \\mid \\mathbf{X}}(\\mathbf{y} \\mid \\mathbf{x}) = \\frac{f_{\\mathbf{X} \\mid \\mathbf{Y}}(\\mathbf{x} \\mid \\mathbf{y}) f_{\\mathbf{Y}}(\\mathbf{y})}{\\int_{\\mathcal{S}_\\mathbf{Y}} f_{\\mathbf{X} \\mid \\mathbf{Y}}(\\mathbf{x} \\mid \\mathbf{y}) f_{\\mathbf{Y}}(\\mathbf{y}) d\\mathbf{y}}\\] where the integral is now a multi-dimensional integral. Again, integration for any component is replaced by summation when needed. 7.1 Tenants of the Bayesian Approach to Inference The above results on their own may be interesting in a probability course. However, we are interested primarily in their application when we have observed a sample from a population which is not fully known. Before we delve into the mechanics, lets pause to reflect on how we intend to apply these results. Recall statistics is about using a sample to make inference on the population. Specifically, we will posit a model for the distribution of a response within the population; however, that model will be specified only up to some unknown parameters. There are two general statistical paradigms for performing inference, and these stem from two different questions we might ask: Given a hypothesis is true, how likely is the observed data? Given the observed data, how likely is a particular hypothesis? The first question results in the classical Frequentist perspective (most statistical courses). The second results in the Bayesian perspective. Prior to collecting data, we might have some belief about the those parameters. Then, we collect a sample from the population; since this data is representative of the population, it must contain information about those parameters. Therefore, we want to update our belief about those parameters in light of this data. That is the Bayesian process in a nutshell. The following three tenants are things that are at the heart of all our analyses in this course. The Bayesian approach takes into account prior knowledge when making inference. The Bayesian approach uses probability to quantify uncertainty in parameters are models. The Bayesian approach conditions on the observed data to update our prior knowledge. Throughout, we will rely on a subjective view of probability. That is, probability characterizes how sure you are of something. So, it does not make sense to say how likely is it to rain tomorrow? There is no one probability that answers this question. Instead, we will always have (even if not explicitly stated) a how likely do you believe element to our question. That is, we are always bringing in our personal (subjective) opinion. This can be very uncomfortable for some of us  the idea of there not being a singleright answer. We will save this discussion for a future chapter; right now, it suffices to say that in a probability course, we generally do not consider the interpretation of probability (it is simply a value to be computed). However, it is this interpretation that separates Bayesians and Frequentists. "],["modeling-samples.html", "8 Modeling Samples 8.1 Independence", " 8 Modeling Samples Rarely is our data a single observation. Instead, we collect a sample of observations. As a result, we must be able to comfortably model a collection of random variables. In a probability course, we are generally concerned with modeling a single random variable. The course may build into modeling the joint distribution of two random variables, but generally not further. However, if each random variable represents a single observation, then a sample of \\(n\\) subjects is actually a collection of \\(n\\) random variables. Part of quantifying our uncertainty in a parameter is first modeling the process that generated the data as a function of that parameter; that means, we need to model the distribution of the responses. We often talk about modeling the data, but that is not precise language. The data is fixed; it is not modeled. We are modeling the process which generated that data  it is this process that produces random values which are then observed. Let \\(X_1, X_2, \\dots, X_n\\) represent \\(n\\) observations of the same variable we intend to make (note the future tense). We group these in a random vector \\(\\mathbf{X}\\) of length \\(n\\). Not only are we interested in how each element in \\(\\mathbf{X}\\) is distributed, we are also interested in modeling how they are interrelated. Definition 8.1 (Joint Density) For a random vector \\(\\mathbf{X}\\), the function \\(f_{\\mathbf{X}}(\\mathbf{x})\\) such that for any set \\(A \\in \\mathbb{R}^n\\), we have \\[Pr(\\mathbf{X} \\in A) = \\int \\dotsi \\int_{A} f_{\\mathbf{X}}(\\mathbf{x}) dx_1 \\dotsb dx_n\\] The joint density is also referred to as the likelihood. Integrals are replaced by sums when appropriate. Probabilities involving multiple random variables involves integration over the joint density. The joint density describes how the elements move together; if we are interested in only a single element, we consider the marginal density, which is accomplished by integrating (or summing) over all possible values for the other elements. ::: {.definition, #defn-marginal-density name=Marginal Density} For a random vector \\(\\mathbf{X}\\), the marginal density of the first component \\(X_1\\) (without loss of generality) is \\[f_{X_1}(u) = \\int \\dotsi \\int f_{\\mathbf{X}}(\\mathbf{x}) dx_2 \\dotsb dx_n\\] ::: Bayes Theorem, and therefore Bayesian data analysis, is primarily concerned with conditional densities, which we now generalize to random vectors. Definition 7.1 (Conditional Density) For a random vector \\(\\mathbf{X}\\), the conditional density of the first \\(k\\) components (without loss of generality) given the remaining \\(n-k\\) components is given by \\[f_{\\mathbf{X}_1 \\mid \\mathbf{X}_2}(\\mathbf{x}_1 \\mid \\mathbf{x}_2) = \\frac{f_{\\mathbf{X}}(\\mathbf{x})}{f_{\\mathbf{X}_2}(\\mathbf{x}_2)}\\] where \\(\\mathbf{X}_1\\) represents the first \\(k\\) components and \\(\\mathbf{X}_2\\) the \\(n - k\\) remaining components. It is worth noting that with respect to the components of interest \\(\\mathbf{X}_1\\), the denominator in the conditional density is just a constant scaling factor to ensure the density integrates/sums to 1. When we are working with named distributions, using statistical software to compute probabilities is often superior to generic calculus software. This is because the algorithms for computing these probabilities are more stable for known distributions than general all-purpose numerical integration methods. 8.1 Independence The above discussion, while accurate, is unrealistic in that it begins with a completely formed likelihood. In reality, we must posit models which correspond to the data generating process. Positing a model for the distribution of an individual observation (element of \\(\\mathbf{X}\\)) often means choosing from among well-known named probability models. Regardless of whether a named model is used or a custom model constructed, the process always involves examining the context to determine an appropriate structure  the shape and support  of the distribution. We then allow the parameters of this distribution to remain unknown. This is where we turn from probability to statistics  suddenly, our models are only partly known, and there are some aspects (the parameters governing the behavior of the model) which are unknown. We will use data to make some statements about these parameters to address questions of interest which are framed in terms of these parameters. Instead of trying to model the joint distribution of the observed data directly, we often model the variability in the individual observations. We then place additional conditions on the relationship between the observations in order to develop the joint distribution. One of the most popular conditions is that of independence. Definition 8.2 (Independence) Two random variables \\(X\\) and \\(Y\\) are said to be independent if and only if \\[f_{X,Y}(x,y) = f_X(x)f_Y(y)\\] This generalizes to a random vector. The components of a random vector \\(\\mathbf{X}\\) are said to be mutually independent if and only if \\[f_{\\mathbf{X}}(\\mathbf{x}) = \\prod_{i=1}^{n} f_{X_i}(x_i)\\] Independence occurs when, and only when, the likelihood is the product of the marginal densities. Assuming independence allows us to easily construct joint densities given the marginal density for each observation! Independence is a powerful condition when constructing likelihoods. However, it cannot be blindly enforced; we should take caution when assuming independence. This requires considering the method in which the data was obtained to determine if it is reasonable that the value of one observation does not affect the likelihood of any other observation. "],["quantifying-prior-information.html", "9 Quantifying Prior Information", " 9 Quantifying Prior Information Data contributes information to our beliefs. But, prior to beginning a study, we generally have some established beliefs. Those beliefs may be based on previous studies, expert opinions, personal experience, etc. The Bayesian framework explicitly incorporates these beliefs in the analysis. It is the job of the analyst to quantify these beliefs. The Bayesian framework encodes any uncertainty through a probability distribution. Recall that our primary aim is to make some statement about the population using a corresponding sample. These statements involve unknown parameters. Thus, we want to make a statement about a parameter using the sample. The data we observe will inform us about the values of these parameters. Prior to beginning the study, however, we generally have some notion about these parameters. What is a typical GPA for a Rose-Hulman student? How much does a member of the mathematics faculty earn each year, on average? Statisticians collect data to inform these beliefs (topic of the next section). But, even without data available, we have some idea of where we think the answer lies. Bayesians encode these beliefs into probability distributions. The beliefs we have prior to seeing the data are described by the prior distribution (since the beliefs were those we had a priori). Definition 9.1 (Prior Distribution) A distribution quantifying our beliefs about uncertainty in the parameter(s) of the underlying sampling distribution prior to observing any data. This is often denoted by \\(\\pi(\\boldsymbol{\\theta})\\) where \\(\\boldsymbol{\\theta}\\) is the parameter vector. This relies on a subjective view of probability. As prior beliefs are subjective, there is no one prior, but each individual may have a unique prior. Constructing a prior distribution is not all that different from constructing the likelihood. There are several aspects involved, but it is all about understanding the structure of the beliefs. Tips for Constructing a Prior: The following considerations should be kept in mind when constructing the prior distribution. Identify the unknown parameter(s). That is, on what unknown value(s) does the likelihood depend? Describe the support for the parameter(s). Use clear statements about our beliefs of the parameters to determine the hyperparameters. Definition 9.2 (Hyperparameter) A constant term of a prior distribution which characterizes the family we are considering. While parameters (constant terms which characterize the likelihood) are unknown, hyperparameters are chosen such that the prior distribution reflects our prior beliefs. Example 9.1 (The Green Ones) Despite logically knowing that each tastes the same, Jamie prefers the green M&amp;M candies. Jamies husband has sent a small bag (of 30 candies) of M&amp;Ms with her for work. If they are a typical pack, she expects 1/6 of the candies to be green; however, if the pack is a holiday pack, she expects 1/2 of the candies to be green. Since it is close to Christmas, Jamie is 60% sure that she got a holiday pack. Notice that in this example, no data has been collected  the pack has not been open. The beliefs stated here are prior to seeing any data, and they can therefore be used to form a prior distribution. Again, notice the use of a when describing the prior instead of the. While this prior will reflect Jamies beliefs; if someone had a different set of beliefs, we would arrive at a different prior. Let \\(Y\\) represent the number of green candies Jamie will observe when she opens the pack. Then, \\(Y \\sim Bin(30, \\theta)\\), where \\(\\theta\\) is the probability of a green candy. This is not the prior distribution but instead represents the likelihood. We see that this likelihood depends on the unknown parameter \\(\\theta\\), which represents the liklihood of an individual candy being green. This is the first step in constructing a prior  constructing the likelihood and identifying any unknown parameters. Now, we must describe the support for \\(\\theta\\). Ordinarily, we might think that \\(\\theta\\) could be any value between 0 and 1 since it represents a probability. However, notice that the context we have here suggests there are really only two possible values: either \\(\\theta = 1/6\\) representing a typical pack, or \\(\\theta = 1/2\\) representing a holiday pack. So, the support of \\(\\theta\\) is the set \\(\\{1/6, 1/2\\}\\). Since the support is countable, we will need a discrete distribution for \\(\\theta\\). Now that we know the support of \\(\\theta\\), we can use any remaining beliefs to create clear statements that help us define the hyperparameters and therefore create the exact form of the prior distribution. Our last piece of information is that Jamie is 60% sure she has a holiday pack. That is, \\[ Pr(\\theta = u) = \\begin{cases} 0.4 &amp; u = 1/6 \\\\ 0.6 &amp; u = 1/2 \\end{cases}. \\] This is a completely acceptable way of writing the prior distribution. However, as we will later see, formulas are much easier to work with instead of specific cases. As an alternative to the above, we write \\[\\pi(\\theta) = 0.4\\delta(\\theta - 1/6) + 0.6\\delta(\\theta - 1/2)\\] where \\(\\delta(x)\\) is the Dirac Delta function defined as \\[\\int_{-\\infty}^{\\infty} f(x) \\delta(x) dx = f(0)\\] for any function \\(f\\). There are other ways to represent \\(\\pi(\\theta)\\), but this makes it a continuous distribution over potential values of \\(\\theta\\). A prior distribution quantifies the uncertainty we have about a parameter prior to observing data. The above example offers a rather simplistic view of constructing a prior. In practice, nearly every problem will involve some numerical computation at some point. Rarely, perhaps never, are we simply provided with a complete prior distribution and asked to perform an analysis. Generally, we must convert statements from researchers into some type of distribution. "],["posterior-distributions.html", "10 Updating Prior Beliefs (Posterior Distributions)", " 10 Updating Prior Beliefs (Posterior Distributions) The previous chapter addressed the construction of the prior distribution, the distribution which captures the uncertainty we have in the unknown parameters governing the data generating process. However, these prior beliefs should be updated with available data. Through an application of Bayes Theorem, we derive the distribution of the parameters after observing the data, incorporating our prior beliefs. This is known as the posterior distribution. Definition 10.1 (Posterior Distribution) A distribution quantifying our beliefs about uncertainty in the parameter(s) of the underlying sampling distribution after observing any data. This is often denoted by \\(\\pi(\\boldsymbol{\\theta} \\mid \\mathbf{y})\\) where \\(\\boldsymbol{\\theta}\\) is the parameter vector and \\(\\mathbf{y}\\) the observe data and computed using Bayes Theorem: \\[\\pi(\\boldsymbol{\\theta} \\mid \\mathbf{y}) = \\frac{f(\\mathbf{y} \\mid \\boldsymbol{\\theta}) \\pi(\\theta)}{\\int f(\\mathbf{y} \\mid \\boldsymbol{\\theta}) \\pi(\\boldsymbol{\\theta}) d\\boldsymbol{\\theta}}\\] The posterior distribution is the conditional distribution of the parameters given the observed data. This allows us to make statements like given the data, how likely is it that the parameter is between \\(a\\) and \\(b\\). Just as the prior distribution depends on a subjective interpretation of probability, so too does the posterior. We now have a way of quantifying our uncertainty in the parameters given the observed data. Recall that there is no one prior distribution but instead a different prior for each set of prior beliefs. Similarly, there is no one posterior distribution. When we say the posterior, we are referring to the posterior distribution which corresponds to the chosen prior distribution and the data observed. Example 10.1 (The Green Ones, Cont.) Consider Example 9.1 previously introduced. Suppose that out of the 30 candies, we observe 10 green candies. Given this data, how likely is it that this is a holiday pack? How has the data impacted Jamies prior beliefs? Recall that we had previously said that the likelihood is Binomial. Specifically, \\(Y \\sim Bin(30, \\theta)\\); that is, \\[\\begin{equation} f(y \\mid \\theta) = \\binom{n}{y} \\theta^y (1 - \\theta)^{n-y}. \\tag{10.1} \\end{equation}\\] Further, based on our prior beliefs, we had specified \\[\\begin{equation} \\pi(\\theta) = 0.4\\delta(\\theta - 1/6) + 0.6\\delta(\\theta - 1/2). \\tag{10.2} \\end{equation}\\] Now, we are prepared to apply Bayes Theorem. \\[\\begin{equation} \\pi(\\theta \\mid y) = \\frac{\\binom{30}{10} \\theta^{10} (1 - \\theta)^{30 - 10} \\left[0.4\\delta(\\theta - 1/6) + 0.6\\delta(\\theta - 1/2)\\right]}{\\int_{0}^{1} \\binom{30}{10} \\theta^{10} (1 - \\theta)^{30 - 10} \\left[0.4\\delta(\\theta - 1/6) + 0.6\\delta(\\theta - 1/2)\\right] d\\theta}. \\tag{10.3} \\end{equation}\\] Turning first to the denominator, we have \\[ \\begin{aligned} \\text{denom} &amp;= \\int_{0}^{1} \\binom{30}{10} \\theta^{10} (1-\\theta)^{30 - 10} (0.4)\\delta(\\theta - 1/6) d\\theta \\\\ &amp;\\quad + \\int_{0}^{1} \\binom{30}{10} \\theta^{10} (1-\\theta)^{30 - 10} (0.6)\\delta(\\theta - 1/2) d\\theta \\\\ &amp;= \\binom{30}{10} (1/6)^{10} (5/6)^{20} (0.4) + \\binom{30}{10} (1/2)^{30} (0.6) \\end{aligned} \\] Notice that this denominator does not depend on the parameter since we integrated it out. It should be a function only of the observed data. This means that once the data is observed, it is a constant as above. Now, we are able to simplify Equation (10.3). \\[ \\begin{aligned} \\pi(\\theta \\mid y) &amp;= \\frac{\\binom{30}{10} \\theta^{10} (1 - \\theta)^{30 - 10} \\left[0.4 \\delta(\\theta - 1/6) + 0.6\\delta(\\theta - 1/2)\\right]}{\\binom{30}{10} (1/6)^{10} (5/6)^{20} (0.4) + \\binom{30}{10} (1/2)^{30} (0.6)} \\\\ &amp;= \\theta^{10} (1 - \\theta)^{30 - 10} \\left[\\frac{\\delta(\\theta - 1/6)}{(1/6)^{10}(5/6)^{20} + (1/2)^{30}(3/2)} + \\frac{\\delta(\\theta - 1/2)}{(1/6)^{10} (5/6)^{20} (2/3) + (1/2)^{30}}\\right] \\end{aligned} \\] which simplifies to \\[\\begin{equation} \\pi(\\theta \\mid y) = (0.2359)\\delta(\\theta - 1/6) + (0.7641)\\delta(\\theta - 1/2) \\tag{10.4} \\end{equation}\\] Given the data, there is a 76.41% chance the pack is a holiday pack. Notice that the data has strengthened the prior beliefs. Where we initially only believed there was a 60% chance it was a holiday pack, we have now increased that probability a decent amount. The data may have seemed somewhat consistent with both models (5 candies are expected in a general setting and 15 in a holiday pack). However, if only 1/6 of candies are green, it is much less likely to see 10 out of 30 compared to seeing 10 out of 30 if 1/2 are green. Therefore, the data increased our belief in the holiday pack. Our beliefs are updated based on the data. There are a couple of other observations we should draw from this example. Notice that the support of the posterior matches the support of the prior. This is always the case (as long as the support of the data does not depend on the likelihood); if you go into a problem whole-heartedly believing something is not possible, then no amount of data will convince you (think of it as a core belief that is unshakable). Data can only convince those who are open to believing something different! The support of the posterior is determined by the support of the prior distribution as well as whether the support of the likelihood depends on the parameter. The hardest part of the above example is computing the integral in the denominator and then carrying the algebra through in order to determine the solution. While we could rely on a computer algebra system in order to perform these computations in these simple settings, relying on these tools tends to fail in more complex problems encountered in practice. Moving forward, we will want a way of overcoming the integral in the denominator, especially in cases when the parameter vector grows to be high-dimensional. To begin emphasizing the need to find alternatives, consider the following observation: the denominator in the computation of the posterior is constant with respect to the parameter. Applying Bayes Theorem in Practice: The denominator in Bayes rule exists to ensure the distribution integrates to 1; it is just a scaling constant. That is, \\[\\pi(\\boldsymbol{\\theta} \\mid \\mathbf{y}) \\propto f(\\mathbf{y} \\mid \\boldsymbol{\\theta}) \\pi(\\boldsymbol{\\theta})\\] This recognition allows us to quickly compute the kernel of the posterior, which in many cases is sufficient for identifying the posterior distribution. Finally, we emphasize that the posterior does not tell you the value of the unknown parameter  a parameter is unknown and will always remain so! The posterior only tells you the beliefs you have about that parameter given the data you have observed and your prior beliefs. "],["point-estimation.html", "11 Point Estimation", " 11 Point Estimation Everything we could ever want to know about a parameter, given the data we have observed, is contained in the posterior distribution. For those very comfortable with probability theory, we may not shy away from having an entire distribution presented to us as a way of summarizing the information available about the parameter. Instead of presenting the entire distribution, however, others may prefer to be presented with a single estimate of the parameter. That is, we are interested in summarizing key aspects of the posterior distribution. Estimating the parameter of interest is typically done by summarizing the location of the posterior distribution. When studying probability, we learn the location of a distribution is typically summarized by the mean, the median, or the mode. As a result, three common point estimates for a parameter in the Bayesian framework are the posterior mean, the posterior median, and posterior mode. Definition 11.1 (Posterior Mean) The average value of the parameter, given the data. \\[E\\left[\\theta \\mid \\mathbf{y}\\right] = \\int \\theta \\pi(\\theta \\mid \\mathbf{y}) d\\theta\\] We note that as the dimension of the parameter vector increases, this could be a very difficult integral to compute. We will address this issue in the next unit. For now, we will typically work with known distributions and therefore known expressions for the posterior mean. Definition 11.2 (Posterior Median) The value such that we are 50% sure, given the data, the parameter must fall below. Formally, this is the value \\(q\\) such that \\[0.5 = \\int_{-\\infty}^{q} \\pi(\\theta \\mid \\mathbf{y}) d\\theta\\] While closed-form solutions may exist for the posterior mean, even with known distributions the posterior median must often be computed numerically. This is not problematic; we are simply acknowledging that in statistics, numerical solutions are common and recognized as valid solutions. Definition 11.3 (Posterior Mode) The most-likely value of the parameter, given the data; if the posterior is continuous, it is the value of the parameter, given the data, which maximizes the density. That is, \\[\\arg \\max_{\\theta} \\pi(\\theta \\mid \\mathbf{y})\\] The posterior mode only makes sense as an estimate if the posterior distribution is unimodal. One might ask which estimate is best. It depends. The mean and median may not be representative of a typical value. The mean is more sensitive to extreme values; the median tends to be more stable. However, many packages default to reporting the posterior mean, making it a popular choice out of simplicity. Again, regardless of which value you may choose to report, do not neglect that you have access to the entire distribution; therefore, you are not limited by a single estimate but can provide a much richer summary of the posterior. It is common for those first learning the Bayesian framework to confuse the parameter being estimated with the method of estimation used. We can use the posterior mode to estimate the mean response. We can use the posterior mean to estimate the variance of the response. The method of estimation (posterior mean, posterior median, or posterior mode) is not linked to the parameter (mean response, variance of the response, etc.). It is worth noting that we do not compute a point estimate for Example 9.1. That is because the support for the parameter contains only two values. The posterior mean would not be very insightful as it is not a value in the support. Given the finite support, it is better to simply report the likelihood of each possibility. "],["interval-estimation.html", "12 Interval Estimation", " 12 Interval Estimation The previous chapter considers a single point estimate for the parameter of interest. However, this ignores the fact that there is variability in these estimates. The distribution itself tells us that the parameter is more likely to fall in some regions than others. So, we consider providing a range of plausible values for the parameter and quantifying our belief that the parameter falls in that range. Definition 12.1 (Point Estimation) The process of estimating a parameter with a single statistic. This is like trying to hit an infinitesimally small target with a dart. Definition 12.2 (Interval Estimation) The process of estimating a parameter with a range of values. This is like trying to capture a target with a ring. Regardless of which method we use, both are estimates, and both depend on the posterior distribution. That is, both are statements about the parameter given the observed data and our prior beliefs. Definition 12.3 (Credible Interval) A \\(100c\\)% credible interval is an interval \\((a, b)\\) such that \\[Pr(a \\leq \\theta \\leq b \\mid \\mathbf{y}) = \\int_{a}^{b} \\pi(\\theta \\mid \\mathbf{y})d\\theta = c\\] For those who have had a previous statistics course taught from the Frequentist perspective, this seems to mirror a confidence interval, but the interpretation is completely different. Since probability is used to quantify subjective beliefs, notice that the credible interval allows us to say that we are \\(100c\\)% sure the parameter falls in this range, given the data. That is a statement that does not make sense from a Frequentist perspective. This does not require repeated sampling to make sense; we simply say, based on the data observed (however much or little we have), we are \\(100c\\)% sure the parameter falls in this interval. There is not a unique credible interval for a parameter. Since there are infinitely many regions which will contain \\(100c\\)% of the posterior distribution, there are infinitely many credible intervals we could provide. In order to provide some level of continuity between applications, we tend to gravitate to one of two types of intervals which have nice properties. Definition 12.4 (Equal-Tailed Credible Interval) This credible interval, which is probably the most commonly used in practice, chooses endpoints such that \\[Pr(\\theta &lt; a \\mid \\mathbf{y}) = \\frac{1-c}{2} = Pr(\\theta &gt; b \\mid \\mathbf{y})\\] As the name implies, an equal-tailed credible interval places the same amount of probability in each tail; we are taking the middle \\(100c\\)% of the distribution. An equal-tailed interval is easy, but it may not always be the most intuitive interval. Figure 12.1 compares to potential 90% credible intervals for a hypothetical posterior distribution. Observe that the equal-tailed interval removes the bottom 5% of the distribution; while this band is narrow, it represents values which correspond to the highest density values. It seems intuitive that we would want to choose the narrowest credible interval which still retains the same area under the curve, as illustrated in the second panel of Figure 12.1. Figure 12.1: Comparison of two 90% credible intervals for a hypothetical posterior distribution. Definition 12.5 (Highest Density Interval) This credible interval, often called an HDI or HPD for highest posterior density, chooses the endpoints such that the interval is as short as possible. When the density is unimodal, this can be accomplished by choosing the endpoints \\(a\\) and \\(b\\) such that \\[\\pi(\\theta = a \\mid \\mathbf{y}) = \\pi(\\theta = b \\mid \\mathbf{y})\\] and \\[\\int_{a}^{b} \\pi(\\theta \\mid \\mathbf{y} d\\theta = c\\] Note that if the posterior distribution is multimodal, then the highest density interval is actually a region as it will likely involve two disjoint intervals. Most software which compute the HDI assume the posterior is unimodal. Let \\((a, b)\\) be a \\(100c\\)% credible interval for the parameter \\(\\theta\\) given a set of data, and suppose we are in \\(\\eta = g(\\theta)\\) for some function \\(g\\). That is, we are interested in a function of the parameter. Then, \\(\\left(g(a), g(b)\\right)\\) will be a \\(100c\\)% credible interval for the parameter \\(\\eta\\) given the data. However, note that if \\((a, b)\\) is an HDI, we are not guaranteed that \\(\\left(g(a), g(b)\\right)\\) is an HDI for \\(\\eta\\). "],["prediction.html", "13 Prediction 13.1 Derivation of the Posterior Predictive 13.2 Summary", " 13 Prediction To this point, we have been focused on making a statement about the parameter given the data. However, researchers are often interested in using the data to predict what might occur in the future. Hopefully by now you realize that within the Bayesian framework, we are never interested solely in a point estimate. So, when we say we are interested in prediction, we mean we are interested in characterizing our uncertainty in a future value given the data we have observed. As this statement is not directly about the parameter, the posterior distribution does not contain the relevant information. Imagine we had not yet collected data. Given only our prior beliefs, how might we characterize a future observation (one not yet observed)? We may not know what value a future observation will take, but we have some sense of the process that will generate it if we have posited a joint density to describe the data generating process. In probability, we routinely used the distribution to characterize future values everytime you answered a question like what is the probability you would observe a value between \\(a\\) and \\(b\\)? It is therefore intuitive that we might turn toward the likelihood \\(f(\\mathbf{y} \\mid \\theta)\\) to describe the variability in data that has not yet been observed. Of course, this highlights the difference between probability and statistics  in probability, we always knew the value of \\(\\theta\\), but in statistics, we do not. Without a value of \\(\\theta\\) to plug into the density, we are unable to use it to compute probabilities about future observations (or, more precisely, any probabilities we computed would be a function of the unknown parameter). Enter our prior beliefs. While we do not know the value of \\(\\theta\\), we do have some prior beliefs about it, and these are captured in the prior distribution. The Bayesian framework proposes marginalizing out the parameter  essentially taking a weighted average over all possible values it could be. What results is not a single value, but a distribution of values known as the prior predictive distribution. Definition 13.1 (Prior Predictive Distribution) The marginal distribution of the response(s) prior to observing any data: \\[m(\\mathbf{y}) = \\int f(\\mathbf{y} \\mid \\theta) \\pi(\\theta) d\\theta\\] Notice this distribution corresponds to the denominator in Bayes Theorem. While rarely used directly, this distribution provides a way of characterizing our uncertainty in future observations based solely on our beliefs about \\(\\theta\\) prior to observing any data. The idea of marginalizing out the parameter is critical. Of course, we will eventually collect data, and we would like to take this knowledge into account. After observing the data, the parameter remains unknown; however, our beliefs about the parameter update (and are captured in the posterior distribution). We want to somehow marginalize out the parameter while accounting for these updated beliefs. Intuitively, we may be led to swapping out the role of the posterior for the prior in Definition 13.1. This results in the posterior predictive distribution. Definition 13.2 (Posterior Predictive Distribution) Let \\(\\mathbf{Y}^*\\) represent a collection of \\(m\\) future observations. The distribution of these future observations given the observed data \\(\\mathbf{Y}\\) (of length \\(n\\)), is given by \\[\\pi\\left(\\mathbf{y}^* \\mid \\mathbf{y}\\right) = \\int f\\left(\\mathbf{y}^* \\mid \\theta\\right) \\pi(\\theta \\mid \\mathbf{y}) d\\theta\\] While this definition is correct, its derivation requires some additional constraints on the data generating process. We present the derivation below primarily to combat any misconceptions about what is happening in the integration above. 13.1 Derivation of the Posterior Predictive Let \\(\\mathbf{Y}^*\\) denote a collection of \\(m\\) future (or new) observations not yet observed. This is distinguished from the collection of \\(n\\) observations we have already made \\(\\mathbf{Y}\\). We impose the following two conditions/assumptions on the data generating process: Given the value of the parameter, the likelihood of \\(\\mathbf{Y}^*\\) has the same form as the likelihood of of the observed data \\(\\mathbf{Y}\\). Given the value of the parameter, the observed data \\(\\mathbf{Y}\\) is independent of the new observations \\(\\mathbf{Y}^*\\). The first condition above is intuitive. It does not make sense to use data that is generated under one process to predict data generated under a completely different process. Therefore, our future observations are always related in some way to the likelihood, as that models the data generating process of interest. The second condition extends the concept of independence presented in a typical probability course. This is conditional independence. Definition 13.3 (Conditional Independence) Two random variables \\(X\\) and \\(Y\\) are said to be independent, conditional on \\(Z\\) if, and only if, \\[f_{(X,Y) \\mid Z} (x, y \\mid z) = f_{X \\mid Z}(x \\mid z) f_{Y \\mid Z}(y \\mid z)\\] Conditional independence is common in statistical theory. Two random quantities are somehow related, but given an additional piece of information become independent. Returning to the stated condition, we are saying that the only thing the new and old observations have in common is the data generating process; once we know the quantities that govern this process (the parameters), then we can gain no further knowledge from the old observations. That is, if someone told you what the parameters were, there would be no need to collect data  you would know everything possible for predicting a future observation. So, the data observed is only useful in that it informs our beliefs about the unknown parameters. The data observed informs our beliefs about the parameters in the data generating process. It is only through what the data tells us about the parameters that the data is useful in predicting a future observation. We are now prepared to derive the posterior predictive distribution. Recall that a marginal distribution can be constructed by integrating over the other elements of a joint distribution. This works even when we are carrying a conditional term through. Therefore, we know that \\[\\pi\\left(\\mathbf{y}^* \\mid \\mathbf{y}\\right) = \\int f\\left(\\mathbf{y}^*, \\theta \\mid \\mathbf{y}\\right) d\\theta\\] Here, we have considered the joint distribution of the new data \\(\\mathbf{Y}^*\\) and the parameter \\(\\theta\\), then integrated over \\(\\theta\\). This statement would have been true for any choice of random variable, but using the parameter allows us to make use of the information we have collected on it through the old data. We now recall that any joint distribution can be written as the product of a conditional distribution and a marginal distribution; this is true even if we are already conditioning on another random variable: \\[f(\\mathbf{y}^*, \\theta \\mid \\mathbf{y}) = f(\\mathbf{y}^* \\mid \\mathbf{y}, \\theta) \\pi(\\theta \\mid \\mathbf{y})\\] Substituting this expression into the previous, we now have that the posterior predictive distribution must be \\[\\pi\\left(\\mathbf{y}^* \\mid \\mathbf{y}\\right) = \\int f(\\mathbf{y}^* \\mid \\mathbf{y}, \\theta) \\pi(\\theta \\mid \\mathbf{y}) d\\theta.\\] We now make use of the conditional independence. We take the first term inside the integral and apply the definition of a conditional density \\[f(\\mathbf{y}^* \\mid \\mathbf{y}, \\theta) = \\frac{f(\\mathbf{y}^*, \\mathbf{y} \\mid \\theta)}{f(\\mathbf{y} \\mid \\theta)}.\\] However, if we are willing to assume that \\(\\mathbf{Y}^*\\) is independent of \\(\\mathbf{Y}\\) given \\(\\theta\\), then the numerator becomes the product of \\(f(\\mathbf{y}^* \\mid \\theta)\\) and \\(f(\\mathbf{y} \\mid \\theta)\\), meaning we have that \\(f(\\mathbf{y}^* \\mid \\mathbf{y}, \\theta) = f(\\mathbf{y}^* \\mid \\theta)\\) under conditional independence. Substituting in this expression gives the resulting posterior predictive distribution. 13.2 Summary Once you have the posterior predictive distribution, you have everything there is to know about future observations given what we have observed. This distribution can be summarized just like any other. Summarizing the location (mean, median, mode) would result in point estimates for future observations. Or, we can construct interval estimates by defining a range for which the future observations would fall with some known probability. Keep in mind that we have switched our focus. We are now focused on a possible data point, not a parameter. Therefore, the support of the posterior predictive may not be the same as the support of the posterior distribution. "],["hypothesis-testing.html", "14 Hypothesis Testing 14.1 Point-Null Hypotheses 14.2 Model Comparison", " 14 Hypothesis Testing We have considered both estimation and prediction at this point. The third type of question often asked by researchers is which model (out of some pre-defined set) is most supported by the data. As with previous estimation and prediction, the Bayesian framework seeks to characterize the evidence for each model, given the data. Recall that for the M&amp;Ms Example (9.1), we derived the following posterior distribution: \\[\\pi(\\theta \\mid y) = (0.2359)\\delta(\\theta - 1/6) + (0.7641)\\delta(\\theta - 1/2)\\] after observing 10 green candies out of a bag of 30 with prior beliefs consistent with \\[\\pi(\\theta) = (0.4)\\delta(\\theta - 1/6) + (0.6)\\delta(\\theta - 1/2).\\] This example is nice for illustrating hypothesis testing because baked into the problem were essentially two hypotheses: \\[H_0: \\theta = 1/6 \\qquad \\text{vs.} \\qquad H_1: \\theta = 1/2\\] Here, the hypotheses are specific points the parameter could assume; in general, they represent regions. That is, we are generally interested in testing \\[H_0: \\theta \\in \\Theta_0 \\qquad \\text{vs.} \\qquad H_1: \\theta \\in \\Theta_1.\\] While not a requirement, in practice \\(\\Theta_0\\) and \\(\\Theta_1\\) are typically mutually exclusive sets which form a partition of the parameter space. Nothing prohibits us from having more than two hypotheses in this framework. Under the Bayesian framework, it is straightforward to compute probabilities of the form the probability \\(H_j\\) is true given the data observed. Under the Frequentist approach, the probability a hypothesis is true is nonsensical; however, under the Bayesian approach, we are using probability simply to characterize our uncertainty about the statement. For the M&amp;Ms Example, the posterior readily provides that \\[ \\begin{aligned} Pr\\left(H_0 \\mid y\\right) &amp;= Pr(\\theta = 1/6 \\mid y) = 0.2359 \\\\ Pr\\left(H_1 \\mid y\\right) &amp;= Pr(\\theta = 1/2 \\mid y) = 0.7641. \\end{aligned} \\] That is, after observing the data, we believe it is much more likely the that the bag represents a holiday pack than a typical pack. In fact, we can readily compute how much more likely we are: \\[\\frac{Pr\\left(H_1 \\mid y\\right)}{Pr\\left(H_0 \\mid y\\right)} = 3.24;\\] that is, we believe it is 3.24 times more likely to be a holiday pack than a typical pack. This is known as the posterior odds. Definition 14.1 (Posterior Odds) The posterior odds of \\(H_1\\) relative to \\(H_0\\) are given by \\[\\frac{Pr\\left(\\theta \\in \\Theta_1 \\mid \\mathbf{y}\\right)}{Pr\\left(\\theta \\in \\Theta_0 \\mid \\mathbf{y}\\right)}\\] where \\(\\Theta_j\\) represents the range of values under \\(H_j\\). Since the hypotheses are arbitrarily chosen, it is acceptable to compute the posterior odds of any hypothesis relative to any other. The posterior odds captures how strongly we favor one hypothesis over another given the observed data. We may be more interested in how much the data impacted our prior beliefs. For example, if the data simply confirmed our beliefs, that is not nearly as extraordinary as it completely reversing our beliefs. The Bayes Factor captures this impact. Definition 14.2 (Bayes Factor) A measure of how the observed data alters your prior beliefs about a hypothesis. The Bayes Factor in favor of the alternative hypothesis is the ratio of the posterior odds for the alternative to the prior odds for the alternative: \\[BF_{10} = \\left(\\frac{Pr\\left(\\theta \\in \\Theta_1 \\mid \\mathbf{y}\\right)}{Pr\\left(\\theta \\in \\Theta_0 \\mid \\mathbf{y}\\right)}\\right)\\left(\\frac{Pr\\left(\\theta \\in \\Theta_0\\right)}{Pr\\left(\\theta \\in \\Theta_1\\right)}\\right)\\] When doing theoretical derivations, it is often more convenient to work with the logarithm of the Bayes Factor. The Bayesian framework is about quantifying our uncertainty. The Bayes Factor measures how that uncertainty has been impacted by the observed data. Two independent papers made recommendations for how to interpret a Bayes Factor; these are simply rules of thumb. Table 14.1: Rules of thumb for interpreting the Bayes Factor. Strength of Evidence Jeffreys Scale Kass and Raftery Scale Weak \\(0 \\leq \\log_{10}(BF) \\lt 0.5\\) \\(0 \\leq \\log(BF) \\lt 1\\) Substantial \\(0.5 \\leq \\log_{10}(BF) \\lt 1\\) \\(2 \\leq \\log(BF) \\lt 3\\) Strong \\(1 \\leq \\log_{10}(BF) \\lt 2\\) \\(3 \\leq \\log(BF) \\lt 5\\) Decisive \\(2 \\leq \\log_{10}(BF)\\) \\(5 \\leq \\log(BF)\\) Take caution when interpreting a Bayes Factor; it quantifies the degree to which the data altered your prior beliefs. It is possible to have a really small Bayes Factor in favor of a hypothesis and yet believe overwhelmingly in that hypothesis given the data; the small Bayes Factor simply implies that you believed in that hypothesis before collecting the data as well. Conversely, it is possible to have a really large Bayes Factor in favor of a hypothesis and yet not distinguish between that hypothesis and another given the data; the large Bayes Factor simply implies that your beliefs about that hypothesis have dramatically changed. For the M&amp;Ms example, our Bayes Factor, in favor of having a holiday pack, is given by \\[BF_{10} = \\left(\\frac{0.7641}{0.2359}\\right)\\left(\\frac{0.4}{0.6}\\right) = 2.159.\\] The log-Bayes Factor is then 0.770, which is weak evidence under the Kass and Raftery scale. This is because prior to collecting data, we already believed that a holiday pack was more likely. As the data have added weight to that hypothesis, the data have not shifted our beliefs overwhelmingly. 14.1 Point-Null Hypotheses Technically speaking, hypothesis testing in the Bayesian framework requires little since we are already established to discuss our uncertainty about a statement about the parameters given the data using the posterior distribution. There is a common scenario which has a potential pitfall worth discussion: point-null hypotheses. Consider testing the following hypotheses: \\[H_0: \\theta = \\theta_0 \\qquad \\text{vs.} \\qquad H_1: \\theta \\neq \\theta_0\\] where here \\(\\Theta_0 = \\{\\theta_0\\}\\) is a singleton set. This can pose a problem for many prior distributions. To illustrate, consider computing the prior odds in favor of \\(H_1\\): \\[\\frac{Pr\\left(\\theta \\neq \\theta_0\\right)}{Pr\\left(\\theta = \\theta_0\\right)} = \\frac{\\int_{\\theta \\neq \\theta_0}^{} \\pi(\\theta) d\\theta}{\\int_{\\theta = \\theta_0}^{} \\pi(\\theta) d\\theta}.\\] For any continuous prior distribution, the numerator will be 1 and the denominator will be 0! Since continuous distributions always imply the probability the random variable takes a specific value is 0, a point-null hypothesis does not make sense with a continuous prior. The continous prior communicates you are infinitely more likely to believe the parameter is anywhere else but the specific value of \\(\\theta_0\\). There is simply a misalignment of beliefs. If you are truly interested in testing a point-null hypothesis, it must be that you believe the null hypothesis is somewhat likely. Therefore, it needs to be incorporated into the prior distribution. If you go into a study believing something is impossible, no amount of data will change your mind. You should only test a hypothesis if, a priori, you believe there is some chance the hypothesis is true. One way of incorporating point-null hypotheses into a prior is the use of a mixture distribution. We place a mass on the value of \\(\\theta_0\\) and then spread out the remaining probability along the support. Example 14.1 (Mixture Prior) Let \\(\\theta\\) be a parameter which has support \\(\\Theta\\), and let \\(\\theta_0 \\in \\Theta\\) be a particular value of interest. Suppose, a priori, we believe \\(Pr(\\theta = \\theta_0) = u\\) for \\(0 &lt; u &lt; 1\\). Then, a suitable prior has the form \\[\\pi(\\theta) = u \\delta(\\theta - \\theta_0) + (1 - u) \\pi(\\theta)\\] for some continuous density \\(\\pi(\\theta)\\) on the support \\(\\Theta\\). This type of density is not a discrete distribution; nor is it a continuous distribution (though we can work with it like it is continuous). 14.2 Model Comparison Hypothesis testing is a special case of model comparison, where in the Bayesian framework the model consists of both the likelihood and the prior. A Bayesian model consists of the choice for the likelihood as well as the choice for the prior. Consider the M&amp;Ms example (9.1); the problem could have been framed as a choice between two models: \\[ \\begin{aligned} \\text{Model 0}:&amp; \\quad \\pi(\\theta) = \\delta(\\theta - 1/6) \\\\ &amp;\\quad f(y \\mid \\theta) = \\binom{n}{\\theta} \\theta^y (1-\\theta)^{n-y} \\\\ \\text{Model 1}:&amp; \\quad \\pi(\\theta) = \\delta(\\theta - 1/2) \\\\ &amp;\\quad f(y \\mid \\theta) = \\binom{n}{\\theta} \\theta^y (1-\\theta)^{n-y} \\end{aligned} \\] where we believed, a priori, that \\(Pr(\\text{Model 1}) = 0.4\\) and \\(Pr(\\text{Model 2}) = 0.6\\). In this case, the models differed only in their choice of prior (which here simplifies further to which value of the parameter to select). In this example, we determined our choice of model by simply working with the posterior distribution. We would like to generalize this process to allow the model to alter both the likelihood and the prior distribution, and for us to place some prior probability on the entirety of the model. We are then interested in using the data to quantify the evidence for each model. To do this, we essentially consider the model \\(\\mathcal{M}\\) to be a parameter. This is known as a heirarchcial model because the priors on the parameter are conditional on the model, and then a further prior is placed on the model itself (it is a multi-level model). Model Comparison Let \\(\\mathcal{M}_j\\) represent the \\(j\\)-th potential model for a data generating process. Reflect the likelihood and prior as a function of the model. For example, we might write \\[ \\begin{aligned} \\text{Model 0}:&amp; \\quad f_0(\\mathbf{y} \\mid \\theta_0, \\mathcal{M}_0) \\\\ &amp; \\quad \\pi_0(\\theta_0 \\mid \\mathcal{M}_0) \\\\ &amp; \\quad \\pi(\\mathcal{M}_0) = Pr(\\mathcal{M}_0) \\\\ \\text{Model 1}:&amp; \\quad f_1(\\mathbf{y} \\mid \\theta_1, \\mathcal{M}_1) \\\\ &amp; \\quad \\pi_1(\\theta_1 \\mid \\mathcal{M}_1) \\\\ &amp; \\quad \\pi(\\mathcal{M}_1) = Pr(\\mathcal{M}_1) \\\\ \\end{aligned} \\] Notice we (potentially) allow the form of the likelihood, the parameters governing that likelihood, and the form of the prior to differ for each model. Our prior beliefs about the parameter are captured within each prior, but we also have prior beleifs about the model itself  how likely each model is. We are interested in determining \\(Pr(\\mathcal{M}_j \\mid \\mathbf{Y})\\) for each \\(j\\). Under this framework, we could compute the likelihood of each model can be written as \\[ \\begin{aligned} Pr\\left(\\mathcal{M}_j \\mid \\mathbf{Y}\\right) &amp;= \\frac{f_j(\\mathbf{y} \\mid \\mathcal{M}_j) Pr(\\mathcal{M}_j)}{\\sum_{j} f_j(\\mathbf{y} \\mid \\mathcal{M}_j) Pr(\\mathcal{M}_j)} \\\\ f_j(\\mathbf{y} \\mid \\mathcal{M}_j) &amp;= \\int f_j(\\mathbf{y} \\mid \\theta_j, \\mathcal{M}_j) \\pi_j(\\theta_j \\mid \\mathcal{M}_j) d\\theta_j \\end{aligned} \\] This is an iterated application of Bayes Theorem. Definition 14.3 (Evidence for a Model) Under the Model Comparison framework defined above, the evidence for \\(\\mathcal{M}_j\\) is defined as \\[f_j(\\mathbf{y} \\mid \\mathcal{M}_j) = \\int f_j(\\mathbf{y} \\mid \\theta_j, \\mathcal{M}_j) \\pi_j(\\theta_j \\mid \\mathcal{M}_j) d\\theta_j\\] The evidence for a model is a number; once the data is observed, it is a function only of the known data and is therefore a constant. The evidence is really just the prior predictive distribution under a particular model evaluated at the observed data. It may seem strange to use the prior predictive distribution when defining the evidence instead of the posterior predictive, but keep in mind that within model comparison, the model itself is the parameter of interest. Changing either the likelihood or the prior will impact the evidence. The evidence can also be used to compute the Bayes Factor for one model over another. Definition 14.4 (Bayes Factor for Model Comparison) The Bayes factor in favor of Model 1 is \\[ \\begin{aligned} BF_{10} &amp;= \\left(\\frac{Pr(\\mathcal{M}_1 \\mid \\mathbf{y})}{Pr(\\mathcal{M}_0 \\mid \\mathbf{y})}\\right)\\left(\\frac{Pr(\\mathcal{M}_0)}{Pr(\\mathcal{M}_1)}\\right) \\\\ &amp;= \\left(\\frac{f_1(\\mathbf{y} \\mid \\mathcal{M}_1) Pr(\\mathcal{M}_1)}{f_0(\\mathbf{y} \\mid \\mathcal{M}_0) Pr(\\mathcal{M}_0)}\\right)\\left(\\frac{Pr(\\mathcal{M}_0)}{Pr(\\mathcal{M}_1)}\\right) \\\\ &amp;= \\frac{f_1(\\mathbf{y} \\mid \\mathcal{M}_1)}{f_0(\\mathbf{y} \\mid \\mathcal{M}_0)} \\end{aligned} \\] That is, the Bayes factor is a ratio of the evidence for each model. Model comparison simply extends our framework by the inclusion of another parameter. That parameter, the model itself, just happens to be discrete. Our goal is to use our machinery to quantify the uncertainty in each model given the data observed. "],["constructing-priors.html", "15 Constructing Prior Distributions 15.1 Elicitation from Experts 15.2 Mixtures 15.3 Chains 15.4 Non-Informative Priors", " 15 Constructing Prior Distributions The selection of a prior distribution is critical to the Bayesian framework; it is also the most criticized component. There is rarely sufficient prior information to determine an exact prior; that is, rarely do we know for certain the family which represents the distribution as well as the exact parameters. Instead, we make some modeling assumptions, as with any analysis. In this chapter, we examine some common paths when constructing prior distributions and the implications of allowing the prior distribution to vary across analysts. 15.1 Elicitation from Experts Ideally, the prior distribution would not be arbitrary but guided by experts. Up to this point, we have focused on using statements by experts to form a parametric approximation to the prior information. We have elicited information about the uncertainty in order to determine values for the hyperparameters  those values that determine the specific shape of the prior distribution. Often, these priors have been conjugate priors. Definition 15.1 (Conjugate Prior) A prior chosen such that the posterior distribution belongs to the same family as the prior, with only updated parameters. That is, if the prior is a Beta distribution, the posterior is also a Beta distribution. This was done historically in order to simplify computation in an era where computing power was limited. In the era of higher-speed computing, this is no longer a requirement. One argument for the use of conjugate priors is that the form is invariant to the data; that is, the data is restricted in what it can say about the parameter. It can update our beliefs, but it cannot update the family which encodes those beliefs. While we will not go into details here, it is almost always possible to construct a conjugate prior. And, if chosen carefully, that prior can approximate nearly any prior information you want. The posterior distribution is always a combination of the prior distribution and the likelihood. Conjugate priors make that very clear. As the sample gets large, the prior distribution is swamped by the data; and, as the sample size increases, Bayesian inference agrees with Frequentist inference. When you are unable to determine a suitable parametric approximation, a histogram approach is possible. Definition 15.2 (Histogram Approach to Prior Construction) Using expert information, attach probability to various intervals for the parameter: Define \\(m+1\\) intervals over the parameter space. Assign probability to each interval: \\(\\pi_j = Pr(\\theta_{j-1} &lt; \\theta &lt; \\theta_j)\\) for each \\(j=1,2,\\dotsc,m\\) where \\(\\theta_0\\) represents the lower boundary of the support and \\(\\theta_{m+1}\\) represents the upper boundary of the support. Set the prior \\(\\pi(\\theta)\\) to be the piecewise distribution over this interval where \\(\\sum_{j=1}^{m+1} \\pi_j = 1\\). There have been critiques of eliciting information from experts. Estimates given may be biased, due to the current availability of data on which the experts are making their informed decisions. We tend to be overconfident in our opinions or go with our initial reaction instead of allowing our beliefs to be updated. We also tend to want to create the prior only after observing the data. The prior should always be constructed prior to observing data. The experts may not actually represent a reasonable sample to capture widespread prior belief. How does one determine who is expertly qualified to speak on a particular topic? How do you rank levels of expertise? We mention these critiques because more important than the choices you make is that those choices are clearly documented. It is okay to construct work that others critique; that is how science develops. No study is perfect, and being able to identify and own the limitations of our study and analysis is critical to the development of knowledge. 15.2 Mixtures Suppose we would like to work with a parametric approximation, but we cannot find a parametric family which captures the structure suggested by the prior information. In these cases, combining multiple distributions may be appropriate. As an example, consider the prior in Figure 15.1 for a parameter which has support \\((0, 1)\\). Figure 15.1: Illustration of a mixture prior for a parameter on the interval (0, 1). For a parameter with support \\((0, 1)\\), we naturally think of the Beta distribution. However, it is impossible to choose a Beta distribution which has the shape illustrated in Figure 15.1. Definition 15.3 (Mixture Distribution) A distribution formed by taking a weighted sum of other distributions. \\[\\pi(\\theta) = \\sum_{k=1}^{K} w_k \\pi_k(\\theta)\\] where \\(\\sum_{k=1}^{K} w_k = 1\\). We actually suggested the use of a mixture prior in dealing with point-null hypotheses. It turns out that if each component of the mixture distribution \\(\\pi_k(\\theta)\\) is a member of the conjugate family, the entire prior will be conjugate (a weighted average of distributions). However, nothing requires that the individual components be of the same family (we could mix a Normal distribution with a t-distribution, for example). While we illustrate the use of a mixture distribution for the prior, nothing stops us from using a mixture distribution for the likelihood. It has been shown that a mixture distribution can approximate any distribution. That is, if we choose \\(K\\) to be large enough, we can approximate any distributional shape with a mixture distribution. 15.3 Chains In this collection of chapters, we have developed the fundamental concepts of Bayesian inference. We have largely avoided specific examples within this text, but we may have had a single parameter in mind whenever we discussed \\(\\theta\\). Many interesting questions, however, involve models for the data that are depend upon multiple parameters. These types of problems often necessitate the need for numerical solutions, which we will address in the next unit. Here, we simply discuss that a common tool for addressing priors over multiple parameters. When \\(\\theta\\) is a parameter vector, then \\(\\pi(\\theta)\\) is actually a joint density across all parameters. Therefore, one key decision that must be made is whether, a priori, we believe these parameters to be independent of one another. Example 15.1 (Heights) During early development, children are regularly benchmarked against national growth charts. One such chart traces a childs height as they grow. However, these charts were developed using the entire population of healthy children. Suppose I am interested in developing such a chart for children with Hispanic parents, as I believe they tend to be a bit shorter, on average. It is typical to model heights as Normally distributed. We need to develop a prior for the unknown parameters. The likelihood for the above example is readily available if we are willing to assume a random sample of \\(n\\) children (of the same age) born to Hispanic parents: \\[ \\begin{aligned} f(\\mathbf{y} \\mid \\mu, \\tau) &amp;= \\prod_{i=1}^{n} \\frac{\\tau^{1/2}}{\\sqrt{2\\pi}} e^{-\\tau/2 (y_i - \\mu)^2} \\\\ &amp;= \\frac{\\tau^{n/2}}{(2\\pi)^{n/2}} e^{-(\\tau/2)\\sum_{i=1}^{n}(y_i - \\mu)^2} \\end{aligned} \\] where we have defined the likelihood in terms of the mean \\(\\mu\\) and the precision \\(\\tau = 1/\\sigma^2\\), instead of the variance. Suppose we believe the parameters are independent of one another, then it is reasonable to propose the prior distributions independently; this leads to \\[ \\begin{aligned} \\pi(\\mu) &amp;= \\frac{\\sqrt{b}}{\\sqrt{2\\pi}} e^{-b/2 (\\mu - a)^2} \\\\ \\pi(\\tau) &amp;= \\frac{s^r}{\\Gamma(r)} \\tau^{r - 1} e^{-s\\tau} \\\\ \\pi(\\mu, \\tau) &amp;= \\pi(\\mu) \\pi(\\tau) \\end{aligned} \\] Of course, this is a modeling assumption. A different set of beliefs would lead to a different structure for the prior. For example, consider \\[ \\begin{aligned} \\pi(\\tau) &amp;= \\frac{s^2}{\\Gamma(r)} \\tau^{r - 1} e^{-s\\tau} \\\\ \\pi(\\mu \\mid \\tau) &amp;= \\frac{\\sqrt{\\tau}}{\\sqrt{2\\pi}} e^{-\\tau/2 (\\mu - a)^2} \\\\ \\pi(\\mu, \\tau) &amp;= \\pi(\\mu \\mid \\tau) \\pi(\\tau) \\end{aligned} \\] This has a hierarchical structure in which the distribution of the mean \\(\\mu\\) depends on the precision \\(\\tau\\). The joint distribution of the parameters (prior to seeing the data) is then the product of the marginal distribution of \\(\\tau\\) and the conditional distribution of \\(\\mu \\mid \\tau\\). As an aside, consider the formation of the posterior; Bayes Theorem will have a denominator of the form \\[\\int \\int f(\\mathbf{y} \\mid \\mu, \\tau) \\pi(\\mu, \\tau) d\\mu d\\tau\\] regardless of which prior formation we develop. The more parameters we have, the more complex the integration in the denominator; this is what motivates the next unit. This process of defining a prior in stages by conditioning on other parameters is known as a chaining. 15.4 Non-Informative Priors The discussion above assumes that our goal is to encode a set of prior information into a distribution. What if we have very little prior information? How do we encode ignorance? Definition 15.4 (Laplac's Prior) Also known as a flat prior, it considers the form \\[\\pi(\\theta) = 1 \\qquad \\forall \\theta \\in \\Theta\\] This prior is often improper; that is, \\(\\int \\pi(\\theta) d\\theta = \\infty\\). Since we are taking the prior to be a constant over the entire support, not just an interval, whenever that support is not bounded, the prior will not be a true density. This seems like it is breaking all the rules, and to some degree it is, but it is still commonly used. This is often used as a default prior when no (or little) prior information is available. A flat prior cannot be expected to represent total ignorance. It is essentially saying that no matter how large of a value you imagine, there is still infinite probability that the parameter takes a value larger than that. The goal is simply to choose a prior that is easily overwhelmed by the likelihood. The benefit of a flat prior is that the posterior distribution is proportional to the likelihood. The idea here is to make the Bayesian framework dependent solely on the data, similar to a Frequentist approach (though the two are still not guaranteed to give the same results). Flat priors are a subset of a larger class of priors that is an active area of research in which the prior is determined solely by the form of the likelihood. Definition 15.5 (Noninformative Prior) A prior which is derived solely on the basis of the likelihood. This seems like a happy middle ground between Bayesians and those who dislike the subjective nature of a prior distribution. So, why is this not the standard? On the one hand, true Bayesians argue that we should make use of prior information; we should not seek to make use of only the data available in that single study. This allows the information from one study to become the prior information for a follow-up study instead of beginning from scratch. Second, there is a potential pitfall when using noninformative priors when they are improper  it is possible for the posterior distribution to be improper (which is a nice way of saying it is not a distribution at all)! If the posterior distribution is improper, it cannot yield any valid inference on the parameters. The Bayes Factor should not be computed when you have an improper prior as the prior odds are not defined since there is no valid probability of each hypothesis a priori. An improper prior can lead to an improper posterior; however, a proper prior will always lead to a proper posterior. The danger is that software which automates Bayesian analyses currently have no way of checking if a posterior is proper; so, this must be done manually. As computing the posterior can be difficult (the entire reason for the next unit), this often involves bounding the integral in some way  a job for true mathematicians. Fear around improper priors often leads to what are known as vague priors. This is taking a parametric family and choosing the hyperparameters to result in massive variances so that the prior, while proper, appears flat over the parameter space. The idea here is to allow the data to easily overwhelm any prior information. Noninformative priors try to make it easy for the likelihood to dominate the prior in the computation of the posterior distribution. "],["additional-study-design.html", "16 Additional Study Design 16.1 Two Types of Studies", " 16 Additional Study Design 16.1 Two Types of Studies Thinking about how the data was collected helps us determine how the results generalize beyond the sample itself (to what population the results apply). When our question of interest is about the relationship between two variables (as most questions are), we must also carefully consider the study design. Too often separated from the statistical analysis that follows, keeping the study design in mind should guide the analysis as well as inform us about the conclusions we can draw. In order to illustrate how study design can impact the results, consider the following example. Example 16.1 (Kangaroo Care) At birth, infants have low levels of Vitamin K, a vitamin needed in order to form blood clots. Though rare, without the ability for her blood to clot, an infant could develop a serious bleed. In order to prevent this, the American Academy of Pediatrics recommends that all infants be given a Vitamin K shot shortly after birth in order to raise Vitamin K levels. As with any shot, there is typically discomfort to the infant, which can be very discomforting to new parents. Kangaroo Care is a method of holding a baby which emphasizes skin-to-skin contact. The child, who is dressed only in a diaper, is placed upright on the parents bare chest; a light blanket is draped over the child. Suppose we are interested in determining if utilizing the method while giving the child a Vitamin K shot reduces the discomfort in the infant, as measured by the total amount of time the child cries following the shot. Contrast the following two potential study designs: We allow the attending nurse to determine whether Kangaroo Care is initiated prior to giving the Vitamin K shot. Following the shot, we record the total time (in seconds) the child cries. We flip a coin. If it comes up heads, the nurse should have the parents implement Kangaroo Care prior to giving the Vitamin K shot; if it comes up tails, the nurse should give the Vitamin K shot without implementing Kagaroo Care. Following the shot, we record the total time (in seconds) the child cries. Note, in both study designs (A) and (B), we only consider term births which have no complications to avoid situations that might alter the timing of the Vitamin K shot or the ability to implement Kangaroo Care. Note that there are some similarities in the two study designs: The underlying population is the same for both designs  infants born at term with no complications. There are two groups being compared in both designs  the Kangaroo Care group and the no Kangaroo Care group. The response (variable of interest) is the same in both designs  the time (in seconds) the infant cries. There is action taken by the researcher in both designs  a Vitamin K shot is given to the child. There is one prominent difference between the two study designs: For design (A), the choice of Kangaroo Care is left up to the nurse (self-selected); for design (B), the choice of Kangaroo is assigned to the nurse by the researcher, and this selection is made at random. Design (A) is an example of an observational study; design (B) is a controlled experiment. Definition 16.1 (Observational Study) A study in which each subject self-selects into one of groups being compared in the study. The phrase self-selects is used very loosely here and can include studies in which the groups are defined by an inherent characteristic or the groups are chosen haphazardly. Definition 16.2 (Controlled Experiment) A study in which each subject is randomly assigned to one of the groups being compared in the study. It is common to think that anytime the environment is controlled by the researcher that a controlled experiment is taking place, but the defining characteristic is the random assignment to groups (sometimes referred to as the factor under study or treatment groups). In the example above, both study designs involved a controlled setting (the delivery room of a hospital) in which trained staff (the nurse) deliver the shot. However, only design (B) is a controlled experiment because the researchers randomly determined into which group the infant would be placed. To understand the impact of random allocation, suppose that we had conducted a study using design (A); further, the results suggest that those infants who were given a shot while using Kangaroo Care cried for a shorter time period, on average. Can we conclude that it was the Kangaroo Care that led to the shorter crying time? Maybe. Consider the following two potential explanations for the resulting data: Kangaroo Care is very effective; as a result, those children who were given Kangaroo Care had reduced crying time, on average, following the Vitamin K shot. It turns out that those nurses who chose to implement Kangaroo Care (remember, they have a choice under design (A) whether they implement the method) were also the nurses with a gentler bedside manner. Therefore, these nurses tended to be very gentle when giving the Vitamin K shot whereas the nurses who chose not to implement Kangaroo Care tended to just jab the needle in when giving the shot. As a result, the reduced crying time is not a result of the Kangaroo Care but the manner in which the shot was given. The problem is that we are unable to determine which of the explanations is correct. Given the data we have collected, we are unable to tease out the effect of the Kangaroo Care from that of the nurses bedside manner. As a result, we are able to say we observed an association between the use of Kangaroo Care and reduced crying time, but we are unable to conclude that Kangaroo Care caused a reduction in the crying time (that is, there may not be a relationship between the two variables). In this hypothetical scenario, the nurses bedside manner is called a confounder. Definition 16.3 (Confounding) When the effect of a variable on the response is mis-represented due to the presence of a third, potentially unobserved, variable known as a confounder. Confounders can mask the relationship between the factor under study and the response. There is a documented association between ice cream sales and the risk of shark attacks. As ice cream sales increase, the risk of a shark attack also tends to increase. This does not mean that if a small city in the Midwest increases its ice cream sales that the citizens are at higher risk of being attacked by a shark. As Figure 16.1 illustrates, there is a confounder  temperature. As the temperatures increase, people tend to buy more ice cream; as the temperature increases, people tend to go to the beach increasing the risk of a shark attack. Two variables can appear to be related as a result of a confounder. Figure 16.1: Illustration of a confounding variable. The confounder, related to both the factor and the treatment can make it appear as though there is a causal relationship when none exists. Confounders are variables that influence both the factor of interest and the response. Observational studies are subject to confounding; thus, controlled experiments are often considered the gold standard in research because they allow us to infer cause-and-effect relationships from the data. Why does the random allocation make such an impact? Because it removes the impact of confounders. Lets return to the hypothetical Vitamin-K study. Suppose there are nurses with a gentle bedside manner and those who are a little less gentle. If the infants are randomly assigned to one of the two treatment groups, then for every gentle nurse who is told to implement Kangaroo Care while giving the shot, there tends to be a gentle nurse who is told to not implement Kangaroo Care. Similarly, for every mean nurse who is told to implement Kangaroo Care while giving a shot, there tends to be a mean nurse who is told to not implement Kangaroo Care. This is illustrated in Figure 16.2. For an observational study, the treatment groups can be unbalanced; for example, the figure illustrates a case in which there is a higher fraction (11/12 compared to 1/4) of friendly nurses in the Kangaroo Care group compared to the No Kangaroo Care group. For the controlled experiment however, the treatment groups tend to be balanced; there is approximately the same fraction of friendly nurses in both groups. Random assignment is the great equalizer. It tends to result in groups which are similar in all respects; therefore, any differences we observe between the groups must be due to the grouping and not an underlying confounding variable. Figure 16.2: Illustration of the impact of random assignment in study design. For the observational study, the treatment groups are unbalanced. For the controlled experiment, the treatment groups are balanced. Randomly assigning subjects to groups balances the groups with respect to any confounders; that is, the groups being compared are similar. Therefore, any differences between the two groups can be attributed to the grouping factor itself, leading to cause-and-effect conclusions. While controlled experiments are a fantastic study design, we should not discount the use of observational studies. Consider the Deepwater Horizon Case Study; suppose we are interested in the following question: Is there evidence that volunteers who are directly exposed to oil have an increased risk of developing adverse respiratory symptoms compared to those who are not directly exposed to oil? The response is whether a volunteer develops adverse respiratory symptoms; the factor of interest is whether the volunteer has direct exposure to oil. We could conduct a controlled experiment by randomly determining which volunteers are assigned to wildlife clean up and which are assigned to administrative tasks, for example. However, it may be that volunteer tasks need to be determined by skillset or by greatest need at the time the person volunteers. It may not be feasible to randomly assign volunteers to specific positions. Or, it could be that the data was obtained after the fact; that is, the data is not the result of a planned study in which case random assignment is not possible because volunteers self-selected into positions in the past. If random assignment is not possible, it does not mean the data is useless. But, it does mean we will need to be sure we address the potential confounding when performing the analysis and discussing the results. The big idea is that in order to make causal conclusions, we must be able to state that the groups being compared are balanced with respect to any potential confounders; random assignment is one technique for accomplishing this. "],["references.html", "References", " References "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
