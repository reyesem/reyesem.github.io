<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>Statistical Foundations for Engineers and Scientists</title>
  <meta name="description" content="Course notes for MA223 (Engineering Statistics I) at Rose-Hulman Institute of Technology.">
  <meta name="generator" content="bookdown 0.5 and GitBook 2.6.7">

  <meta property="og:title" content="Statistical Foundations for Engineers and Scientists" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="Course notes for MA223 (Engineering Statistics I) at Rose-Hulman Institute of Technology." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Statistical Foundations for Engineers and Scientists" />
  
  <meta name="twitter:description" content="Course notes for MA223 (Engineering Statistics I) at Rose-Hulman Institute of Technology." />
  

<meta name="author" content="Eric M Reyes">



  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="Regmodel.html">
<link rel="next" href="Regassessment.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />










<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Statistical Modeling</a></li>

<li class="divider"></li>
<li class="part"><span><b>I Unit I: Language and Logic of Inference</b></span></li>
<li class="chapter" data-level="1" data-path="Basics.html"><a href="Basics.html"><i class="fa fa-check"></i><b>1</b> The Statistical Process</a><ul>
<li class="chapter" data-level="1.1" data-path="Basics.html"><a href="Basics.html#overview-of-drawing-inference"><i class="fa fa-check"></i><b>1.1</b> Overview of Drawing Inference</a></li>
<li class="chapter" data-level="1.2" data-path="Basics.html"><a href="Basics.html#anatomy-of-a-dataset"><i class="fa fa-check"></i><b>1.2</b> Anatomy of a Dataset</a></li>
<li class="chapter" data-level="1.3" data-path="Basics.html"><a href="Basics.html#a-note-on-codebooks"><i class="fa fa-check"></i><b>1.3</b> A Note on Codebooks</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="CaseDeepwater.html"><a href="CaseDeepwater.html"><i class="fa fa-check"></i><b>2</b> Case Study: Health Effects of the Deepwater Horizon Oil Spill</a></li>
<li class="chapter" data-level="3" data-path="Questions.html"><a href="Questions.html"><i class="fa fa-check"></i><b>3</b> Asking the Right Questions</a><ul>
<li class="chapter" data-level="3.1" data-path="Questions.html"><a href="Questions.html#characterizing-a-variable"><i class="fa fa-check"></i><b>3.1</b> Characterizing a Variable</a></li>
<li class="chapter" data-level="3.2" data-path="Questions.html"><a href="Questions.html#framing-the-question"><i class="fa fa-check"></i><b>3.2</b> Framing the Question</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="Data.html"><a href="Data.html"><i class="fa fa-check"></i><b>4</b> Gathering the Evidence (Data Collection)</a><ul>
<li class="chapter" data-level="4.1" data-path="Data.html"><a href="Data.html#what-makes-a-sample-reliable"><i class="fa fa-check"></i><b>4.1</b> What Makes a Sample Reliable</a></li>
<li class="chapter" data-level="4.2" data-path="Data.html"><a href="Data.html#poor-methods-of-data-collection"><i class="fa fa-check"></i><b>4.2</b> Poor Methods of Data Collection</a></li>
<li class="chapter" data-level="4.3" data-path="Data.html"><a href="Data.html#preferred-methods-of-sampling"><i class="fa fa-check"></i><b>4.3</b> Preferred Methods of Sampling</a></li>
<li class="chapter" data-level="4.4" data-path="Data.html"><a href="Data.html#two-types-of-studies"><i class="fa fa-check"></i><b>4.4</b> Two Types of Studies</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="Summaries.html"><a href="Summaries.html"><i class="fa fa-check"></i><b>5</b> Presenting the Evidence (Summarizing Data)</a><ul>
<li class="chapter" data-level="5.1" data-path="Summaries.html"><a href="Summaries.html#characteristics-of-a-distribution-summarizing-a-single-variable"><i class="fa fa-check"></i><b>5.1</b> Characteristics of a Distribution (Summarizing a Single Variable)</a></li>
<li class="chapter" data-level="5.2" data-path="Summaries.html"><a href="Summaries.html#summarizing-relationships"><i class="fa fa-check"></i><b>5.2</b> Summarizing Relationships</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="SamplingDistns.html"><a href="SamplingDistns.html"><i class="fa fa-check"></i><b>6</b> Assessing the Evidence (Quantifying the Variability in Estimates)</a><ul>
<li class="chapter" data-level="6.1" data-path="SamplingDistns.html"><a href="SamplingDistns.html#conceptualizing-the-sampling-distribution"><i class="fa fa-check"></i><b>6.1</b> Conceptualizing the Sampling Distribution</a></li>
<li class="chapter" data-level="6.2" data-path="SamplingDistns.html"><a href="SamplingDistns.html#example-of-a-sampling-distribution"><i class="fa fa-check"></i><b>6.2</b> Example of a Sampling Distribution</a></li>
<li class="chapter" data-level="6.3" data-path="SamplingDistns.html"><a href="SamplingDistns.html#modeling-the-sampling-distribution"><i class="fa fa-check"></i><b>6.3</b> Modeling the Sampling Distribution</a></li>
<li class="chapter" data-level="6.4" data-path="SamplingDistns.html"><a href="SamplingDistns.html#using-a-model-for-the-sampling-distributions-confidence-intervals"><i class="fa fa-check"></i><b>6.4</b> Using a Model for the Sampling Distributions (Confidence Intervals)</a></li>
<li class="chapter" data-level="6.5" data-path="SamplingDistns.html"><a href="SamplingDistns.html#bringing-it-all-together"><i class="fa fa-check"></i><b>6.5</b> Bringing it All Together</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="NullDistns.html"><a href="NullDistns.html"><i class="fa fa-check"></i><b>7</b> Quantifying the Evidence (Rejecting Bad Models)</a><ul>
<li class="chapter" data-level="7.1" data-path="NullDistns.html"><a href="NullDistns.html#some-subtleties"><i class="fa fa-check"></i><b>7.1</b> Some Subtleties</a></li>
<li class="chapter" data-level="7.2" data-path="NullDistns.html"><a href="NullDistns.html#assuming-the-null-hypothesis"><i class="fa fa-check"></i><b>7.2</b> Assuming the Null Hypothesis</a></li>
<li class="chapter" data-level="7.3" data-path="NullDistns.html"><a href="NullDistns.html#using-the-null-distribution"><i class="fa fa-check"></i><b>7.3</b> Using the Null Distribution</a></li>
<li class="chapter" data-level="7.4" data-path="NullDistns.html"><a href="NullDistns.html#sampling-distributions-vs.null-distributions"><i class="fa fa-check"></i><b>7.4</b> Sampling Distributions vs. Null Distributions</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="RecapLanguage.html"><a href="RecapLanguage.html"><i class="fa fa-check"></i><b>8</b> Using the Tools Together</a><ul>
<li class="chapter" data-level="8.1" data-path="RecapLanguage.html"><a href="RecapLanguage.html#framing-the-question-fundamental-idea-i"><i class="fa fa-check"></i><b>8.1</b> Framing the Question (Fundamental Idea I)</a></li>
<li class="chapter" data-level="8.2" data-path="RecapLanguage.html"><a href="RecapLanguage.html#getting-good-data-fundamental-idea-ii"><i class="fa fa-check"></i><b>8.2</b> Getting Good Data (Fundamental Idea II)</a></li>
<li class="chapter" data-level="8.3" data-path="RecapLanguage.html"><a href="RecapLanguage.html#presenting-the-data-fundamental-idea-iii"><i class="fa fa-check"></i><b>8.3</b> Presenting the Data (Fundamental Idea III)</a></li>
<li class="chapter" data-level="8.4" data-path="RecapLanguage.html"><a href="RecapLanguage.html#quantifying-the-variability-in-the-estimate-fundamental-idea-iv"><i class="fa fa-check"></i><b>8.4</b> Quantifying the Variability in the Estimate (Fundamental Idea IV)</a></li>
<li class="chapter" data-level="8.5" data-path="RecapLanguage.html"><a href="RecapLanguage.html#quantifying-the-evidence-fundamental-idea-v"><i class="fa fa-check"></i><b>8.5</b> Quantifying the Evidence (Fundamental Idea V)</a></li>
<li class="chapter" data-level="8.6" data-path="RecapLanguage.html"><a href="RecapLanguage.html#summary"><i class="fa fa-check"></i><b>8.6</b> Summary</a></li>
</ul></li>
<li class="part"><span><b>II Unit II: Comparing the Average Response Across Groups</b></span></li>
<li class="chapter" data-level="9" data-path="CaseOrganic.html"><a href="CaseOrganic.html"><i class="fa fa-check"></i><b>9</b> Case Study: Organic Foods and Superior Morals</a></li>
<li class="chapter" data-level="10" data-path="ANOVAquestions.html"><a href="ANOVAquestions.html"><i class="fa fa-check"></i><b>10</b> Framing the Question</a><ul>
<li class="chapter" data-level="10.1" data-path="ANOVAquestions.html"><a href="ANOVAquestions.html#general-setting"><i class="fa fa-check"></i><b>10.1</b> General Setting</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="ANOVAdata.html"><a href="ANOVAdata.html"><i class="fa fa-check"></i><b>11</b> Study Design</a><ul>
<li class="chapter" data-level="11.1" data-path="ANOVAdata.html"><a href="ANOVAdata.html#aspects-of-a-well-designed-experiment"><i class="fa fa-check"></i><b>11.1</b> Aspects of a Well Designed Experiment</a></li>
<li class="chapter" data-level="11.2" data-path="ANOVAdata.html"><a href="ANOVAdata.html#collecting-observational-data"><i class="fa fa-check"></i><b>11.2</b> Collecting Observational Data</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="ANOVAsummaries.html"><a href="ANOVAsummaries.html"><i class="fa fa-check"></i><b>12</b> Presenting the Data</a></li>
<li class="chapter" data-level="13" data-path="ANOVAteststat.html"><a href="ANOVAteststat.html"><i class="fa fa-check"></i><b>13</b> Quantifying the Evidence</a><ul>
<li class="chapter" data-level="13.1" data-path="ANOVAteststat.html"><a href="ANOVAteststat.html#partitioning-variability"><i class="fa fa-check"></i><b>13.1</b> Partitioning Variability</a></li>
<li class="chapter" data-level="13.2" data-path="ANOVAteststat.html"><a href="ANOVAteststat.html#forming-a-standardized-test-statistic"><i class="fa fa-check"></i><b>13.2</b> Forming a Standardized Test Statistic</a></li>
<li class="chapter" data-level="13.3" data-path="ANOVAteststat.html"><a href="ANOVAteststat.html#obtaining-a-p-value"><i class="fa fa-check"></i><b>13.3</b> Obtaining a P-value</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="ANOVAmodel.html"><a href="ANOVAmodel.html"><i class="fa fa-check"></i><b>14</b> Building the Statistical Model</a><ul>
<li class="chapter" data-level="14.1" data-path="ANOVAmodel.html"><a href="ANOVAmodel.html#general-formulation"><i class="fa fa-check"></i><b>14.1</b> General Formulation</a></li>
<li class="chapter" data-level="14.2" data-path="ANOVAmodel.html"><a href="ANOVAmodel.html#statistical-model-for-a-quantitative-response-and-a-categorical-predictor"><i class="fa fa-check"></i><b>14.2</b> Statistical Model for A Quantitative Response and a Categorical Predictor</a></li>
<li class="chapter" data-level="14.3" data-path="ANOVAmodel.html"><a href="ANOVAmodel.html#conditions-on-the-error-distribution"><i class="fa fa-check"></i><b>14.3</b> Conditions on the Error Distribution</a></li>
<li class="chapter" data-level="14.4" data-path="ANOVAmodel.html"><a href="ANOVAmodel.html#simulating-the-null-distribution"><i class="fa fa-check"></i><b>14.4</b> Simulating the Null Distribution</a></li>
<li class="chapter" data-level="14.5" data-path="ANOVAmodel.html"><a href="ANOVAmodel.html#recap"><i class="fa fa-check"></i><b>14.5</b> Recap</a></li>
</ul></li>
<li class="chapter" data-level="15" data-path="ANOVAclassical.html"><a href="ANOVAclassical.html"><i class="fa fa-check"></i><b>15</b> Classical ANOVA Model</a><ul>
<li class="chapter" data-level="15.1" data-path="ANOVAclassical.html"><a href="ANOVAclassical.html#modeling-the-population"><i class="fa fa-check"></i><b>15.1</b> Modeling the Population</a></li>
<li class="chapter" data-level="15.2" data-path="ANOVAclassical.html"><a href="ANOVAclassical.html#adding-the-assumption-of-normality"><i class="fa fa-check"></i><b>15.2</b> Adding the Assumption of Normality</a></li>
<li class="chapter" data-level="15.3" data-path="ANOVAclassical.html"><a href="ANOVAclassical.html#impact-of-normality-assumption"><i class="fa fa-check"></i><b>15.3</b> Impact of Normality Assumption</a></li>
<li class="chapter" data-level="15.4" data-path="ANOVAclassical.html"><a href="ANOVAclassical.html#analysis-of-organic-food-case-study"><i class="fa fa-check"></i><b>15.4</b> Analysis of Organic Food Case Study</a></li>
<li class="chapter" data-level="15.5" data-path="ANOVAclassical.html"><a href="ANOVAclassical.html#recap-1"><i class="fa fa-check"></i><b>15.5</b> Recap</a></li>
</ul></li>
<li class="chapter" data-level="16" data-path="ANOVAassessment.html"><a href="ANOVAassessment.html"><i class="fa fa-check"></i><b>16</b> Assessing Modeling Assumptions</a><ul>
<li class="chapter" data-level="16.1" data-path="ANOVAassessment.html"><a href="ANOVAassessment.html#assessing-independence"><i class="fa fa-check"></i><b>16.1</b> Assessing Independence</a></li>
<li class="chapter" data-level="16.2" data-path="ANOVAassessment.html"><a href="ANOVAassessment.html#assessing-homoskedasticity"><i class="fa fa-check"></i><b>16.2</b> Assessing Homoskedasticity</a></li>
<li class="chapter" data-level="16.3" data-path="ANOVAassessment.html"><a href="ANOVAassessment.html#assessing-normality"><i class="fa fa-check"></i><b>16.3</b> Assessing Normality</a></li>
<li class="chapter" data-level="16.4" data-path="ANOVAassessment.html"><a href="ANOVAassessment.html#general-tips-for-assessing-assumptions"><i class="fa fa-check"></i><b>16.4</b> General Tips for Assessing Assumptions</a></li>
</ul></li>
<li class="chapter" data-level="17" data-path="ANOVArecap.html"><a href="ANOVArecap.html"><i class="fa fa-check"></i><b>17</b> Using the Tools Together</a><ul>
<li class="chapter" data-level="17.1" data-path="ANOVArecap.html"><a href="ANOVArecap.html#framing-the-question-fundamental-idea-i-1"><i class="fa fa-check"></i><b>17.1</b> Framing the Question (Fundamental Idea I)</a></li>
<li class="chapter" data-level="17.2" data-path="ANOVArecap.html"><a href="ANOVArecap.html#getting-good-data-fundamental-idea-ii-1"><i class="fa fa-check"></i><b>17.2</b> Getting Good Data (Fundamental Idea II)</a></li>
<li class="chapter" data-level="17.3" data-path="ANOVArecap.html"><a href="ANOVArecap.html#presenting-the-data-fundamental-idea-iii-1"><i class="fa fa-check"></i><b>17.3</b> Presenting the Data (Fundamental Idea III)</a></li>
<li class="chapter" data-level="17.4" data-path="ANOVArecap.html"><a href="ANOVArecap.html#quantifying-the-variability-in-the-estimate-fundamental-idea-iv-1"><i class="fa fa-check"></i><b>17.4</b> Quantifying the Variability in the Estimate (Fundamental Idea IV)</a></li>
<li class="chapter" data-level="17.5" data-path="ANOVArecap.html"><a href="ANOVArecap.html#quantifying-the-evidence-fundamental-idea-v-1"><i class="fa fa-check"></i><b>17.5</b> Quantifying the Evidence (Fundamental Idea V)</a></li>
<li class="chapter" data-level="17.6" data-path="ANOVArecap.html"><a href="ANOVArecap.html#conclusion"><i class="fa fa-check"></i><b>17.6</b> Conclusion</a></li>
</ul></li>
<li class="chapter" data-level="18" data-path="ANOVAblocking.html"><a href="ANOVAblocking.html"><i class="fa fa-check"></i><b>18</b> Analyzing a Design that Incorporates Blocking</a><ul>
<li class="chapter" data-level="18.1" data-path="ANOVAblocking.html"><a href="ANOVAblocking.html#what-is-the-big-deal"><i class="fa fa-check"></i><b>18.1</b> What is the Big Deal?</a></li>
<li class="chapter" data-level="18.2" data-path="ANOVAblocking.html"><a href="ANOVAblocking.html#solution-partition-the-variability"><i class="fa fa-check"></i><b>18.2</b> Solution: Partition the Variability</a></li>
<li class="chapter" data-level="18.3" data-path="ANOVAblocking.html"><a href="ANOVAblocking.html#interpreting-the-analysis"><i class="fa fa-check"></i><b>18.3</b> Interpreting the Analysis</a></li>
</ul></li>
<li class="part"><span><b>III Unit III: Modeling the Average Response as a Function of Several Predictors</b></span></li>
<li class="chapter" data-level="19" data-path="CaseGreece.html"><a href="CaseGreece.html"><i class="fa fa-check"></i><b>19</b> Case Study: Seismic Activity in Greece</a></li>
<li class="chapter" data-level="20" data-path="Regquestions.html"><a href="Regquestions.html"><i class="fa fa-check"></i><b>20</b> Myriad of Potential Questions</a></li>
<li class="chapter" data-level="21" data-path="Regdata.html"><a href="Regdata.html"><i class="fa fa-check"></i><b>21</b> Nature of Collecting Multivariable Data</a></li>
<li class="chapter" data-level="22" data-path="Regsummaries.html"><a href="Regsummaries.html"><i class="fa fa-check"></i><b>22</b> Summarizing Multivariable Data</a><ul>
<li class="chapter" data-level="22.1" data-path="Regsummaries.html"><a href="Regsummaries.html#characterizing-the-marginal-relationship-of-two-quantitative-variables"><i class="fa fa-check"></i><b>22.1</b> Characterizing the Marginal Relationship of Two Quantitative Variables</a></li>
<li class="chapter" data-level="22.2" data-path="Regsummaries.html"><a href="Regsummaries.html#visualizing-the-impact-of-a-third-variable-on-the-marginal-relationship"><i class="fa fa-check"></i><b>22.2</b> Visualizing the Impact of a Third Variable on the Marginal Relationship</a></li>
</ul></li>
<li class="chapter" data-level="23" data-path="Regmodel.html"><a href="Regmodel.html"><i class="fa fa-check"></i><b>23</b> Extending Our Statistical Model</a><ul>
<li class="chapter" data-level="23.1" data-path="Regmodel.html"><a href="Regmodel.html#statistical-model-for-a-quantitative-response-and-quantitative-predictors"><i class="fa fa-check"></i><b>23.1</b> Statistical Model for A Quantitative Response and Quantitative Predictor(s)</a><ul>
<li class="chapter" data-level="23.1.1" data-path="Regmodel.html"><a href="Regmodel.html#including-multiple-precitors"><i class="fa fa-check"></i><b>23.1.1</b> Including Multiple Precitors</a></li>
<li class="chapter" data-level="23.1.2" data-path="Regmodel.html"><a href="Regmodel.html#including-categorical-predictors"><i class="fa fa-check"></i><b>23.1.2</b> Including Categorical Predictors</a></li>
<li class="chapter" data-level="23.1.3" data-path="Regmodel.html"><a href="Regmodel.html#general-model-formulation"><i class="fa fa-check"></i><b>23.1.3</b> General Model Formulation</a></li>
</ul></li>
<li class="chapter" data-level="23.2" data-path="Regmodel.html"><a href="Regmodel.html#estimating-the-parameters"><i class="fa fa-check"></i><b>23.2</b> Estimating the Parameters</a></li>
<li class="chapter" data-level="23.3" data-path="Regmodel.html"><a href="Regmodel.html#embedding-our-questions-into-a-statistical-framework"><i class="fa fa-check"></i><b>23.3</b> Embedding Our Questions into a Statistical Framework</a></li>
<li class="chapter" data-level="23.4" data-path="Regmodel.html"><a href="Regmodel.html#recap-2"><i class="fa fa-check"></i><b>23.4</b> Recap</a></li>
</ul></li>
<li class="chapter" data-level="24" data-path="Regconditions.html"><a href="Regconditions.html"><i class="fa fa-check"></i><b>24</b> Conditions on the Error Term of a Regression Model</a><ul>
<li class="chapter" data-level="24.1" data-path="Regconditions.html"><a href="Regconditions.html#classical-regression-model"><i class="fa fa-check"></i><b>24.1</b> Classical Regression Model</a></li>
<li class="chapter" data-level="24.2" data-path="Regconditions.html"><a href="Regconditions.html#interpretation-of-the-parameters"><i class="fa fa-check"></i><b>24.2</b> Interpretation of the Parameters</a></li>
<li class="chapter" data-level="24.3" data-path="Regconditions.html"><a href="Regconditions.html#addressing-confounding-through-our-interpretation"><i class="fa fa-check"></i><b>24.3</b> Addressing Confounding through our Interpretation</a></li>
<li class="chapter" data-level="24.4" data-path="Regconditions.html"><a href="Regconditions.html#empirical-model-for-the-sampling-distribution"><i class="fa fa-check"></i><b>24.4</b> Empirical Model for the Sampling Distribution</a></li>
<li class="chapter" data-level="24.5" data-path="Regconditions.html"><a href="Regconditions.html#recap-3"><i class="fa fa-check"></i><b>24.5</b> Recap</a></li>
</ul></li>
<li class="chapter" data-level="25" data-path="Regassessment.html"><a href="Regassessment.html"><i class="fa fa-check"></i><b>25</b> Assessing Modeling Assumptions</a><ul>
<li class="chapter" data-level="25.1" data-path="Regassessment.html"><a href="Regassessment.html#computing-residuals"><i class="fa fa-check"></i><b>25.1</b> Computing Residuals</a></li>
<li class="chapter" data-level="25.2" data-path="Regassessment.html"><a href="Regassessment.html#assessing-mean-0"><i class="fa fa-check"></i><b>25.2</b> Assessing Mean 0</a></li>
<li class="chapter" data-level="25.3" data-path="Regassessment.html"><a href="Regassessment.html#assessing-independence-1"><i class="fa fa-check"></i><b>25.3</b> Assessing Independence</a></li>
<li class="chapter" data-level="25.4" data-path="Regassessment.html"><a href="Regassessment.html#assessing-homoskedasticity-1"><i class="fa fa-check"></i><b>25.4</b> Assessing Homoskedasticity</a></li>
<li class="chapter" data-level="25.5" data-path="Regassessment.html"><a href="Regassessment.html#assessing-normality-1"><i class="fa fa-check"></i><b>25.5</b> Assessing Normality</a></li>
<li class="chapter" data-level="25.6" data-path="Regassessment.html"><a href="Regassessment.html#general-tips-for-assessing-assumptions-1"><i class="fa fa-check"></i><b>25.6</b> General Tips for Assessing Assumptions</a></li>
</ul></li>
<li class="chapter" data-level="26" data-path="Reginteractions.html"><a href="Reginteractions.html"><i class="fa fa-check"></i><b>26</b> Modifying an Effect</a><ul>
<li class="chapter" data-level="26.1" data-path="Reginteractions.html"><a href="Reginteractions.html#building-an-effect-modifier-into-the-model"><i class="fa fa-check"></i><b>26.1</b> Building an Effect-Modifier into the Model</a></li>
<li class="chapter" data-level="26.2" data-path="Reginteractions.html"><a href="Reginteractions.html#inference-for-effect-modifications"><i class="fa fa-check"></i><b>26.2</b> Inference for Effect Modifications</a></li>
</ul></li>
<li class="chapter" data-level="27" data-path="Regquality.html"><a href="Regquality.html"><i class="fa fa-check"></i><b>27</b> Quantifying the Quality of a Model Fit</a><ul>
<li class="chapter" data-level="27.1" data-path="Regquality.html"><a href="Regquality.html#partitioning-variability-1"><i class="fa fa-check"></i><b>27.1</b> Partitioning Variability</a></li>
<li class="chapter" data-level="27.2" data-path="Regquality.html"><a href="Regquality.html#r-squared"><i class="fa fa-check"></i><b>27.2</b> R-squared</a></li>
<li class="chapter" data-level="27.3" data-path="Regquality.html"><a href="Regquality.html#overfitting"><i class="fa fa-check"></i><b>27.3</b> Overfitting</a></li>
<li class="chapter" data-level="27.4" data-path="Regquality.html"><a href="Regquality.html#goal-of-modeling"><i class="fa fa-check"></i><b>27.4</b> Goal of Modeling</a></li>
</ul></li>
<li class="chapter" data-level="28" data-path="Regrecap.html"><a href="Regrecap.html"><i class="fa fa-check"></i><b>28</b> Puting it All Together</a><ul>
<li class="chapter" data-level="28.1" data-path="Regrecap.html"><a href="Regrecap.html#graphical-summary"><i class="fa fa-check"></i><b>28.1</b> Graphical Summary</a></li>
<li class="chapter" data-level="28.2" data-path="Regrecap.html"><a href="Regrecap.html#development-of-statistical-model"><i class="fa fa-check"></i><b>28.2</b> Development of Statistical Model</a></li>
<li class="chapter" data-level="28.3" data-path="Regrecap.html"><a href="Regrecap.html#assessment-of-conditions"><i class="fa fa-check"></i><b>28.3</b> Assessment of Conditions</a></li>
<li class="chapter" data-level="28.4" data-path="Regrecap.html"><a href="Regrecap.html#summary-of-model-fit"><i class="fa fa-check"></i><b>28.4</b> Summary of Model Fit</a></li>
</ul></li>
<li class="part"><span><b>IV Unit IV: Special Cases</b></span></li>
<li class="chapter" data-level="29" data-path="CaseBabies.html"><a href="CaseBabies.html"><i class="fa fa-check"></i><b>29</b> Case Study: Birth Weights of Babies</a></li>
<li class="chapter" data-level="30" data-path="OneMean.html"><a href="OneMean.html"><i class="fa fa-check"></i><b>30</b> Inference on the Mean of a Single Population (One-Sample t-Tests)</a><ul>
<li class="chapter" data-level="30.1" data-path="OneMean.html"><a href="OneMean.html#framing-the-question-1"><i class="fa fa-check"></i><b>30.1</b> Framing the Question</a></li>
<li class="chapter" data-level="30.2" data-path="OneMean.html"><a href="OneMean.html#classical-approach"><i class="fa fa-check"></i><b>30.2</b> Classical Approach</a></li>
<li class="chapter" data-level="30.3" data-path="OneMean.html"><a href="OneMean.html#connection-to-modeling"><i class="fa fa-check"></i><b>30.3</b> Connection to Modeling</a></li>
</ul></li>
<li class="chapter" data-level="31" data-path="TwoMeans.html"><a href="TwoMeans.html"><i class="fa fa-check"></i><b>31</b> Comparing the Means of Two Independent Groups (Two-Sample t-Tests)</a><ul>
<li class="chapter" data-level="31.1" data-path="TwoMeans.html"><a href="TwoMeans.html#framing-the-question-2"><i class="fa fa-check"></i><b>31.1</b> Framing the Question</a></li>
<li class="chapter" data-level="31.2" data-path="TwoMeans.html"><a href="TwoMeans.html#classical-approach-1"><i class="fa fa-check"></i><b>31.2</b> Classical Approach</a></li>
<li class="chapter" data-level="31.3" data-path="TwoMeans.html"><a href="TwoMeans.html#connection-to-modeling-1"><i class="fa fa-check"></i><b>31.3</b> Connection to Modeling</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Statistical Foundations for Engineers and Scientists</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="Regconditions" class="section level1">
<h1><span class="header-section-number">24</span> Conditions on the Error Term of a Regression Model</h1>
<p>In the previous chapter we developed a general model for generating a quantitative response as a linear function of several predictors:</p>
<p><span class="math display">\[(\text{Response})_i = \beta_0 + \sum_{j=1}^{p} \beta_j (\text{Predictor})_{i,j} + \epsilon_i\]</span></p>
<p>We also discussed a common method for estimating the parameters of this model from a sample — the least squares method. However, if we are to construct a model for the sampling distribution of these estimates we must add some structure to the stochastic component <span class="math inline">\(\epsilon\)</span> in the model. Just as in the previous unit, the more assumptions we are willing to make, the easier the analysis, but the less likely our model is to be applicable to the actual data-generating process we have observed. The conditions we make dictate how we conduct inference (the computation of a p-value or confidence interval).</p>
<div id="classical-regression-model" class="section level2">
<h2><span class="header-section-number">24.1</span> Classical Regression Model</h2>
<p>In this section, we discuss four potential conditions we might place on the stochastic portion of the model. As we will see, the conditions we consider are extremely similar to those considered in Chapter <a href="ANOVAclassical.html#ANOVAclassical">15</a>.</p>
<p>The first condition we consider is that the noise attributed to one observed individual is independent of the noise attributed to any other individual observed. That is, the amount of error in any one individual’s response is unrelated to the error in any other response observed.</p>
<p>The second condition that is typically placed on the distribution of the errors is that the variability of the responses is similar for every value of the predictor variables (homoskedasticity). This generalizes the way we characterized the condition in the ANOVA model; the primary difference is that in ANOVA, we had a finite number of groups over which the variance had to remain constant. Now, we are asking the variability about the regression line to be constant for all values of the predictors.</p>
<p>The third condition is that errors follow a Normal distribution. Given the shape of the Normal distribution, this condition implies that some responses will tend to fall above the line (we will underpredict for these observations), and some responses will tend to fall below the line (we will overpredict for these observations). Assuming this condition holds adds a lot of structure to the errors and gets toward modeling the distribution of the population, as we did in ANOVA.</p>
<p>The fourth condition, which is the most important, is that for every value of the predictor, the average error is 0. This acondition implies that the model we have posited for the data generating process is accurate. That is, the form of the model is appropriate. The reason we say this is the most important condition is that while we have methods for conducting an analysis while relaxing the remaining three conditions, if this condition is violated, it says that your model is wrong and you need to essentially start over in developing the model.</p>
<p>If you assume all four of these conditions, we have what we refer to as the “Classical Regression Model.”</p>

<div class="rmdtip">
<p>“Classical Regression Model”: For a quantitative response and <span class="math inline">\(p\)</span> predictors (which could include indicators to represent a categorical variable), the classical regression model assumes the following data-generating process:</p>
<p><span class="math display">\[(\text{Response})_i = \beta_0 + \sum_{j=1}^{p} \beta_j (\text{Predictor})_{j,i} + \epsilon_i\]</span></p>
<p>where</p>
<ol style="list-style-type: decimal">
<li>The errors have a mean of 0 for all values of the predictors.</li>
<li>The errors are independent of one another.</li>
<li>The errors have the same variability for all values of the predictors.</li>
<li>The errors follow a Normal Distribution.</li>
</ol>
It is possible to relax these assumptions; however, this is the default “regression” analysis implemented in the majority of statistical packages.
</div>
<p></p>
<p>We have stressed the implications of each condition. Figure <a href="Regconditions.html#fig:regconditions-assumptions">24.1</a> illustrates these conditions for the case of a single quantitative predictor. The condition that the errors have mean 0 implies that for a given value of the predictor, the average response is given by the line (shown as the green dot in the figure). The condition of Normality implies that for a given value of the predictor, the response is distributed evenly about the regression line, with some above and some below. Further, the shape of the Normal distribution implies that these responses will cluster about the line. The condition of homoskedasticity implies that while the responses vary around the line, they do so the same degree, regardless of the value of the predictor. Therefore, the model is just as precise for all values of the predictor. Finally, any two responses must be unrelated.</p>
<div class="figure" style="text-align: center"><span id="fig:regconditions-assumptions"></span>
<img src="images/RegConditions-Assumptions.jpg" alt="Illustration of the conditions on the error term for the classical regression model." width="80%" />
<p class="caption">
Figure 24.1: Illustration of the conditions on the error term for the classical regression model.
</p>
</div>
<p>As with ANOVA, these conditions will allow us to easily model the sampling distribution of our estimates, which is the critical step in developing any type of inference. In the previous chapter, we considered the following model for the bracketed duration:</p>
<p><span class="math display">\[(\text{Bracketed Duration})_i = \beta_0 + \beta_1(\text{Magnitude})_i + \epsilon_i\]</span></p>
<p>This model was used to assess the marginal relationship between the bracketed duration and the magnitude overall. Our hypotheses of interest which captures the question of interest was</p>
<blockquote>
<p><span class="math inline">\(H_0: \beta_1 = 0\)</span><br />
<span class="math inline">\(H_0: \beta_1 \neq 0\)</span></p>
</blockquote>
<p>Using the method of least squares, we estimated the parameters in the model; this leads to the following equation for predicting the bracketed duration given the magnitude:</p>
<p><span class="math display">\[(\text{Brackted Duration}) = -19.19 + 4.48(\text{Magnitude})\]</span></p>
<p>Most statistical software packages will present the fit through a table which contains the parameter estimates as well as additional information regarding the parameter estimates. Table <a href="Regconditions.html#tab:regconditions-slr-summary">24.1</a> summarizes the fit for the above model. The p-values which are included are always testing if the corresponding parameter is equal to 0. Based on the results, we have strong evidence that the slope coefficient associated with the magnitude differs from 0; that is, we have strong evidence (<span class="math inline">\(p &lt; 0.001\)</span>) of a relationship between the bracketed duration and the magnitude of the earthquake. Further, our data is consistent with this coefficient being in the range of (3.05, 5.917) based on the 95% confidence interval.</p>
<table>
<caption><span id="tab:regconditions-slr-summary">Table 24.1: </span>Summary of the linear model fit relating the bracketed duration at locations in Greece following an earthquake with the magnitude of the event.</caption>
<thead>
<tr class="header">
<th align="left">Term</th>
<th align="right">Estimate</th>
<th align="right">Standard Error</th>
<th align="right">Lower 95% CI</th>
<th align="right">Upper 95% CI</th>
<th align="left">P Value</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">(Intercept)</td>
<td align="right">-19.194</td>
<td align="right">3.975</td>
<td align="right">-27.066</td>
<td align="right">-11.323</td>
<td align="left">&lt; 0.001</td>
</tr>
<tr class="even">
<td align="left">Magnitude</td>
<td align="right">4.484</td>
<td align="right">0.724</td>
<td align="right">3.050</td>
<td align="right">5.917</td>
<td align="left">&lt; 0.001</td>
</tr>
</tbody>
</table>
<p>In addition tot he estimate, a confidence interval and p-value associated with testing whether the parameter is equal to 0, the ouptut also includes the <strong>standard error</strong> of the estimate. This is a measure of the variability in the estimate; it is standard deviation associated with the sampling distribution of the statistic. This is used in the analytical formulas for computing the confidence intervals and p-values reported in the table.</p>

<div class="definition">
<span id="def:defn-standard-error" class="definition"><strong>Definition 24.1  (Standard Error)  </strong></span>The estimated standard deviation of a statistic; it quantifies the variability in the sampling distribution of the statistic.
</div>
<p></p>
</div>
<div id="interpretation-of-the-parameters" class="section level2">
<h2><span class="header-section-number">24.2</span> Interpretation of the Parameters</h2>
<p>Each of the conditions from the classical regression model can be relaxed, with the exception of the condition that the errors have an average of 0 for all values of the predictors. Not only does this ensure that the model is correctly specified, but it also provides an interpretation for the parameters. If the errors are not biasing the average response (since on average, they have a value of 0), then we are able to say that the determinisic portion of our model is giving the <em>average</em> response.</p>

<div class="rmdkeyidea">
The deterministic portion of a regression model specifies the <em>average</em> value of the response given the value(s) of the predictor(s).
</div>
<p></p>
<p>As an example, consider the <a href="CaseGreece.html#CaseGreece">Seismic Activity Case Study</a>. Specifically, consider our model which predicted the bracketed duration as a function of both the magnitude of the earthquake and the distance from the location to the center of the earthquake:</p>
<p><span class="math display">\[(\text{Bracketed Duration})_i = \beta_0 + \beta_1(\text{Magnitude})_i + \beta_2(\text{Epicentral Distance})_i + \epsilon_i\]</span></p>
<p>Using the method of least squares, we are able to estimate the parameters in this model; the deterministic portion of this model is then estimated as</p>
<p><span class="math display">\[(\text{Bracketed Duration}) = -30.72 + 6.99 (\text{Magnitude}) + -0.08(\text{Epicentral Distance})\]</span></p>
<p>The full fit is summarized in Table <a href="Regconditions.html#tab:regconditions-mlr-summary">24.2</a>.</p>
<table>
<caption><span id="tab:regconditions-mlr-summary">Table 24.2: </span>Summary of the linear model fit relating the bracketed duration at locations in Greece following an earthquake with the magnitude of the event as well as the distance the location is from the epicenter of the earthquake.</caption>
<thead>
<tr class="header">
<th align="left">Term</th>
<th align="right">Estimate</th>
<th align="right">Standard Error</th>
<th align="right">Lower 95% CI</th>
<th align="right">Upper 95% CI</th>
<th align="left">P Value</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">(Intercept)</td>
<td align="right">-30.715</td>
<td align="right">4.887</td>
<td align="right">-40.395</td>
<td align="right">-21.036</td>
<td align="left">&lt; 0.001</td>
</tr>
<tr class="even">
<td align="left">Magnitude</td>
<td align="right">6.991</td>
<td align="right">0.964</td>
<td align="right">5.082</td>
<td align="right">8.900</td>
<td align="left">&lt; 0.001</td>
</tr>
<tr class="odd">
<td align="left">Epicentral_Distance</td>
<td align="right">-0.077</td>
<td align="right">0.021</td>
<td align="right">-0.118</td>
<td align="right">-0.036</td>
<td align="left">&lt; 0.001</td>
</tr>
</tbody>
</table>
<p>Using this fit, we are able to estimate the <em>average</em> bracketed duration at a location given the magnitude of an earthquake and the distance it is from the center of the earthquake. Specifically, following an earthquake with a magnitude of 5.5, a location which is 2 kilometers from the epicenter of the earthquake will experience a bracketed duration of 7.58 seconds, on average. Remember, the deterministic portion is not trying to explain every single response but the overall trend; we now see that it is doing so by specifying the trend, <em>on average</em>. We do not expect every location which is 2 kilometers away from the epicenter of a 5.5 earthquake to experience 7.58 seconds of strong motion; however, we expect the bracketed duration to vary about this value.</p>
<p>This is huge; it says that when we use a regression model to predict a response, we are actually predicting the <em>average</em> response. More, we can interpret the parameters themselves. Let’s begin with the intercept term, <span class="math inline">\(\beta_0\)</span>. Notice that in our model above, if we try to predict the bracketed duration for a location where an earthquake occurs (so the distance from the epicenter is 0 kilometers) which has a magnitude of 0, then our least squares estimates predict an average bracketed duration of -30.72 seconds. But, this is the value of <span class="math inline">\(\widehat{\beta}_0\)</span>, the estimate for the intercept. In fact, for any regression model, the intercept <span class="math inline">\(\beta_0\)</span> is the value of the deterministic portion of the model whenever all predictors in the model are set to 0.</p>

<div class="rmdtip">
The intercept in a regression model <span class="math inline">\(\beta_0\)</span> represents the <em>average</em> response when all predictors in the model are set equal to 0. Note that this may often be an unreasonable scenario.
</div>
<p></p>
<p>For our particular example, the estimate of the intercept does not make sense — what does it mean to have a duration of -30.72 seconds? This can often be the case when trying to interpret the intercept term due to what we call <strong>extrapolation</strong>. We do not have any data on the bracketed duration for locations which are less than a kilometer from the epicenter of an earthquake; nor do we have data on the bracketed duration when an earthquake has a magnitude of 0 as there is no such thing. Therefore, we are using a model to predict for a region over which the model was not constructed to operate. This is a lot like using a screw driver to hammer a nail — we are using a tool to accomplish a task for which it was not designed. We should not be surprised when it fails. The primary reason extrapolation is dangerous is that without data in a particular region, we have no support that the model will continue to hold in that region. For this reason, unless you have strong scientific justification for why a model will hold over all values of the predictor, extrapolation should be avoided.</p>

<div class="definition">
<span id="def:defn-extrapolation" class="definition"><strong>Definition 24.2  (Extrapolation)  </strong></span>Using a model to predict outside of a region for which data is available.
</div>
<p></p>
<p>We have seen that the intercept is the average value of the response when the predictors take the value of 0. How then do we interpret the coefficients (or slopes) associated with each predictor. We again use an example. Let’s compare the average bracketed duration for a location which is 5 kilometers away from the epicenter of an earthquake which has a magnitude of 3 and one which has a magnitude of 4:</p>
<p><span class="math display">\[
\begin{aligned}
  \text{Magnitude of 3:} \quad &amp;(\text{Bracketed Duration}) = -30.72 + 6.99 (3) + -0.08(5) = -10.13 \\
  \text{Magnitude of 4:} \quad &amp;(\text{Bracketed Duration}) = -30.72 + 6.99 (4) + -0.08(5) = -3.14
\end{aligned}
\]</span></p>
<p>Notice the two estimates differ by 6.99 seconds, which is exactly the value of <span class="math inline">\(\widehat{\beta}_1\)</span>, the estimate of the coefficient associated with magnitude in our model. Notice, however, in order to get this difference, we left the epicentral distance the same in both scenarios. This leads us to observing that 6.99 seconds is the change in the average bracketed duration when the magnitude increased by 1 unit while the epicentral distance remained the same.</p>

<div class="rmdtip">
The coefficient (or slope) <span class="math inline">\(\beta_j\)</span> in a regression model associated with the <span class="math inline">\(j\)</span>-th predictor represents the <em>average</em> change in the response when the <span class="math inline">\(j\)</span>-th predictor is <em>increased</em> by 1 unit, <em>holding all other predictors constant</em>.
</div>
<p></p>
<p>In the previous chapter, we saw that our research questions can be framed in terms of the parameters from the regression model. The interpretation of these parameters allows us to see that our research questions are characterizing the relationship between the response and the predictor, <em>on average</em>.</p>
</div>
<div id="addressing-confounding-through-our-interpretation" class="section level2">
<h2><span class="header-section-number">24.3</span> Addressing Confounding through our Interpretation</h2>
<p>This phrase “holding all other predictors constant” has extreme power. It is this understanding of how the parameters are interpreted that we are able to take our first steps toward addressing confounding. For example, consider the model</p>
<p><span class="math display">\[(\text{Bracketed Duration})_i = \beta_0 + \beta_1(\text{Magnitude})_i + \beta_2(\text{Epicentral Distance})_i + \epsilon_i\]</span></p>
<p>From above, we found that for every kilometer further the epicenter of the earthquake is, we can expect the brackted duration to decrease by -0.08 seconds, on average. Someone might argue as follows: “This is not a controlled experiment; therefore, while there is a relationship here, it is possible that what is really happening is that earthquakes which were further away were also smaller in magnitude. Therefore, it is not the distance that is driving this relationship but the magnitude of the earthquake.” Here, this individual is saying that magnitude is a confounder — related to both the bracketed duration (response) and the variable of interest (distance from the epicenter). If we had fit a marginal model, this would be a valid concern. However, remember our interpretation of <span class="math inline">\(\beta_2\)</span> (and our estimate of it). Our fit suggests that for every kilometer further the epicenter of the earthquake is, we can expect the bracketed duration to decrease by -0.08 seconds, on average, <em>holding the magnitude of the earthquake fixed</em>. Therefore, since this estimate is comparing to earthquakes of the same magnitude, magnitude cannot be confounding the relationship observed. We have isolated the effect of the epicentral distance.</p>
<p>Our solution to confounding is to incorporate the relationship between the confounder and the response into our model. Then, any remaining variables cannot be affected by the confounder. Of course this has one major limitation — we cannot account for any variables which are not recorded.</p>
<p>There are entire texts devoted to this topic. Here, we simply emphasize that regression models allow us to control for the confounders we have observed. The relationships are “adjusted for” these confounders due to the interpretation that a coefficient is the effect “holding all other predictors constant.” Regression models allow us to compare similar groups, which are balanced on these confounders, after the fact (instead of having incorporated these comparisons through the study design).</p>
</div>
<div id="empirical-model-for-the-sampling-distribution" class="section level2">
<h2><span class="header-section-number">24.4</span> Empirical Model for the Sampling Distribution</h2>
<p>In Table <a href="Regconditions.html#tab:regconditions-mlr-summary">24.2</a>, we were able to estimate the decrease in bracketed duration, on average, for each kilometer further that location is from the epicenter of an earthquake while holding the magnitude of the earthquake constant; it is reasonable this average decrease is between 0.036 and 0.118 seconds (95% confidence interval). However, this estimate is only valid assuming the data is consistent with the conditions of the classical regression model. What if we are unwilling to make such strong assumptions? In this section, we discuss a method for making inference under only two of the above conditions:</p>
<ul>
<li>The error in the response for one observation is independent of the error in the response for all other observations.</li>
<li>The error in the responses are on average 0 for all values of the predictors.</li>
</ul>
<p>In order to empirically model the sampling distribution of the estimates in our model, we can appeal to bootstrapping as in the first unit. Specifically, we can resample (with replacement) from the original sample several times. For each resample, we ensure we select all variables associated with the selected observation. For this resampled dataset, we compute the least squares fit (see Figure <a href="Regconditions.html#fig:regconditions-bootstrap">24.2</a>). Since the observations have changed, the least squares fit will also change. By repeating this process over and over again, we can obtain a model for how the estimates would change in repeated sampling.</p>
<div class="figure" style="text-align: center"><span id="fig:regconditions-bootstrap"></span>
<img src="images/RegConditions-Bootstrap.jpg" alt="Illustration of a single iteration of a bootstrap procedure to construct an empirical estimate of the sampling distribution for the estimates of the coefficients in a regression model." width="80%" />
<p class="caption">
Figure 24.2: Illustration of a single iteration of a bootstrap procedure to construct an empirical estimate of the sampling distribution for the estimates of the coefficients in a regression model.
</p>
</div>
<p>Figure <a href="Regconditions.html#fig:regconditions-mlr-bootstrap-plot">24.3</a> shows empirical models for the sampling distribution of the three estimates from the regression model</p>
<p><span class="math display">\[(\text{Bracketed Duration})_i = \beta_0 + \beta_1(\text{Magnitude})_i + \beta_2(\text{Epicentral Distance})_i + \epsilon_i\]</span></p>
<p>which was fit and summarized in Table <a href="Regconditions.html#tab:regconditions-mlr-summary">24.2</a>. Overlayed in the figure are the analytical models for the sampling distribution of the estimates under the classical regression model. We notice that the model assuming the classical regression model conditions is not all that accurate in this case; we explore the reasoning behind this in Chapter @(Regassessment). For now, suffice it to say that we should rely on the results from an empirical model instead of the analytical model suggested by the classical regression model. Once we have a model for the sampling distribution, we can construct confidence intervals and begin performing inference.</p>
<div class="figure" style="text-align: center"><span id="fig:regconditions-mlr-bootstrap-plot"></span>
<img src="images/regconditions-mlr-bootstrap-plot-1.png" alt="Empirical models for the sampling distribution of the estimates from a regression model explaining bracketed duration as a function of the magnitude of the earthquake and its distance from the measuring location.  Overlayed are the analytical models for the sampling distribution assuming all conditions for the classical regression model." width="80%" />
<p class="caption">
Figure 24.3: Empirical models for the sampling distribution of the estimates from a regression model explaining bracketed duration as a function of the magnitude of the earthquake and its distance from the measuring location. Overlayed are the analytical models for the sampling distribution assuming all conditions for the classical regression model.
</p>
</div>
<p>While we do not discuss it thoroughly, if interest is in computing a p-value to address he above hypotheses, we can construct a null distribution in a similar fashion as that discussed in Chapter <a href="ANOVAmodel.html#ANOVAmodel">14</a> in the context of a regression model.</p>
</div>
<div id="recap-3" class="section level2">
<h2><span class="header-section-number">24.5</span> Recap</h2>
<p>We have covered a lot of ground in this chapter, and it is worth taking a moment to summarize the big ideas. In order to construct a model for the sampling distribution for the estimates of the parameters in the regression model, we took a step back and modeled the data generating process. Such a model consists of two components: a deterministic component explaining the differences between groups and a stochastic component capturing the noise in the system.</p>
<p>Certain conditions are placed on the distribution of the noise in our model. With a full set of conditions (classical regression model), we are able to model the sampling distribution analytically. We can also construct an empirical model for the sampling distribution assuming the data is consistent with fewer conditions.</p>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="Regmodel.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="Regassessment.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": false,
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": null,
"download": ["MA223CourseNotes.pdf"],
"toc": {
"collapse": "section"
},
"toolbar": {
"position": "fixed"
},
"search": true
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(script.src))
      script.src  = script.src.replace(/^https?:/, '');
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
